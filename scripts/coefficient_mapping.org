#+title: Mapping

This notebook will explore the mapping of the IoTVar parameters and equation coefficients.
* Imports
#+begin_src jupyter-python :kernel iotvar_powerprofiler :results silent
import numpy as np
import matplotlib.pyplot as plt
import os
import polars as pl
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error
import tensorflow as tf
from tensorflow.keras.models import Sequential, Model
from tensorflow.keras.layers import Dense, Dropout, Input
from tensorflow.keras.optimizers import Adam
import seaborn as sns
import pandas as pd
from tensorflow.keras import backend as K
from sklearn.preprocessing import StandardScaler
from scipy.stats import iqr
#+end_src
* Functions
#+begin_src jupyter-python :kernel iotvar_powerprofiler
def filter_outliers(df):
    _iqr = iqr(df['m'])
    p_25, p_75 = np.percentile(df['m'], [25, 75])
    whisker_length= 2.5
    upper_bound = p_75 + whisker_length * _iqr
    lower_bound  = p_25 - whisker_length * _iqr
    df_clean = df.filter((pl.col('m') > lower_bound)&(pl.col('m') < upper_bound))
    return df_clean
#+end_src

#+RESULTS:

* Plotting the dataset
Let's read the data.
#+begin_src jupyter-python :kernel iotvar_powerprofiler
# path = "../data/final_data/coefficients/"
path = "../data/final_data/coefficients_fixed_b/"
csv_files = [file for file in os.listdir(path) if file.endswith(".csv")]
coeff_dfs = []

for file in csv_files:
    file_path = os.path.join(path, file)
    df = pl.read_csv(file_path)
    _iqr = iqr(df['m'])
    p_25, p_75 = np.percentile(df['m'], [25, 75])
    whisker_length= 1.5
    upper_bound = p_75 + whisker_length * _iqr
    lower_bound  = p_25 - whisker_length * _iqr
    df_clean = df.filter((pl.col('m') > lower_bound)&(pl.col('m') < upper_bound))
    # coeff_dfs.append(df)
    coeff_dfs.append(df_clean)

m_b_df_minus = pl.concat(coeff_dfs)
m_b_df_minus = m_b_df_minus.filter((pl.col('refresh_period')!=3))
m_b_3sec_df = pl.read_csv("../data/final_data/coefficients_fixed_b/3sec.csv")
#m_b_1sec_df = pl.read_csv("../data/final_data/coefficients_fixed_b/1sec.csv")
#m_b_1sec_df_trimmed = m_b_1sec_df.filter(pl.col('m')>2.46)
#m_b_1sec_df_filtered = filter_outliers(m_b_1sec_df_trimmed)
df_individual_sensor = m_b_3sec_df.filter(pl.col('m')>2.46)

m_b_df = pl.concat([m_b_df_minus,df_individual_sensor])
#m_b_df = pl.concat(coeff_dfs)
# m_b_df = m_b_df_minus
# m_b_df = m_b_1sec_df
# m_b_df = m_b_3sec_df
# m_b_df = m_b_1sec_df_trimmed
# m_b_df = pl.concat([m_b_df_minus,m_b_1sec_df_trimmed])
m_b_df
#+end_src

#+RESULTS:
#+begin_example
shape: (1_230, 4)
┌────────────────┬────────────────┬──────────┬──────────┐
│ refresh_period ┆ number_sensors ┆ m        ┆ b        │
│ ---            ┆ ---            ┆ ---      ┆ ---      │
│ i64            ┆ i64            ┆ f64      ┆ f64      │
╞════════════════╪════════════════╪══════════╪══════════╡
│ 60             ┆ 125            ┆ 2.20219  ┆ 0.01279  │
│ 60             ┆ 175            ┆ 2.185199 ┆ 0.014657 │
│ 60             ┆ 175            ┆ 2.243553 ┆ 0.01789  │
│ 60             ┆ 125            ┆ 2.213822 ┆ 0.013416 │
│ 60             ┆ 50             ┆ 2.184708 ┆ 0.013618 │
│ …              ┆ …              ┆ …        ┆ …        │
│ 3              ┆ 125            ┆ 2.48992  ┆ 0.012912 │
│ 3              ┆ 75             ┆ 2.522686 ┆ 0.024871 │
│ 3              ┆ 50             ┆ 2.50307  ┆ 0.013075 │
│ 3              ┆ 75             ┆ 2.535685 ┆ 0.017001 │
│ 3              ┆ 50             ┆ 2.515175 ┆ 0.015888 │
└────────────────┴────────────────┴──────────┴──────────┘
#+end_example

Let's plot the data.
** m coefficients
#+begin_src jupyter-python :kernel iotvar_powerprofiler
fig = plt.figure()
fig.set_size_inches(25, 25)
ax = fig.add_subplot(projection='3d')
ax.scatter(m_b_df['refresh_period'],m_b_df['number_sensors'],m_b_df['m'],label='Slope m')
#ax.scatter(m_b_df['refresh_period'],m_b_df['number_sensors'],m_b_df['b'],label='Slope m')
ax.set_xlabel("Refresh time $R_{G}$", fontsize=50, labelpad=30)
ax.set_ylabel("Number of sensors in group $nb_{V_{G}}$", fontsize=50, labelpad=35)
ax.zaxis.set_rotate_label(False)
ax.set_zlabel("Slope $m$", fontsize=50, labelpad=25, rotation=90)
ax.tick_params(labelsize=40)
ax.view_init(10, 20)
plt.tight_layout()
plt.legend()
plt.show()
#+end_src

#+RESULTS:
[[./.ob-jupyter/71a632645db24a2fa7eb27cec087d17c92394c8c.png]]

** b coefficients
#+begin_src jupyter-python :kernel iotvar_powerprofiler
fig = plt.figure()
fig.set_size_inches(25, 25)
ax = fig.add_subplot(projection='3d')
ax.scatter(m_b_df['refresh_period'],m_b_df['number_sensors'],m_b_df['b'],label='Slope m')
ax.set_xlabel("Refresh time $R_{G}$", fontsize=50, labelpad=30)
ax.set_ylabel("Number of sensors in group $nb_{V_{G}}$", fontsize=50, labelpad=35)
ax.zaxis.set_rotate_label(False)
ax.set_zlabel("Intercept $b$", fontsize=50, labelpad=25, rotation=90)
ax.tick_params(labelsize=40)
ax.view_init(10, 20)
plt.tight_layout()
plt.legend()
plt.show()
#+end_src

#+RESULTS:
[[./.ob-jupyter/ae3a7d79f4420800763fbb15ecbcb40451bb3f11.png]]
* Bayesian Linear Regression
** Uni-variable
#+begin_src jupyter-python :kernel iotvar_powerprofiler
# Pandas and numpy for data manipulation
import arviz as az
import matplotlib.pyplot as plt
import numpy as np
import pandas as pd
import pymc as pm
import xarray as xr

from pymc import HalfCauchy, Model, Normal, sample

az.style.use("arviz-darkgrid")

print(f"Running on PyMC v{pm.__version__}")
#+end_src

#+RESULTS:
: Running on PyMC v5.15.0

#+begin_src jupyter-python :kernel iotvar_powerprofiler
x = m_b_df['number_sensors'].to_numpy()
y = m_b_df['m'].to_numpy()
data = pd.DataFrame(dict(x=x, y=y))
#+end_src

#+RESULTS:

#+begin_src jupyter-python :kernel iotvar_powerprofiler
plt.figure(figsize=(8, 8))

plt.plot(x,y, 'bo');
plt.xlabel('Duration (sec)', size = 18); plt.ylabel('m', size = 18);
plt.title('Slope vs Number of Sensors', size = 20);
#+end_src

#+RESULTS:
[[./.ob-jupyter/342fa299405aa9b89fbfa6f506e271da1fec160d.png]]


#+begin_src jupyter-python :kernel iotvar_powerprofiler :results silent
with Model() as model:  # model specifications in PyMC are wrapped in a with-statement
    # Define priors
    sigma = HalfCauchy("sigma", beta=10)
    intercept = Normal("Intercept", 0, sigma=20)
    slope = Normal("slope", 0, sigma=20)

    # Define likelihood
    likelihood = Normal("y", mu=intercept + slope * x, sigma=sigma, observed=y)

    # Inference!
    # draw 3000 posterior samples using NUTS sampling
    idata = sample(3000)
#+end_src

#+begin_src jupyter-python :kernel iotvar_powerprofiler :results silent
import bambi as bmb
model = bmb.Model("y ~ x", data)
idata = model.fit(draws=3000)
#+end_src

#+begin_src jupyter-python :kernel iotvar_powerprofiler
az.plot_trace(idata, figsize=(10, 7));
#+end_src

#+RESULTS:
[[./.ob-jupyter/f4c2250b088fb8edfede05a77a96fa1092b3fcd4.png]]

#+begin_src jupyter-python :kernel iotvar_powerprofiler
idata.posterior["y_model"] = idata.posterior["Intercept"] + idata.posterior["x"] * xr.DataArray(x)
_, ax = plt.subplots(figsize=(7, 7))
az.plot_lm(idata=idata, y="y", num_samples=100, axes=ax, y_model="y_model")
ax.set_title("Posterior predictive regression lines")
ax.set_xlabel("x");
#+end_src

#+RESULTS:
:RESULTS:
: /home/han4n/anaconda3/envs/IoTVar_PowerProfiler/lib/python3.10/site-packages/arviz/plots/lmplot.py:211: UserWarning: posterior_predictive not found in idata
:   warnings.warn("posterior_predictive not found in idata", UserWarning)
[[./.ob-jupyter/a42359c8896b69f692bf0a191719a7482389d6f9.png]]
:END:
** Multi-variable
#+begin_src jupyter-python :kernel iotvar_powerprofiler :results silent
import arviz as az
import pandas as pd
import matplotlib.pyplot as plt
import numpy as np
#+end_src

#+begin_src jupyter-python :kernel iotvar_powerprofiler
X1 = np.array(m_b_df['number_sensors'])
X2 = np.array(m_b_df['refresh_period'])
Y = np.array(m_b_df['m'])
fig, axes = plt.subplots(1, 2, sharex=True, figsize=(10, 4))
axes[0].scatter(X1, Y, alpha=0.6)
axes[1].scatter(X2, Y, alpha=0.6)
axes[0].set_ylabel("Slope m")
axes[0].set_xlabel("Number of sensors")
axes[1].set_xlabel("Refresh period");
#+end_src

#+RESULTS:
[[./.ob-jupyter/73edaa3387455de20881aab203b9c203cab6a48e.png]]

#+begin_src jupyter-python :kernel iotvar_powerprofiler
import pymc as pm

print(f"Running on PyMC v{pm.__version__}")
#+end_src

#+RESULTS:
: Running on PyMC v5.15.0

#+begin_src jupyter-python :kernel iotvar_powerprofiler :results silent
basic_model = pm.Model()

with basic_model:
    # Priors for unknown model parameters
    alpha = pm.Normal("alpha", mu=0, sigma=10)
    beta = pm.Normal("beta", mu=0, sigma=10, shape=2)
    sigma = pm.HalfNormal("sigma", sigma=1)

    # Expected value of outcome
    mu = alpha + beta[0] * X1 + beta[1] * X2

    # Likelihood (sampling distribution) of observations
    Y_obs = pm.Normal("Y_obs", mu=mu, sigma=sigma, observed=Y)

#+end_src
#+begin_src jupyter-python :kernel iotvar_powerprofiler :results silent
with basic_model:
    # draw 1000 posterior samples
    idata = pm.sample()
#+end_src

#+begin_src jupyter-python :kernel iotvar_powerprofiler
idata.posterior["alpha"].sel(draw=slice(0, 4))
#+end_src

#+RESULTS:
: <xarray.DataArray 'alpha' (chain: 2, draw: 5)>
: array([[2.58762228, 2.58734447, 2.59306559, 2.59482014, 2.59144283],
:        [2.58760981, 2.56219368, 2.57981525, 2.5790335 , 2.58504476]])
: Coordinates:
:   * chain    (chain) int64 0 1
:   * draw     (draw) int64 0 1 2 3 4

#+begin_src jupyter-python :kernel iotvar_powerprofiler
az.plot_trace(idata, combined=True);
#+end_src

#+RESULTS:
[[./.ob-jupyter/5f92ee31e09147e0e32503c8fa339775d0c2d6f4.png]]

#+begin_src jupyter-python :kernel iotvar_powerprofiler
az.summary(idata, round_to=3)
#+end_src

#+RESULTS:
#+begin_example
          mean     sd  hdi_3%  hdi_97%  mcse_mean  mcse_sd  ess_bulk  \
alpha    2.585  0.007   2.570    2.598        0.0      0.0   774.323
beta[0]  0.000  0.000   0.000    0.000        0.0      0.0   841.914
beta[1] -0.021  0.000  -0.021   -0.020        0.0      0.0  1116.364
sigma    0.090  0.002   0.086    0.094        0.0      0.0  1516.729

         ess_tail  r_hat
alpha     896.561  1.005
beta[0]  1019.298  1.003
beta[1]   904.399  1.003
sigma    1349.253  1.005
#+end_example

#+begin_src jupyter-python :kernel iotvar_powerprofiler
az.plot_energy(idata)
#+end_src

#+RESULTS:
:RESULTS:
: <Axes: >
#+attr_org: :width 672
[[./.ob-jupyter/d84c795158ee33082741176cdfa27655b5dd23d7.png]]
:END:

#+begin_src jupyter-python :kernel iotvar_powerprofiler
az.plot_forest(idata, var_names=["beta"], combined=True, hdi_prob=0.95, r_hat=True);
#+end_src

#+RESULTS:
[[./.ob-jupyter/cd2919912ee3bb8a98e21b9e16acc8f8b703d1d6.png]]

#+begin_src jupyter-python :kernel iotvar_powerprofiler
az.plot_posterior(idata)
#+end_src

#+RESULTS:
:RESULTS:
: array([<Axes: title={'center': 'alpha'}>,
:        <Axes: title={'center': 'beta\n0'}>,
:        <Axes: title={'center': 'beta\n1'}>,
:        <Axes: title={'center': 'sigma'}>], dtype=object)
[[./.ob-jupyter/cabb8a1d287cdc2b2bb41be281f4cefd06aa60d2.png]]
:END:
* Random Forest Regression
** slope m
#+begin_src jupyter-python :kernel iotvar_powerprofiler
import numpy as np
from sklearn.ensemble import RandomForestRegressor
from sklearn.model_selection import train_test_split, GridSearchCV

X = np.zeros([len(m_b_df['number_sensors']),2])
X[:,0] = np.array(m_b_df['refresh_period'])
X[:,1] = np.array(m_b_df['number_sensors'])

Z = np.array(m_b_df['m'])
# Split data into training and testing sets
X_train, X_test, Z_train, Z_test = train_test_split(X, Z, test_size=0.2, random_state=42)

# Initialize RandomForestRegressor
rf = RandomForestRegressor()

# Hyperparameter tuning using GridSearchCV
param_grid = {
    'n_estimators': [100, 200, 300],
    'max_depth': [10, 20, 30],
    'min_samples_split': [2, 5, 10]
}

grid_search = GridSearchCV(estimator=rf, param_grid=param_grid, cv=5, n_jobs=-1, verbose=2)
grid_search.fit(X_train, Z_train)

# Best model
best_rf = grid_search.best_estimator_

# Predict on test set
Z_pred = best_rf.predict(X_test)

# Evaluate model
from sklearn.metrics import mean_squared_error
mse = mean_squared_error(Z_test, Z_pred)
print(f"Mean Squared Error: {mse}")

#+end_src

#+RESULTS:
: Fitting 5 folds for each of 27 candidates, totalling 135 fits
: Mean Squared Error: 0.00043448068488293373

#+begin_src jupyter-python :kernel iotvar_powerprofiler
print(len(Z_pred))
print(len(Z_test))
print(len(X_test[:, 0]))
print(len(X_test[:, 1]))
#+end_src

#+RESULTS:
: 183
: 183
: 183
: 183

#+begin_src jupyter-python :kernel iotvar_powerprofiler
import matplotlib.pyplot as plt
from mpl_toolkits.mplot3d import Axes3D
import numpy as np

# Assuming X_test and Z_test are your test data and Z_pred are the predicted values

fig = plt.figure()
fig.set_size_inches(25, 25)
ax = fig.add_subplot(111, projection='3d')

# Scatter plot of the actual data points
ax.scatter(X_test[:, 0], X_test[:, 1], Z_test, color='blue', label='Actual')

# Create a grid of values for the surface plot
x_range = np.linspace(X_test[:, 0].min(), X_test[:, 0].max(), 100)
y_range = np.linspace(X_test[:, 1].min(), X_test[:, 1].max(), 100)
x_grid, y_grid = np.meshgrid(x_range, y_range)
xy_grid = np.c_[x_grid.ravel(), y_grid.ravel()]

# Predict z values for the grid
z_grid_pred = best_rf.predict(xy_grid).reshape(x_grid.shape)

# Surface plot of the predicted values

ax.plot_surface(x_grid, y_grid, z_grid_pred, color='orange', alpha=0.5, label='Predicted')

#ax.scatter(X_test[:, 0], X_test[:, 1], Z_pred, color='orange', label='Predicted')
ax.set_xlabel("Refresh time $R_{G}$", fontsize=50, labelpad=30)
ax.set_ylabel("Number of sensors in group $nb_{V_{G}}$", fontsize=50, labelpad=35)
ax.zaxis.set_rotate_label(False)
ax.set_zlabel("Slope $m$", fontsize=50, labelpad=25, rotation=90)
ax.tick_params(labelsize=40)
ax.view_init(10, 20)
plt.tight_layout()
#ax.legend()

plt.show()

#+end_src

#+RESULTS:
[[./.ob-jupyter/cc29db6a36f1c5302907b1bff2ad5a922fb728c6.png]]

#+begin_src jupyter-python :kernel iotvar_powerprofiler
Z_pred = best_rf.predict(X_test)

# Plot X vs Z
plt.figure(figsize=(14, 6),dpi=200)


plt.subplot(1, 2, 1)
plt.scatter(X_test[:, 0], Z_test, color='blue', label='Actual')
plt.scatter(X_test[:, 0], Z_pred, color='red', label='Predicted', marker='x')
plt.xlabel("Refresh time $R_{G}$")
plt.ylabel("Slope $m$")
plt.title('$R_{G}$ vs $m$')
plt.legend()

# Plot Y vs Z
plt.subplot(1, 2, 2)
plt.scatter(X_test[:, 1], Z_test, color='blue', label='Actual')
plt.scatter(X_test[:, 1], Z_pred, color='red', label='Predicted', marker='x')
plt.xlabel("Number of sensors in group $nb_{V_{G}}$")
plt.ylabel("Slope $m$")
plt.title('$nb_{V_{G}}$ vs $m$')
plt.legend()

plt.tight_layout()
plt.show()
#+end_src

#+RESULTS:
[[./.ob-jupyter/56f2eeb24ba8f10c02fbeeb9ea7287c28ae18ed9.png]]

** Intersect b
#+begin_src jupyter-python :kernel iotvar_powerprofiler
import numpy as np
from sklearn.ensemble import RandomForestRegressor
from sklearn.model_selection import train_test_split, GridSearchCV

X = np.zeros([len(m_b_df['number_sensors']),2])
X[:,0] = np.array(m_b_df['refresh_period'])
X[:,1] = np.array(m_b_df['number_sensors'])

Z = np.array(m_b_df['b'])
# Split data into training and testing sets
X_train, X_test, Z_train, Z_test = train_test_split(X, Z, test_size=0.2, random_state=42)

# Initialize RandomForestRegressor
rf = RandomForestRegressor()

# Hyperparameter tuning using GridSearchCV
param_grid = {
    'n_estimators': [100, 200, 300],
    'max_depth': [10, 20, 30],
    'min_samples_split': [2, 5, 12]
}

grid_search = GridSearchCV(estimator=rf, param_grid=param_grid, cv=5, n_jobs=-1, verbose=2)
grid_search.fit(X_train, Z_train)

# Best model
best_rf = grid_search.best_estimator_

# Predict on test set
Z_pred = best_rf.predict(X_test)

# Evaluate model
from sklearn.metrics import mean_squared_error
mse = mean_squared_error(Z_test, Z_pred)
print(f"Mean Squared Error: {mse}")
#+end_src

#+RESULTS:
#+begin_example
Fitting 5 folds for each of 27 candidates, totalling 135 fits
[CV] END max_depth=30, min_samples_split=12, n_estimators=100; total time=   0.2s
[CV] END max_depth=30, min_samples_split=12, n_estimators=100; total time=   0.2s
[CV] END max_depth=30, min_samples_split=12, n_estimators=100; total time=   0.2s
[CV] END max_depth=30, min_samples_split=12, n_estimators=100; total time=   0.2s
[CV] END max_depth=30, min_samples_split=12, n_estimators=100; total time=   0.2s
[CV] END max_depth=30, min_samples_split=12, n_estimators=100; total time=   0.2s
[CV] END max_depth=30, min_samples_split=12, n_estimators=100; total time=   0.2s
[CV] END max_depth=30, min_samples_split=12, n_estimators=200; total time=   0.4s
[CV] END max_depth=30, min_samples_split=12, n_estimators=200; total time=   0.4s
[CV] END max_depth=30, min_samples_split=12, n_estimators=200; total time=   0.4s
[CV] END max_depth=30, min_samples_split=12, n_estimators=200; total time=   0.4s
[CV] END max_depth=30, min_samples_split=12, n_estimators=200; total time=   0.4s
[CV] END max_depth=30, min_samples_split=12, n_estimators=200; total time=   0.4s
[CV] END max_depth=30, min_samples_split=12, n_estimators=200; total time=   0.4s
[CV] END max_depth=30, min_samples_split=12, n_estimators=200; total time=   0.4s
[CV] END max_depth=30, min_samples_split=12, n_estimators=200; total time=   0.4s
[CV] END max_depth=30, min_samples_split=12, n_estimators=200; total time=   0.4s
[CV] END max_depth=30, min_samples_split=12, n_estimators=200; total time=   0.4s
[CV] END max_depth=30, min_samples_split=12, n_estimators=200; total time=   0.4s
[CV] END max_depth=30, min_samples_split=12, n_estimators=200; total time=   0.4s
[CV] END max_depth=30, min_samples_split=12, n_estimators=300; total time=   0.6s
[CV] END max_depth=30, min_samples_split=12, n_estimators=300; total time=   0.6s
[CV] END max_depth=30, min_samples_split=12, n_estimators=300; total time=   0.6s
[CV] END max_depth=30, min_samples_split=12, n_estimators=300; total time=   0.6s
[CV] END max_depth=30, min_samples_split=12, n_estimators=300; total time=   0.6s
[CV] END max_depth=30, min_samples_split=12, n_estimators=300; total time=   0.6s
[CV] END max_depth=30, min_samples_split=12, n_estimators=300; total time=   0.6s
[CV] END max_depth=30, min_samples_split=12, n_estimators=300; total time=   0.6s
[CV] END max_depth=30, min_samples_split=12, n_estimators=300; total time=   0.6s
[CV] END max_depth=30, min_samples_split=12, n_estimators=300; total time=   0.6s
[CV] END max_depth=30, min_samples_split=12, n_estimators=300; total time=   0.6s
[CV] END max_depth=30, min_samples_split=12, n_estimators=300; total time=   0.6s
[CV] END max_depth=10, min_samples_split=2, n_estimators=100; total time=   0.2s
[CV] END max_depth=10, min_samples_split=2, n_estimators=100; total time=   0.2s
[CV] END max_depth=10, min_samples_split=2, n_estimators=200; total time=   0.4s
[CV] END max_depth=10, min_samples_split=2, n_estimators=200; total time=   0.4s
[CV] END max_depth=10, min_samples_split=5, n_estimators=100; total time=   0.2s
[CV] END max_depth=10, min_samples_split=5, n_estimators=100; total time=   0.2s
[CV] END max_depth=10, min_samples_split=5, n_estimators=200; total time=   0.4s
[CV] END max_depth=10, min_samples_split=5, n_estimators=200; total time=   0.4s
[CV] END max_depth=10, min_samples_split=5, n_estimators=300; total time=   0.6s
[CV] END max_depth=10, min_samples_split=5, n_estimators=300; total time=   0.6s
[CV] END max_depth=10, min_samples_split=12, n_estimators=300; total time=   0.6s
[CV] END max_depth=10, min_samples_split=12, n_estimators=300; total time=   0.6s
[CV] END max_depth=20, min_samples_split=2, n_estimators=200; total time=   0.4s
[CV] END max_depth=20, min_samples_split=2, n_estimators=200; total time=   0.4s
[CV] END max_depth=20, min_samples_split=5, n_estimators=100; total time=   0.2s
[CV] END max_depth=20, min_samples_split=5, n_estimators=100; total time=   0.2s
[CV] END max_depth=20, min_samples_split=5, n_estimators=100; total time=   0.2s
[CV] END max_depth=20, min_samples_split=5, n_estimators=200; total time=   0.4s
[CV] END max_depth=20, min_samples_split=5, n_estimators=300; total time=   0.6s
[CV] END max_depth=20, min_samples_split=5, n_estimators=300; total time=   0.6s
[CV] END max_depth=20, min_samples_split=12, n_estimators=200; total time=   0.4s
[CV] END max_depth=20, min_samples_split=12, n_estimators=200; total time=   0.4s
[CV] END max_depth=30, min_samples_split=2, n_estimators=100; total time=   0.2s
[CV] END max_depth=30, min_samples_split=2, n_estimators=100; total time=   0.2s
[CV] END max_depth=30, min_samples_split=2, n_estimators=100; total time=   0.2s
[CV] END max_depth=30, min_samples_split=2, n_estimators=200; total time=   0.4s
[CV] END max_depth=30, min_samples_split=2, n_estimators=300; total time=   0.6s
[CV] END max_depth=30, min_samples_split=2, n_estimators=300; total time=   0.6s
[CV] END max_depth=30, min_samples_split=5, n_estimators=200; total time=   0.4s
[CV] END max_depth=30, min_samples_split=5, n_estimators=200; total time=   0.4s
[CV] END max_depth=30, min_samples_split=5, n_estimators=300; total time=   0.6s
[CV] END max_depth=30, min_samples_split=5, n_estimators=300; total time=   0.6s
[CV] END max_depth=30, min_samples_split=12, n_estimators=300; total time=   0.6s
[CV] END max_depth=30, min_samples_split=12, n_estimators=300; total time=   0.4s
[CV] END max_depth=10, min_samples_split=2, n_estimators=100; total time=   0.2s
[CV] END max_depth=10, min_samples_split=2, n_estimators=200; total time=   0.4s
[CV] END max_depth=10, min_samples_split=2, n_estimators=300; total time=   0.6s
[CV] END max_depth=10, min_samples_split=5, n_estimators=100; total time=   0.2s
[CV] END max_depth=10, min_samples_split=5, n_estimators=100; total time=   0.2s
[CV] END max_depth=10, min_samples_split=5, n_estimators=100; total time=   0.2s
[CV] END max_depth=10, min_samples_split=5, n_estimators=200; total time=   0.4s
[CV] END max_depth=10, min_samples_split=5, n_estimators=200; total time=   0.4s
[CV] END max_depth=10, min_samples_split=12, n_estimators=100; total time=   0.2s
[CV] END max_depth=10, min_samples_split=12, n_estimators=100; total time=   0.2s
[CV] END max_depth=10, min_samples_split=12, n_estimators=100; total time=   0.2s
[CV] END max_depth=10, min_samples_split=12, n_estimators=200; total time=   0.4s
[CV] END max_depth=10, min_samples_split=12, n_estimators=300; total time=   0.6s
[CV] END max_depth=10, min_samples_split=12, n_estimators=300; total time=   0.6s
[CV] END max_depth=20, min_samples_split=2, n_estimators=200; total time=   0.4s
[CV] END max_depth=20, min_samples_split=2, n_estimators=200; total time=   0.4s
[CV] END max_depth=20, min_samples_split=5, n_estimators=100; total time=   0.2s
[CV] END max_depth=20, min_samples_split=5, n_estimators=100; total time=   0.2s
[CV] END max_depth=20, min_samples_split=5, n_estimators=200; total time=   0.4s
[CV] END max_depth=20, min_samples_split=5, n_estimators=200; total time=   0.4s
[CV] END max_depth=20, min_samples_split=5, n_estimators=300; total time=   0.6s
[CV] END max_depth=20, min_samples_split=12, n_estimators=100; total time=   0.2s
[CV] END max_depth=20, min_samples_split=12, n_estimators=200; total time=   0.4s
[CV] END max_depth=20, min_samples_split=12, n_estimators=200; total time=   0.4s
[CV] END max_depth=30, min_samples_split=2, n_estimators=100; total time=   0.2s
[CV] END max_depth=30, min_samples_split=2, n_estimators=100; total time=   0.2s
[CV] END max_depth=30, min_samples_split=2, n_estimators=100; total time=   0.2s
[CV] END max_depth=30, min_samples_split=2, n_estimators=200; total time=   0.4s
[CV] END max_depth=30, min_samples_split=2, n_estimators=300; total time=   0.6s
[CV] END max_depth=30, min_samples_split=2, n_estimators=300; total time=   0.6s
[CV] END max_depth=30, min_samples_split=5, n_estimators=200; total time=   0.4s
[CV] END max_depth=30, min_samples_split=5, n_estimators=300; total time=   0.6s
[CV] END max_depth=30, min_samples_split=12, n_estimators=100; total time=   0.2s
[CV] END max_depth=30, min_samples_split=12, n_estimators=100; total time=   0.2s
Mean Squared Error: 3.3786967277771405
#+end_example



#+begin_src jupyter-python :kernel iotvar_powerprofiler
import matplotlib.pyplot as plt
from mpl_toolkits.mplot3d import Axes3D
import numpy as np

# Assuming X_test and Z_test are your test data and Z_pred are the predicted values

fig = plt.figure()
fig.set_size_inches(25, 25)
ax = fig.add_subplot(111, projection='3d')

# Scatter plot of the actual data points
ax.scatter(X_test[:, 0], X_test[:, 1], Z_test, color='blue', label='Actual')

# Create a grid of values for the surface plot
x_range = np.linspace(X_test[:, 0].min(), X_test[:, 0].max(), 100)
y_range = np.linspace(X_test[:, 1].min(), X_test[:, 1].max(), 100)
x_grid, y_grid = np.meshgrid(x_range, y_range)
xy_grid = np.c_[x_grid.ravel(), y_grid.ravel()]

# Predict z values for the grid
z_grid_pred = best_rf.predict(xy_grid).reshape(x_grid.shape)

# Surface plot of the predicted values

ax.plot_surface(x_grid, y_grid, z_grid_pred, color='orange', alpha=0.5, label='Predicted')

ax.set_xlabel("Refresh time $R_{G}$", fontsize=50, labelpad=30)
ax.set_ylabel("Number of sensors in group $nb_{V_{G}}$", fontsize=50, labelpad=35)
ax.zaxis.set_rotate_label(False)
ax.set_zlabel("Intercept $b$", fontsize=50, labelpad=25, rotation=90)
ax.tick_params(labelsize=40)
ax.view_init(10, 20)
plt.tight_layout()
ax.legend()
plt.show()

#+end_src

#+RESULTS:
[[./.ob-jupyter/d68efb930562fd678e0456c26137f43b8455e818.png]]

#+begin_src jupyter-python :kernel iotvar_powerprofiler
Z_pred = best_rf.predict(X_test)

# Plot X vs Z
plt.figure(figsize=(14, 6),dpi=200)


plt.subplot(1, 2, 1)
plt.scatter(X_test[:, 0], Z_test, color='blue', label='Actual')
plt.scatter(X_test[:, 0], Z_pred, color='red', label='Predicted', marker='x')
plt.xlabel("Refresh time $R_{G}$")
plt.ylabel("Intercept $b$")
plt.title('$R_{G}$ vs $b$')
plt.legend()

# Plot Y vs Z
plt.subplot(1, 2, 2)
plt.scatter(X_test[:, 1], Z_test, color='blue', label='Actual')
plt.scatter(X_test[:, 1], Z_pred, color='red', label='Predicted', marker='x')
plt.xlabel("Number of sensors in group $nb_{V_{G}}$")
plt.ylabel("Intercept $b$")
plt.title('$nb_{V_{G}}$ vs $b$')
plt.legend()

plt.tight_layout()
plt.show()
#+end_src

#+RESULTS:
[[./.ob-jupyter/ef974490d0e765fe66c57caaa81d34b8afaf484a.png]]
* XGBoost Regression
** Slope m
#+begin_src jupyter-python :kernel iotvar_powerprofiler
import xgboost as xgb
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error

# Assuming X and Z are your features and target variables
X = np.zeros([len(m_b_df['number_sensors']),2])
X[:,0] = np.array(m_b_df['refresh_period'])
X[:,1] = np.array(m_b_df['number_sensors'])

Z = np.array(m_b_df['m'])

# Split the data into training and testing sets
X_train, X_test, Z_train, Z_test = train_test_split(X, Z, test_size=0.2, random_state=42)

# Initialize XGBoost regressor
xgb_reg = xgb.XGBRegressor(objective='reg:squarederror', n_estimators=100, max_depth=3, learning_rate=0.1)

# Train the model
xgb_reg.fit(X_train, Z_train)

# Predict on test set
Z_pred = xgb_reg.predict(X_test)

# Evaluate model performance
mse = mean_squared_error(Z_test, Z_pred)
print(f"Mean Squared Error: {mse}")
#+end_src

#+RESULTS:
: Mean Squared Error: 0.00042853380111642215

#+begin_src jupyter-python :kernel iotvar_powerprofiler
import matplotlib.pyplot as plt
from mpl_toolkits.mplot3d import Axes3D
import numpy as np

# 3D Scatter plot for Actual and Predicted values
fig = plt.figure(figsize=(25, 25))
ax = fig.add_subplot(111, projection='3d')

# Scatter plot of the actual data points
ax.scatter(X_test[:, 0], X_test[:, 1], Z_test, color='blue', label='Actual',s=250)

# Scatter plot of the predicted data points
#ax.scatter(X_test[:, 0], X_test[:, 1], Z_pred, color='red', label='Predicted', marker='^')

x_range = np.linspace(X_test[:, 0].min(), X_test[:, 0].max(), 100)
y_range = np.linspace(X_test[:, 1].min(), X_test[:, 1].max(), 100)
x_grid, y_grid = np.meshgrid(x_range, y_range)
xy_grid = np.c_[x_grid.ravel(), y_grid.ravel()]

# Predict z values for the grid
z_grid_pred = xgb_reg.predict(xy_grid).reshape(x_grid.shape)

# Surface plot of the predicted values

ax.plot_surface(x_grid, y_grid, z_grid_pred, color='orange', alpha=0.5, label='Predicted')


ax.set_xlabel("Refresh time $R_{G}$", fontsize=50, labelpad=30)
ax.set_ylabel("Number of sensors in group $nb_{V_{G}}$", fontsize=50, labelpad=35)
ax.zaxis.set_rotate_label(False)
ax.set_zlabel("Slope $m$", fontsize=50, labelpad=25, rotation=90)
ax.tick_params(labelsize=40)
ax.view_init(10, 20)
ax.set_title("XGBoost", fontsize=60)
ax.legend(prop={'size': 40})
plt.tight_layout()
plt.show()
#+end_src

#+RESULTS:
[[./.ob-jupyter/faf9ae92a909d22ccbc04ae0f0d10ced8707c8ab.png]]

#+begin_src jupyter-python :kernel iotvar_powerprofiler
plt.figure(figsize=(14, 6))

plt.subplot(1, 2, 1)
plt.scatter(X_test[:, 0], Z_test, color='blue', label='Actual')
plt.scatter(X_test[:, 0], Z_pred, color='red', label='Predicted', marker='x')
plt.xlabel("Refresh time $R_{G}$")
plt.ylabel("Slope $m$")
plt.title('$R_{G}$ vs $m$')
plt.legend()

# Plot Y vs Z
plt.subplot(1, 2, 2)
plt.scatter(X_test[:, 1], Z_test, color='blue', label='Actual')
plt.scatter(X_test[:, 1], Z_pred, color='red', label='Predicted', marker='x')
plt.xlabel("Number of sensors in group $nb_{V_{G}}$")
plt.ylabel("Slope $m$")
plt.title('$nb_{V_{G}}$ vs $m$')
plt.legend()

plt.tight_layout()
plt.show()
#+end_src

#+RESULTS:
[[./.ob-jupyter/b9f2915ff57ed3707cb005bcf3057346109fd650.png]]

*** Benchmarking individual XGBoost

#+begin_src jupyter-python :kernel iotvar_powerprofiler
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score
mae = mean_absolute_error(Z_test, Z_pred)
mse = mean_squared_error(Z_test, Z_pred)
r2 = r2_score(Z_test, Z_pred)

print(f"Mean Absolute Error: {mae}")
print(f"Mean Squared Error: {mse}")
print(f"R-squared: {r2}")

# 2. Feature Importance
# Assuming you have trained model named `xgb_model`

xgb.plot_importance(xgb_reg)
plt.title('Feature Importance')
plt.show()

# 3. Visualization
# Scatter plot of Actual vs Predicted
comparison_df = pd.DataFrame({'Actual': Z_test, 'Predicted': Z_pred})
plt.figure(figsize=(12, 6))
sns.scatterplot(x='Actual', y='Predicted', data=comparison_df)
plt.title('Actual vs Predicted b Values')
plt.xlabel('Actual b')
plt.ylabel('Predicted b')
plt.plot([comparison_df['Actual'].min(), comparison_df['Actual'].max()],
         [comparison_df['Actual'].min(), comparison_df['Actual'].max()],
         color='red', linestyle='--')
plt.show()

# Residual plot
residuals = Z_test - Z_pred
plt.figure(figsize=(12, 6))
sns.histplot(residuals, kde=True)
plt.title('Residuals Distribution')
plt.xlabel('Residuals')
plt.ylabel('Frequency')
plt.show()
#+end_src

#+RESULTS:
:RESULTS:
: Mean Absolute Error: 0.01611495736188463
: Mean Squared Error: 0.00042853380111642215
: R-squared: 0.9857758739325319
#+attr_org: :width 728
[[./.ob-jupyter/ef4edf6510becd85039f6df52c05fac4815f4d8e.png]]
[[./.ob-jupyter/0b0f0d45577795c997a54b70c52c74f44fc90b11.png]]
[[./.ob-jupyter/df21345e69ffe524b17d4fec1f489a2541ce5826.png]]
:END:

** intersect b
#+begin_src jupyter-python :kernel iotvar_powerprofiler
import xgboost as xgb
X = np.zeros([len(m_b_df['number_sensors']),3])
X[:,0] = np.array(m_b_df['m'])
X[:,1] = np.array(m_b_df['refresh_period'])
X[:,2] = np.array(m_b_df['number_sensors'])

Z = np.array(m_b_df['b'])

# Split the data into training and testing sets
X_train, X_test, Z_train, Z_test = train_test_split(X, Z, test_size=0.2, random_state=42)

# Initialize XGBoost regressor
xgb_reg = xgb.XGBRegressor(objective='reg:squarederror', n_estimators=16, max_depth=6, learning_rate=0.1)

# Train the model
xgb_reg.fit(X_train, Z_train)

# Predict on test set
Z_pred = xgb_reg.predict(X_test)

z_pred_unscaled = scaler_y.inverse_transform(Z_pred.reshape(-1, 1))

# Evaluate model performance
mse = mean_squared_error(Z_test, Z_pred)
print(f"Mean Squared Error: {mse}")
#+end_src

#+RESULTS:
: Mean Squared Error: 3.8833231350956168

#+begin_src jupyter-python :kernel iotvar_powerprofiler
import matplotlib.pyplot as plt
from mpl_toolkits.mplot3d import Axes3D
import numpy as np

# 3D Scatter plot for Actual and Predicted values
fig = plt.figure(figsize=(25, 25))
ax = fig.add_subplot(111, projection='3d')

# Scatter plot of the actual data points
ax.scatter(X_test[:, 0], X_test[:, 1], Z_test, color='blue', label='Actual',s=250)

# Scatter plot of the predicted data points
#ax.scatter(X_test[:, 0], X_test[:, 1], Z_pred, color='red', label='Predicted', marker='^')

x_range = np.linspace(X_test[:, 0].min(), X_test[:, 0].max(), 100)
y_range = np.linspace(X_test[:, 1].min(), X_test[:, 1].max(), 100)
x_grid, y_grid = np.meshgrid(x_range, y_range)
xy_grid = np.c_[x_grid.ravel(), y_grid.ravel()]

# Predict z values for the grid
z_grid_pred = xgb_reg.predict(xy_grid).reshape(x_grid.shape)

# Surface plot of the predicted values

ax.plot_surface(x_grid, y_grid, z_grid_pred, color='orange', alpha=0.5, label='Predicted')

ax.set_xlabel("Refresh time $R_{G}$", fontsize=40, labelpad=30)
ax.set_ylabel("Number of sensors in group $nb_{V_{G}}$", fontsize=40, labelpad=35)
ax.set_zlabel("Intercept $b$", fontsize=40, labelpad=25, rotation=90)
ax.zaxis.set_rotate_label(False)
ax.tick_params(labelsize=40)
ax.view_init(10, 20)
ax.set_title("XGBoost", fontsize=60)
plt.tight_layout()
ax.legend(prop={'size': 40})
plt.show()
#+end_src

#+RESULTS:
[[./.ob-jupyter/d780cf4362e03708dae07a2688d7851305fa611a.png]]


#+begin_src jupyter-python :kernel iotvar_powerprofiler
plt.figure(figsize=(21, 6))

plt.subplot(1, 3, 1)
plt.scatter(X_test[:,0], Z_test, color='blue', label='Actual')
plt.scatter(X_test[:,0], Z_pred, color='red', label='Predicted', marker='x')
plt.xlabel("slope m")
plt.ylabel("Intercept $b$")
plt.title('$R_{G}$ vs $m$')
plt.legend()

# Plot Y vs Z
plt.subplot(1, 3, 2)
plt.scatter(X_test[:, 1], Z_test, color='blue', label='Actual')
plt.scatter(X_test[:, 1], Z_pred, color='red', label='Predicted', marker='x')
plt.xlabel("Refresh time $R_{G}$")
plt.ylabel("Intercept $b$")
plt.title('$nb_{V_{G}}$ vs $b$')
plt.legend()

plt.subplot(1, 3, 3)
plt.scatter(X_test[:, 2], Z_test, color='blue', label='Actual')
plt.scatter(X_test[:, 2], Z_pred, color='red', label='Predicted', marker='x')
plt.xlabel("Number Sensors")
plt.ylabel("Intercept $b$")
plt.title('Number_sensors vs $b$')
plt.legend()


plt.tight_layout()
plt.show()
#+end_src

#+RESULTS:
[[./.ob-jupyter/6cb0eea8af74bd93940fcd6ee9aeb4c641a81ab7.png]]

#+begin_src jupyter-python :kernel iotvar_powerprofiler :results silent
import xgboost as xgb
import optuna
from sklearn.metrics import mean_squared_error
from sklearn.preprocessing import StandardScaler

# Create feature matrix and target vector
X = np.zeros([len(m_b_df['number_sensors']), 3])
X[:, 0] = np.array(m_b_df['m'])
X[:, 1] = np.array(m_b_df['refresh_period'])
X[:, 2] = np.array(m_b_df['number_sensors'])

Z = np.array(m_b_df['b'])

# Split the data into training and testing sets
X_train, X_test, Z_train, Z_test = train_test_split(X, Z, test_size=0.2, random_state=42)

# Initialize StandardScaler
scaler = StandardScaler()
X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)

# Define the objective function for Optuna
def objective(trial):
    param = {
        'objective': 'reg:squarederror',
        'n_estimators': trial.suggest_int('n_estimators', 2, 500),
        'max_depth': trial.suggest_int('max_depth', 2, 10),
        'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.2),
        'subsample': trial.suggest_float('subsample', 0.6, 1.0),
        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.6, 1.0),
        'alpha': trial.suggest_loguniform('alpha', 1e-8, 1.0),
        'lambda': trial.suggest_loguniform('lambda', 1e-8, 1.0),
        'gamma': trial.suggest_loguniform('gamma', 1e-8, 1.0)
    }

    xgb_reg = xgb.XGBRegressor(**param)
    xgb_reg.fit(X_train, Z_train, eval_set=[(X_test, Z_test)], early_stopping_rounds=10, verbose=False)

    Z_pred = xgb_reg.predict(X_test)
    mse = mean_squared_error(Z_test, Z_pred)
    return mse

# Run the optimization
study = optuna.create_study(direction='minimize')
study.optimize(objective, n_trials=500, timeout=600)

# Train the model with the best parameters
best_params = study.best_params
best_xgb_reg = xgb.XGBRegressor(**best_params)
best_xgb_reg.fit(X_train, Z_train)

# Predict on test set
Z_pred = best_xgb_reg.predict(X_test)

# Evaluate model performance
mse = mean_squared_error(Z_test, Z_pred)
print(f"Mean Squared Error: {mse}")
#+end_src

#+RESULTS:
#+begin_example
Fitting 3 folds for each of 100 candidates, totalling 300 fits
/home/han4n/anaconda3/envs/IoTVar_PowerProfiler/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5
  warnings.warn(f"A NumPy version >={np_minversion} and <{np_maxversion}"
/home/han4n/anaconda3/envs/IoTVar_PowerProfiler/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5
  warnings.warn(f"A NumPy version >={np_minversion} and <{np_maxversion}"
/home/han4n/anaconda3/envs/IoTVar_PowerProfiler/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5
  warnings.warn(f"A NumPy version >={np_minversion} and <{np_maxversion}"
/home/han4n/anaconda3/envs/IoTVar_PowerProfiler/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5
  warnings.warn(f"A NumPy version >={np_minversion} and <{np_maxversion}"
[CV] END colsample_bytree=0.9, learning_rate=0.01, max_depth=3, n_estimators=50, subsample=0.7; total time=   0.0s
[CV] END colsample_bytree=0.7, learning_rate=0.2, max_depth=10, n_estimators=100, subsample=0.6; total time=   0.2s
[CV] END colsample_bytree=0.6, learning_rate=0.1, max_depth=3, n_estimators=200, subsample=0.7; total time=   0.1s
[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=10, n_estimators=50, subsample=0.6; total time=   0.1s
[CV] END colsample_bytree=0.7, learning_rate=0.2, max_depth=5, n_estimators=100, subsample=0.8; total time=   0.1s
[CV] END colsample_bytree=0.8, learning_rate=0.05, max_depth=9, n_estimators=50, subsample=0.7; total time=   0.1s
[CV] END colsample_bytree=0.9, learning_rate=0.1, max_depth=7, n_estimators=200, subsample=0.9; total time=   0.1s
[CV] END colsample_bytree=0.6, learning_rate=0.15, max_depth=6, n_estimators=50, subsample=0.9; total time=   0.0s
[CV] END colsample_bytree=1.0, learning_rate=0.05, max_depth=6, n_estimators=200, subsample=1.0; total time=   0.1s
[CV] END colsample_bytree=0.9, learning_rate=0.15, max_depth=9, n_estimators=50, subsample=1.0; total time=   0.0s
[CV] END colsample_bytree=0.9, learning_rate=0.15, max_depth=9, n_estimators=50, subsample=1.0; total time=   0.0s
[CV] END colsample_bytree=0.6, learning_rate=0.01, max_depth=6, n_estimators=100, subsample=0.8; total time=   0.0s
[CV] END colsample_bytree=0.7, learning_rate=0.01, max_depth=5, n_estimators=200, subsample=1.0; total time=   0.1s
[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=8, n_estimators=100, subsample=0.9; total time=   0.1s
[CV] END colsample_bytree=1.0, learning_rate=0.15, max_depth=4, n_estimators=50, subsample=0.7; total time=   0.0s
[CV] END colsample_bytree=0.7, learning_rate=0.1, max_depth=7, n_estimators=50, subsample=0.6; total time=   0.0s
[CV] END colsample_bytree=0.7, learning_rate=0.1, max_depth=7, n_estimators=50, subsample=0.6; total time=   0.0s
[CV] END colsample_bytree=0.6, learning_rate=0.15, max_depth=10, n_estimators=100, subsample=0.8; total time=   0.1s
[CV] END colsample_bytree=0.6, learning_rate=0.15, max_depth=10, n_estimators=100, subsample=0.8; total time=   0.1s
[CV] END colsample_bytree=0.6, learning_rate=0.15, max_depth=10, n_estimators=100, subsample=0.8; total time=   0.1s
[CV] END colsample_bytree=0.6, learning_rate=0.01, max_depth=5, n_estimators=200, subsample=1.0; total time=   0.1s
[CV] END colsample_bytree=0.6, learning_rate=0.01, max_depth=5, n_estimators=200, subsample=1.0; total time=   0.1s
[CV] END colsample_bytree=0.7, learning_rate=0.1, max_depth=7, n_estimators=200, subsample=0.8; total time=   0.2s
[CV] END colsample_bytree=0.7, learning_rate=0.1, max_depth=7, n_estimators=200, subsample=0.8; total time=   0.1s
[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=4, n_estimators=50, subsample=0.6; total time=   0.0s
[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=4, n_estimators=50, subsample=0.6; total time=   0.0s
[CV] END colsample_bytree=1.0, learning_rate=0.05, max_depth=8, n_estimators=100, subsample=0.9; total time=   0.1s
[CV] END colsample_bytree=1.0, learning_rate=0.05, max_depth=8, n_estimators=100, subsample=0.9; total time=   0.2s
[CV] END colsample_bytree=0.7, learning_rate=0.15, max_depth=6, n_estimators=50, subsample=0.6; total time=   0.0s
[CV] END colsample_bytree=0.7, learning_rate=0.15, max_depth=6, n_estimators=50, subsample=0.6; total time=   0.0s
[CV] END colsample_bytree=0.8, learning_rate=0.15, max_depth=10, n_estimators=50, subsample=0.6; total time=   0.1s
[CV] END colsample_bytree=0.8, learning_rate=0.15, max_depth=10, n_estimators=50, subsample=0.6; total time=   0.1s
[CV] END colsample_bytree=0.6, learning_rate=0.1, max_depth=6, n_estimators=100, subsample=0.7; total time=   0.1s
[CV] END colsample_bytree=0.6, learning_rate=0.1, max_depth=6, n_estimators=100, subsample=0.7; total time=   0.0s
[CV] END colsample_bytree=0.6, learning_rate=0.1, max_depth=6, n_estimators=100, subsample=0.7; total time=   0.1s
[CV] END colsample_bytree=0.7, learning_rate=0.05, max_depth=7, n_estimators=50, subsample=0.7; total time=   0.0s
[CV] END colsample_bytree=0.9, learning_rate=0.1, max_depth=9, n_estimators=200, subsample=1.0; total time=   0.3s
[CV] END colsample_bytree=0.6, learning_rate=0.1, max_depth=8, n_estimators=100, subsample=0.8; total time=   0.1s
[CV] END colsample_bytree=0.6, learning_rate=0.05, max_depth=7, n_estimators=200, subsample=1.0; total time=   0.1s
[CV] END colsample_bytree=0.6, learning_rate=0.05, max_depth=7, n_estimators=200, subsample=1.0; total time=   0.1s
[CV] END colsample_bytree=0.6, learning_rate=0.15, max_depth=5, n_estimators=50, subsample=0.9; total time=   0.0s
[CV] END colsample_bytree=0.6, learning_rate=0.15, max_depth=5, n_estimators=50, subsample=0.9; total time=   0.0s
[CV] END colsample_bytree=0.8, learning_rate=0.15, max_depth=4, n_estimators=100, subsample=0.9; total time=   0.0s
[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=10, n_estimators=50, subsample=0.8; total time=   0.1s
[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=4, n_estimators=200, subsample=0.6; total time=   0.1s
[CV] END colsample_bytree=0.6, learning_rate=0.01, max_depth=3, n_estimators=200, subsample=1.0; total time=   0.1s
[CV] END colsample_bytree=0.8, learning_rate=0.15, max_depth=5, n_estimators=200, subsample=0.6; total time=   0.1s
[CV] END colsample_bytree=0.8, learning_rate=0.15, max_depth=5, n_estimators=200, subsample=0.6; total time=   0.1s
[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=4, n_estimators=50, subsample=0.9; total time=   0.0s
[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=4, n_estimators=50, subsample=0.9; total time=   0.0s
[CV] END colsample_bytree=0.6, learning_rate=0.05, max_depth=5, n_estimators=50, subsample=0.8; total time=   0.0s
[CV] END colsample_bytree=0.6, learning_rate=0.05, max_depth=5, n_estimators=50, subsample=0.8; total time=   0.0s
[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=4, n_estimators=100, subsample=0.7; total time=   0.1s
[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=4, n_estimators=100, subsample=0.7; total time=   0.1s
[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=100, subsample=0.9; total time=   0.0s
[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=100, subsample=0.9; total time=   0.1s
[CV] END colsample_bytree=0.7, learning_rate=0.01, max_depth=10, n_estimators=200, subsample=0.9; total time=   0.3s
[CV] END colsample_bytree=0.7, learning_rate=0.01, max_depth=3, n_estimators=200, subsample=0.8; total time=   0.1s
[CV] END colsample_bytree=0.6, learning_rate=0.01, max_depth=6, n_estimators=100, subsample=0.7; total time=   0.0s
[CV] END colsample_bytree=0.7, learning_rate=0.2, max_depth=10, n_estimators=200, subsample=0.6; total time=   0.2s
[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=6, n_estimators=100, subsample=0.7; total time=   0.1s
[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=6, n_estimators=100, subsample=0.7; total time=   0.1s
[CV] END colsample_bytree=0.6, learning_rate=0.2, max_depth=5, n_estimators=200, subsample=0.7; total time=   0.1s
[CV] END colsample_bytree=0.6, learning_rate=0.2, max_depth=5, n_estimators=200, subsample=0.7; total time=   0.1s
[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=10, n_estimators=50, subsample=0.9; total time=   0.1s
[CV] END colsample_bytree=0.9, learning_rate=0.05, max_depth=3, n_estimators=50, subsample=0.7; total time=   0.0s
[CV] END colsample_bytree=0.7, learning_rate=0.01, max_depth=9, n_estimators=100, subsample=0.6; total time=   0.1s
[CV] END colsample_bytree=0.7, learning_rate=0.01, max_depth=9, n_estimators=100, subsample=0.6; total time=   0.1s
[CV] END colsample_bytree=0.9, learning_rate=0.15, max_depth=10, n_estimators=100, subsample=0.8; total time=   0.1s
[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=8, n_estimators=100, subsample=0.8; total time=   0.1s
[CV] END colsample_bytree=0.7, learning_rate=0.2, max_depth=10, n_estimators=100, subsample=0.6; total time=   0.3s
[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=10, n_estimators=50, subsample=0.6; total time=   0.1s
[CV] END colsample_bytree=0.7, learning_rate=0.2, max_depth=5, n_estimators=100, subsample=0.8; total time=   0.1s
[CV] END colsample_bytree=0.8, learning_rate=0.05, max_depth=9, n_estimators=50, subsample=0.7; total time=   0.1s
[CV] END colsample_bytree=0.9, learning_rate=0.1, max_depth=7, n_estimators=200, subsample=0.9; total time=   0.2s
[CV] END colsample_bytree=1.0, learning_rate=0.05, max_depth=6, n_estimators=200, subsample=1.0; total time=   0.1s
[CV] END colsample_bytree=0.6, learning_rate=0.01, max_depth=6, n_estimators=100, subsample=0.8; total time=   0.1s
[CV] END colsample_bytree=0.7, learning_rate=0.01, max_depth=5, n_estimators=200, subsample=1.0; total time=   0.1s
[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=8, n_estimators=100, subsample=0.9; total time=   0.1s
[CV] END colsample_bytree=0.7, learning_rate=0.1, max_depth=7, n_estimators=50, subsample=0.6; total time=   0.0s
[CV] END colsample_bytree=0.7, learning_rate=0.15, max_depth=10, n_estimators=100, subsample=0.9; total time=   0.1s
[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=9, n_estimators=100, subsample=0.9; total time=   0.2s
[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=9, n_estimators=100, subsample=0.9; total time=   0.1s
[CV] END colsample_bytree=0.6, learning_rate=0.1, max_depth=6, n_estimators=50, subsample=1.0; total time=   0.0s
[CV] END colsample_bytree=0.6, learning_rate=0.1, max_depth=6, n_estimators=50, subsample=1.0; total time=   0.0s
[CV] END colsample_bytree=0.9, learning_rate=0.1, max_depth=5, n_estimators=200, subsample=0.9; total time=   0.1s
[CV] END colsample_bytree=0.9, learning_rate=0.1, max_depth=5, n_estimators=200, subsample=0.9; total time=   0.1s
[CV] END colsample_bytree=0.8, learning_rate=0.05, max_depth=5, n_estimators=200, subsample=0.6; total time=   0.1s
[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=4, n_estimators=50, subsample=0.6; total time=   0.0s
[CV] END colsample_bytree=0.6, learning_rate=0.1, max_depth=6, n_estimators=200, subsample=0.7; total time=   0.1s
[CV] END colsample_bytree=0.6, learning_rate=0.1, max_depth=6, n_estimators=200, subsample=0.7; total time=   0.1s
[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=5, n_estimators=200, subsample=0.7; total time=   0.1s
[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=5, n_estimators=200, subsample=0.7; total time=   0.1s
[CV] END colsample_bytree=1.0, learning_rate=0.15, max_depth=9, n_estimators=50, subsample=0.7; total time=   0.1s
[CV] END colsample_bytree=1.0, learning_rate=0.15, max_depth=9, n_estimators=50, subsample=0.7; total time=   0.1s
[CV] END colsample_bytree=0.9, learning_rate=0.1, max_depth=9, n_estimators=200, subsample=1.0; total time=   0.2s
[CV] END colsample_bytree=0.9, learning_rate=0.1, max_depth=9, n_estimators=200, subsample=1.0; total time=   0.2s
[CV] END colsample_bytree=0.6, learning_rate=0.05, max_depth=7, n_estimators=200, subsample=1.0; total time=   0.1s
[CV] END colsample_bytree=0.6, learning_rate=0.01, max_depth=7, n_estimators=50, subsample=0.9; total time=   0.0s
[CV] END colsample_bytree=0.7, learning_rate=0.05, max_depth=3, n_estimators=100, subsample=0.8; total time=   0.0s
[CV] END colsample_bytree=0.7, learning_rate=0.05, max_depth=3, n_estimators=100, subsample=0.8; total time=   0.1s
[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=4, n_estimators=200, subsample=0.6; total time=   0.1s
[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=4, n_estimators=200, subsample=0.6; total time=   0.2s
[CV] END colsample_bytree=0.7, learning_rate=0.2, max_depth=3, n_estimators=200, subsample=0.6; total time=   0.1s
[CV] END colsample_bytree=0.9, learning_rate=0.1, max_depth=7, n_estimators=200, subsample=0.7; total time=   0.2s
[CV] END colsample_bytree=0.6, learning_rate=0.05, max_depth=8, n_estimators=100, subsample=0.9; total time=   0.1s
[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=4, n_estimators=50, subsample=0.9; total time=   0.0s
[CV] END colsample_bytree=0.8, learning_rate=0.05, max_depth=5, n_estimators=100, subsample=1.0; total time=   0.0s
[CV] END colsample_bytree=0.8, learning_rate=0.05, max_depth=5, n_estimators=100, subsample=1.0; total time=   0.0s
[CV] END colsample_bytree=0.7, learning_rate=0.05, max_depth=6, n_estimators=100, subsample=0.8; total time=   0.1s
[CV] END colsample_bytree=0.7, learning_rate=0.05, max_depth=6, n_estimators=100, subsample=0.8; total time=   0.1s
[CV] END colsample_bytree=0.7, learning_rate=0.15, max_depth=5, n_estimators=200, subsample=0.7; total time=   0.1s
[CV] END colsample_bytree=0.7, learning_rate=0.15, max_depth=5, n_estimators=200, subsample=0.7; total time=   0.1s
[CV] END colsample_bytree=0.7, learning_rate=0.1, max_depth=3, n_estimators=50, subsample=0.8; total time=   0.0s
[CV] END colsample_bytree=0.7, learning_rate=0.1, max_depth=3, n_estimators=50, subsample=0.8; total time=   0.0s
[CV] END colsample_bytree=0.7, learning_rate=0.1, max_depth=3, n_estimators=50, subsample=0.8; total time=   0.0s
[CV] END colsample_bytree=0.6, learning_rate=0.1, max_depth=4, n_estimators=200, subsample=0.7; total time=   0.1s
[CV] END colsample_bytree=0.6, learning_rate=0.01, max_depth=6, n_estimators=100, subsample=0.7; total time=   0.0s
[CV] END colsample_bytree=0.6, learning_rate=0.01, max_depth=6, n_estimators=100, subsample=0.7; total time=   0.0s
[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=7, n_estimators=200, subsample=0.6; total time=   0.1s
[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=7, n_estimators=200, subsample=0.6; total time=   0.1s
[CV] END colsample_bytree=0.8, learning_rate=0.15, max_depth=4, n_estimators=100, subsample=0.8; total time=   0.0s
[CV] END colsample_bytree=0.8, learning_rate=0.15, max_depth=4, n_estimators=100, subsample=0.8; total time=   0.1s
[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=3, n_estimators=200, subsample=1.0; total time=   0.1s
[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=3, n_estimators=200, subsample=1.0; total time=   0.1s
[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=10, n_estimators=50, subsample=0.9; total time=   0.1s
[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=10, n_estimators=50, subsample=0.9; total time=   0.1s
[CV] END colsample_bytree=0.9, learning_rate=0.2, max_depth=6, n_estimators=100, subsample=0.8; total time=   0.1s
[CV] END colsample_bytree=0.9, learning_rate=0.2, max_depth=6, n_estimators=100, subsample=0.8; total time=   0.1s
[CV] END colsample_bytree=0.9, learning_rate=0.2, max_depth=6, n_estimators=100, subsample=0.8; total time=   0.1s
[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=8, n_estimators=100, subsample=1.0; total time=   0.1s
[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=8, n_estimators=100, subsample=0.8; total time=   0.1s
[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=8, n_estimators=100, subsample=0.8; total time=   0.1s
[CV] END colsample_bytree=0.7, learning_rate=0.05, max_depth=7, n_estimators=200, subsample=1.0; total time=   0.1s
[CV] END colsample_bytree=0.9, learning_rate=0.01, max_depth=4, n_estimators=100, subsample=0.6; total time=   0.0s
[CV] END colsample_bytree=0.6, learning_rate=0.05, max_depth=4, n_estimators=100, subsample=1.0; total time=   0.0s
[CV] END colsample_bytree=0.6, learning_rate=0.05, max_depth=4, n_estimators=100, subsample=1.0; total time=   0.0s
[CV] END colsample_bytree=1.0, learning_rate=0.05, max_depth=3, n_estimators=100, subsample=0.6; total time=   0.0s
[CV] END colsample_bytree=1.0, learning_rate=0.05, max_depth=3, n_estimators=100, subsample=0.6; total time=   0.0s
[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=8, n_estimators=50, subsample=0.8; total time=   0.1s
[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=3, n_estimators=50, subsample=0.7; total time=   0.0s[CV] END colsample_bytree=0.9, learning_rate=0.01, max_depth=3, n_estimators=50, subsample=0.7; total time=   0.0s
[CV] END colsample_bytree=0.9, learning_rate=0.01, max_depth=4, n_estimators=50, subsample=0.8; total time=   0.1s
[CV] END colsample_bytree=0.9, learning_rate=0.01, max_depth=4, n_estimators=50, subsample=0.8; total time=   0.0s
[CV] END colsample_bytree=0.9, learning_rate=0.01, max_depth=4, n_estimators=50, subsample=0.8; total time=   0.1s
[CV] END colsample_bytree=0.6, learning_rate=0.1, max_depth=3, n_estimators=200, subsample=0.7; total time=   0.1s
[CV] END colsample_bytree=0.7, learning_rate=0.2, max_depth=5, n_estimators=100, subsample=0.8; total time=   0.1s
[CV] END colsample_bytree=0.8, learning_rate=0.05, max_depth=9, n_estimators=50, subsample=0.7; total time=   0.1s
[CV] END colsample_bytree=0.6, learning_rate=0.15, max_depth=6, n_estimators=50, subsample=0.9; total time=   0.0s
[CV] END colsample_bytree=0.6, learning_rate=0.15, max_depth=6, n_estimators=50, subsample=0.9; total time=   0.0s
[CV] END colsample_bytree=1.0, learning_rate=0.05, max_depth=6, n_estimators=200, subsample=1.0; total time=   0.2s
[CV] END colsample_bytree=0.7, learning_rate=0.01, max_depth=5, n_estimators=200, subsample=1.0; total time=   0.2s
[CV] END colsample_bytree=1.0, learning_rate=0.15, max_depth=4, n_estimators=50, subsample=0.7; total time=   0.0s
[CV] END colsample_bytree=0.7, learning_rate=0.15, max_depth=10, n_estimators=100, subsample=0.9; total time=   0.2s
[CV] END colsample_bytree=1.0, learning_rate=0.05, max_depth=4, n_estimators=200, subsample=0.7; total time=   0.1s
[CV] END colsample_bytree=1.0, learning_rate=0.05, max_depth=4, n_estimators=200, subsample=0.7; total time=   0.1s
[CV] END colsample_bytree=0.6, learning_rate=0.01, max_depth=5, n_estimators=200, subsample=1.0; total time=   0.1s
[CV] END colsample_bytree=0.6, learning_rate=0.1, max_depth=6, n_estimators=50, subsample=1.0; total time=   0.0s
[CV] END colsample_bytree=0.7, learning_rate=0.1, max_depth=7, n_estimators=200, subsample=0.8; total time=   0.2s
[CV] END colsample_bytree=0.9, learning_rate=0.1, max_depth=5, n_estimators=200, subsample=0.9; total time=   0.1s
[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=4, n_estimators=200, subsample=0.7; total time=   0.1s
[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=4, n_estimators=200, subsample=0.7; total time=   0.1s
[CV] END colsample_bytree=0.6, learning_rate=0.1, max_depth=6, n_estimators=200, subsample=0.7; total time=   0.1s
[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=5, n_estimators=200, subsample=0.7; total time=   0.2s
[CV] END colsample_bytree=0.7, learning_rate=0.05, max_depth=4, n_estimators=200, subsample=0.7; total time=   0.1s
[CV] END colsample_bytree=0.7, learning_rate=0.05, max_depth=4, n_estimators=200, subsample=0.7; total time=   0.1s
[CV] END colsample_bytree=0.7, learning_rate=0.05, max_depth=7, n_estimators=50, subsample=0.7; total time=   0.0s
[CV] END colsample_bytree=0.7, learning_rate=0.05, max_depth=7, n_estimators=50, subsample=0.7; total time=   0.1s
[CV] END colsample_bytree=0.6, learning_rate=0.1, max_depth=8, n_estimators=100, subsample=0.8; total time=   0.1s
[CV] END colsample_bytree=0.6, learning_rate=0.1, max_depth=8, n_estimators=100, subsample=0.8; total time=   0.1s
[CV] END colsample_bytree=0.6, learning_rate=0.1, max_depth=6, n_estimators=200, subsample=0.9; total time=   0.1s
[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=9, n_estimators=100, subsample=0.9; total time=   0.2s
[CV] END colsample_bytree=0.6, learning_rate=0.15, max_depth=5, n_estimators=50, subsample=0.9; total time=   0.0s
[CV] END colsample_bytree=0.7, learning_rate=0.05, max_depth=3, n_estimators=100, subsample=0.8; total time=   0.1s
[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=10, n_estimators=50, subsample=0.8; total time=   0.1s
[CV] END colsample_bytree=0.8, learning_rate=0.1, max_depth=10, n_estimators=50, subsample=0.8; total time=   0.1s
[CV] END colsample_bytree=1.0, learning_rate=0.05, max_depth=6, n_estimators=50, subsample=0.8; total time=   0.0s
[CV] END colsample_bytree=1.0, learning_rate=0.05, max_depth=6, n_estimators=50, subsample=0.8; total time=   0.1s
[CV] END colsample_bytree=0.7, learning_rate=0.2, max_depth=3, n_estimators=200, subsample=0.6; total time=   0.1s
[CV] END colsample_bytree=0.7, learning_rate=0.2, max_depth=3, n_estimators=200, subsample=0.6; total time=   0.1s
[CV] END colsample_bytree=0.6, learning_rate=0.05, max_depth=8, n_estimators=100, subsample=0.9; total time=   0.1s
[CV] END colsample_bytree=0.6, learning_rate=0.05, max_depth=8, n_estimators=100, subsample=0.9; total time=   0.1s
[CV] END colsample_bytree=0.6, learning_rate=0.05, max_depth=5, n_estimators=50, subsample=0.8; total time=   0.0s
[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=4, n_estimators=100, subsample=0.7; total time=   0.1s
[CV] END colsample_bytree=0.8, learning_rate=0.05, max_depth=5, n_estimators=100, subsample=1.0; total time=   0.1s
[CV] END colsample_bytree=0.7, learning_rate=0.05, max_depth=6, n_estimators=100, subsample=0.8; total time=   0.1s
[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=5, n_estimators=100, subsample=0.9; total time=   0.1s
[CV] END colsample_bytree=0.7, learning_rate=0.15, max_depth=5, n_estimators=200, subsample=0.7; total time=   0.1s
[CV] END colsample_bytree=0.7, learning_rate=0.01, max_depth=3, n_estimators=200, subsample=0.8; total time=   0.1s
[CV] END colsample_bytree=0.7, learning_rate=0.01, max_depth=3, n_estimators=200, subsample=0.8; total time=   0.1s
[CV] END colsample_bytree=0.6, learning_rate=0.1, max_depth=4, n_estimators=200, subsample=0.7; total time=   0.1s
[CV] END colsample_bytree=0.6, learning_rate=0.1, max_depth=4, n_estimators=200, subsample=0.7; total time=   0.1s
[CV] END colsample_bytree=0.7, learning_rate=0.2, max_depth=10, n_estimators=200, subsample=0.6; total time=   0.2s
[CV] END colsample_bytree=0.7, learning_rate=0.2, max_depth=10, n_estimators=200, subsample=0.6; total time=   0.3s
[CV] END colsample_bytree=0.8, learning_rate=0.2, max_depth=3, n_estimators=200, subsample=1.0; total time=   0.1s
[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=4, n_estimators=100, subsample=0.9; total time=   0.0s
[CV] END colsample_bytree=0.6, learning_rate=0.01, max_depth=9, n_estimators=200, subsample=0.8; total time=   0.1s
[CV] END colsample_bytree=0.6, learning_rate=0.01, max_depth=9, n_estimators=200, subsample=0.8; total time=   0.1s
[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=8, n_estimators=100, subsample=1.0; total time=   0.1s
[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=8, n_estimators=100, subsample=1.0; total time=   0.1s
[CV] END colsample_bytree=0.9, learning_rate=0.01, max_depth=5, n_estimators=200, subsample=0.8; total time=   0.1s
[CV] END colsample_bytree=0.9, learning_rate=0.01, max_depth=5, n_estimators=200, subsample=0.8; total time=   0.1s
[CV] END colsample_bytree=0.9, learning_rate=0.05, max_depth=8, n_estimators=100, subsample=0.7; total time=   0.1s
[CV] END colsample_bytree=0.9, learning_rate=0.05, max_depth=8, n_estimators=100, subsample=0.7; total time=   0.1s
[CV] END colsample_bytree=1.0, learning_rate=0.05, max_depth=3, n_estimators=100, subsample=0.6; total time=   0.0s
[CV] END colsample_bytree=0.8, learning_rate=0.05, max_depth=3, n_estimators=200, subsample=0.6; total time=   0.1s
[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=3, n_estimators=50, subsample=0.7; total time=   0.0s
[CV] END colsample_bytree=1.0, learning_rate=0.2, max_depth=3, n_estimators=50, subsample=0.7; total time=   0.0s
[CV] END colsample_bytree=0.6, learning_rate=0.1, max_depth=8, n_estimators=100, subsample=0.7; total time=   0.0s
[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=7, n_estimators=50, subsample=0.7; total time=   0.0s
[CV] END colsample_bytree=0.8, learning_rate=0.01, max_depth=7, n_estimators=100, subsample=1.0; total time=   0.1s
Best parameters found:  {'subsample': 0.6, 'n_estimators': 200, 'max_depth': 4, 'learning_rate': 0.01, 'colsample_bytree': 1.0}
Mean Squared Error: 3.8114421050658738
#+end_example

#+begin_src jupyter-python :kernel iotvar_powerprofiler
# Output the best parameters
print("Best parameters found: ", study.best_params)
#+end_src

#+RESULTS:
: Best parameters found:  {'n_estimators': 199, 'max_depth': 3, 'learning_rate': 0.02156023917563496, 'subsample': 0.9051307243351219, 'colsample_bytree': 0.8641742514356441, 'alpha': 0.0031413149637324472, 'lambda': 4.3280168867835695e-05, 'gamma': 0.0025863365538159907}

#+begin_src jupyter-python :kernel iotvar_powerprofiler :results silent
import xgboost as xgb
import numpy as np
import optuna
from sklearn.model_selection import train_test_split, cross_val_score
from sklearn.metrics import mean_squared_error
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import KFold

# Create feature matrix and target vector
X = np.zeros([len(m_b_df['number_sensors']), 3])
X[:, 0] = np.array(m_b_df['m'])
X[:, 1] = np.array(m_b_df['refresh_period'])
X[:, 2] = np.array(m_b_df['number_sensors'])

Z = np.array(m_b_df['b'])

# Split the data into training and testing sets
X_train, X_test, Z_train, Z_test = train_test_split(X, Z, test_size=0.2, random_state=42)

# Initialize StandardScaler
scaler = StandardScaler()
X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)

# Define the objective function for Optuna
def objective(trial):
    param = {
        'objective': 'reg:squarederror',
        'n_estimators': trial.suggest_int('n_estimators', 50, 500),
        'max_depth': trial.suggest_int('max_depth', 3, 10),
        'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.2),
        'subsample': trial.suggest_float('subsample', 0.6, 1.0),
        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.6, 1.0),
        'alpha': trial.suggest_loguniform('alpha', 1e-8, 1.0),
        'lambda': trial.suggest_loguniform('lambda', 1e-8, 1.0),
        'gamma': trial.suggest_loguniform('gamma', 1e-8, 1.0)
    }

    xgb_reg = xgb.XGBRegressor(**param)

    kf = KFold(n_splits=5, shuffle=True, random_state=42)
    cv_scores = cross_val_score(xgb_reg, X_train, Z_train, cv=kf, scoring='neg_mean_squared_error')

    return np.mean(-cv_scores)

# Run the optimization
study = optuna.create_study(direction='minimize')
study.optimize(objective, n_trials=100, timeout=600)

# Output the best parameters
print("Best parameters found: ", study.best_params)

# Train the model with the best parameters and early stopping
best_params = study.best_params
best_xgb_reg = xgb.XGBRegressor(**best_params)

best_xgb_reg.fit(
    X_train,
    Z_train,
    eval_set=[(X_test, Z_test)],
    early_stopping_rounds=10,
    verbose=True
)

# Predict on test set
Z_pred = best_xgb_reg.predict(X_test)

# Evaluate model performance
mse = mean_squared_error(Z_test, Z_pred)
print(f"Mean Squared Error: {mse}")
#+end_src

#+begin_src jupyter-python :kernel iotvar_powerprofiler :results silent
from sklearn.preprocessing import PolynomialFeatures
from sklearn.pipeline import Pipeline
from sklearn.compose import ColumnTransformer

# Convert to DataFrame for easier manipulation
df = pd.DataFrame({
    'm': m_b_df['m'],
    'refresh_period': m_b_df['refresh_period'],
    'number_sensors': m_b_df['number_sensors'],
    'b': m_b_df['b']
})

# Create interaction and polynomial features
poly = PolynomialFeatures(degree=2, include_bias=False, interaction_only=False)
X_poly = poly.fit_transform(df[['m', 'refresh_period', 'number_sensors']])

# Standardize the new feature set
scaler = StandardScaler()
X_poly_scaled = scaler.fit_transform(X_poly)

# Update X and Z
X = X_poly_scaled
Z = df['b'].values

# Split the data into training and testing sets
X_train, X_test, Z_train, Z_test = train_test_split(X, Z, test_size=0.2, random_state=42)

# Define the objective function for Optuna
def objective(trial):
    param = {
        'objective': 'reg:squarederror',
        'n_estimators': trial.suggest_int('n_estimators', 50, 500),
        'max_depth': trial.suggest_int('max_depth', 3, 10),
        'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.2),
        'subsample': trial.suggest_float('subsample', 0.6, 1.0),
        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.6, 1.0),
        'alpha': trial.suggest_loguniform('alpha', 1e-8, 1.0),
        'lambda': trial.suggest_loguniform('lambda', 1e-8, 1.0),
        'gamma': trial.suggest_loguniform('gamma', 1e-8, 1.0)
    }

    xgb_reg = xgb.XGBRegressor(**param)

    kf = KFold(n_splits=5, shuffle=True, random_state=42)
    cv_scores = cross_val_score(xgb_reg, X_train, Z_train, cv=kf, scoring='neg_mean_squared_error')

    return np.mean(-cv_scores)

# Run the optimization
study = optuna.create_study(direction='minimize')
study.optimize(objective, n_trials=100, timeout=600)

# Output the best parameters
print("Best parameters found: ", study.best_params)

# Train the model with the best parameters and early stopping
best_params = study.best_params
best_xgb_reg = xgb.XGBRegressor(**best_params)

best_xgb_reg.fit(
    X_train,
    Z_train,
    eval_set=[(X_test, Z_test)],
    early_stopping_rounds=10,
    verbose=True
)

# Predict on test set
Z_pred = best_xgb_reg.predict(X_test)

# Evaluate model performance
mse = mean_squared_error(Z_test, Z_pred)
print(f"Mean Squared Error: {mse}")

#+end_src
*** Benchmarking individual XGBoost

#+begin_src jupyter-python :kernel iotvar_powerprofiler
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score
mae = mean_absolute_error(Z_test, Z_pred)
mse = mean_squared_error(Z_test, Z_pred)
r2 = r2_score(Z_test, Z_pred)

print(f"Mean Absolute Error: {mae}")
print(f"Mean Squared Error: {mse}")
print(f"R-squared: {r2}")

# 2. Feature Importance
# Assuming you have trained model named `xgb_model`

#xgb.plot_importance(xgb_reg)
xgb.plot_importance(best_xgb_reg)
plt.title('Feature Importance')
plt.show()

# 3. Visualization
# Scatter plot of Actual vs Predicted
comparison_df = pd.DataFrame({'Actual': Z_test, 'Predicted': Z_pred})
plt.figure(figsize=(12, 6))
sns.scatterplot(x='Actual', y='Predicted', data=comparison_df)
plt.title('Actual vs Predicted b Values')
plt.xlabel('Actual b')
plt.ylabel('Predicted b')
plt.plot([comparison_df['Actual'].min(), comparison_df['Actual'].max()],
         [comparison_df['Actual'].min(), comparison_df['Actual'].max()],
         color='red', linestyle='--')
plt.show()

# Residual plot
residuals = Z_test - Z_pred
plt.figure(figsize=(12, 6))
sns.histplot(residuals, kde=True)
plt.title('Residuals Distribution')
plt.xlabel('Residuals')
plt.ylabel('Frequency')
plt.show()
#+end_src

#+RESULTS:
:RESULTS:
: Mean Absolute Error: 1.4703653422335652
: Mean Squared Error: 3.816080524040097
: R-squared: 0.15111653559306137
#+attr_org: :width 728
[[./.ob-jupyter/28e5efe63127e88eb0923dce2fe5dfa3e886328f.png]]
[[./.ob-jupyter/15000fa185f5ebf02a8261a46d254afbdcd0291a.png]]
[[./.ob-jupyter/6ae26a7b15af8de420c54874ba8ac537cf983ed7.png]]
:END:

** Hyper-parameter tuning
**** Random search
#+begin_src jupyter-python :kernel iotvar_powerprofiler :results silent
from sklearn.model_selection import RandomizedSearchCV

# Define the parameter grid
param_dist = {
    'n_estimators': np.arange(50, 400, 50),
    'max_depth': np.arange(3, 10, 1),
    'learning_rate': [0.01, 0.05, 0.1, 0.15, 0.2],
    'subsample': [0.6, 0.7, 0.8, 0.9, 1.0],
    'colsample_bytree': [0.6, 0.7, 0.8, 0.9, 1.0],
    'gamma': [0, 0.1, 0.2, 0.3, 0.4]
}

# Initialize Randomized Search
random_search = RandomizedSearchCV(estimator=xgb.XGBRegressor(objective='reg:squarederror'),
                                   param_distributions=param_dist,
                                   n_iter=100,  # Number of random configurations to try
                                   cv=5, scoring='neg_mean_squared_error',
                                   n_jobs=-1, verbose=2, random_state=42)

# Perform Randomized Search
random_search.fit(X_train, Z_train)

# Get the best estimator
best_xgb_reg_random = random_search.best_estimator_

# Predict on test set
Z_pred_random = best_xgb_reg_random.predict(X_test)
#+end_src

#+begin_src jupyter-python :kernel iotvar_powerprofiler
# Evaluate the best model from random search
best_mse_random = mean_squared_error(Z_test, Z_pred_random)
print(f"Best Mean Squared Error after Randomized Search: {best_mse_random}")
#+end_src

#+RESULTS:
: Best Mean Squared Error after Randomized Search: 3.3095586432223816

**** Gridsearch
#+begin_src jupyter-python :kernel iotvar_powerprofiler :results silent
from sklearn.model_selection import GridSearchCV
import numpy as np

# Define a refined parameter grid based on previous results
refined_param_grid = {
    'n_estimators': [150, 200, 250],
    'max_depth': [4, 5, 6],
    'learning_rate': [0.05, 0.1, 0.15],
    'subsample': [0.7, 0.8, 0.9],
    'colsample_bytree': [0.7, 0.8, 0.9],
    'gamma': [0, 0.1, 0.2]
}

# Initialize Grid Search
refined_grid_search = GridSearchCV(estimator=xgb.XGBRegressor(objective='reg:squarederror'),
                                   param_grid=refined_param_grid,
                                   cv=5, scoring='neg_mean_squared_error',
                                   n_jobs=-1, verbose=2)

# Perform Grid Search
refined_grid_search.fit(X_train, Z_train)

# Get the best estimator
best_xgb_reg_refined = refined_grid_search.best_estimator_

# Predict on test set
Z_pred_refined = best_xgb_reg_refined.predict(X_test)

#+end_src

#+begin_src jupyter-python :kernel iotvar_powerprofiler
# Evaluate the best model from random search
best_mse_refined = mean_squared_error(Z_test, Z_pred_refined)
print(f"Best Mean Squared Error after Refined Grid Search: {best_mse_refined}")
#+end_src

#+RESULTS:
: Best Mean Squared Error after Refined Grid Search: 3.55907688246615

#+begin_src jupyter-python :kernel iotvar_powerprofiler
xgb.plot_importance(best_xgb_reg_refined)
plt.show()
#+end_src

#+RESULTS:
:RESULTS:
#+attr_org: :width 728
[[./.ob-jupyter/a843339ba5313207eba3bb228b62547112981839.png]]
:END:

**** Random search with more iterations
#+begin_src jupyter-python :kernel iotvar_powerprofiler :results silent
from sklearn.model_selection import RandomizedSearchCV
import numpy as np

# Define the parameter grid with broader ranges
param_dist = {
    'n_estimators': np.arange(50, 400, 50),
    'max_depth': np.arange(3, 10, 1),
    'learning_rate': [0.01, 0.05, 0.1, 0.15, 0.2],
    'subsample': [0.6, 0.7, 0.8, 0.9, 1.0],
    'colsample_bytree': [0.6, 0.7, 0.8, 0.9, 1.0],
    'gamma': [0, 0.1, 0.2, 0.3, 0.4]
}

# Initialize Randomized Search with more iterations
random_search = RandomizedSearchCV(estimator=xgb.XGBRegressor(objective='reg:squarederror'),
                                   param_distributions=param_dist,
                                   n_iter=200,  # Increase the number of random configurations to try
                                   cv=5, scoring='neg_mean_squared_error',
                                   n_jobs=-1, verbose=2, random_state=42)

# Perform Randomized Search
random_search.fit(X_train, Z_train)

# Get the best estimator
best_xgb_reg_random = random_search.best_estimator_

# Predict on test set
Z_pred_random = best_xgb_reg_random.predict(X_test)

#+end_src
#+begin_src jupyter-python :kernel iotvar_powerprofiler
# Evaluate the best model from random search
best_mse_random = mean_squared_error(Z_test, Z_pred_random)
print(f"Best Mean Squared Error after Extended Randomized Search: {best_mse_random}")

#+end_src

#+RESULTS:
: Best Mean Squared Error after Extended Randomized Search: 3.303196951945521

**** Bayesian optimization
#+begin_src jupyter-python :kernel iotvar_powerprofiler :results silent
from skopt import BayesSearchCV
from skopt.space import Real, Integer

# Define the parameter space
param_space = {
    'n_estimators': Integer(50, 400),
    'max_depth': Integer(3, 10),
    'learning_rate': Real(0.01, 0.2, 'log-uniform'),
    'subsample': Real(0.6, 1.0),
    'colsample_bytree': Real(0.6, 1.0),
    'gamma': Real(0, 0.4)
}

# Initialize Bayesian Search
bayes_search = BayesSearchCV(estimator=xgb.XGBRegressor(objective='reg:squarederror'),
                             search_spaces=param_space,
                             n_iter=50,  # Number of parameter settings that are sampled
                             cv=5, scoring='neg_mean_squared_error',
                             n_jobs=-1, verbose=2, random_state=42)

# Perform Bayesian Search
bayes_search.fit(X_train, Z_train)

# Get the best estimator
best_xgb_reg_bayes = bayes_search.best_estimator_

# Predict on test set
Z_pred_bayes = best_xgb_reg_bayes.predict(X_test)
#+end_src

#+begin_src jupyter-python :kernel iotvar_powerprofiler
# Evaluate the best model from Bayesian search
best_mse_bayes = mean_squared_error(Z_test, Z_pred_bayes)
print(f"Best Mean Squared Error after Bayesian Optimization: {best_mse_bayes}")
#+end_src

#+RESULTS:
: Best Mean Squared Error after Bayesian Optimization: 3.2904985565424543
**** Searching around the optimal parameters
#+begin_src jupyter-python :kernel iotvar_powerprofiler :results silent
from sklearn.model_selection import GridSearchCV
import numpy as np

# Define a refined parameter grid based on the new best parameters
refined_param_grid = {
    'n_estimators': [70, 100, 140],
    'max_depth': [1, 2, 3,4,5],
    'learning_rate': [1, 0.1, 0.2]
}

# Initialize Grid Search
refined_grid_search = GridSearchCV(estimator=xgb.XGBRegressor(objective='reg:squarederror'),
                                   param_grid=refined_param_grid,
                                   cv=5, scoring='neg_mean_squared_error',
                                   n_jobs=-1, verbose=2)

# Perform Grid Search
refined_grid_search.fit(X_train, Z_train)

# Get the best estimator
best_xgb_reg_refined = refined_grid_search.best_estimator_

# Predict on test set
Z_pred_refined = best_xgb_reg_refined.predict(X_test)
#+end_src

#+begin_src jupyter-python :kernel iotvar_powerprofiler
# Evaluate the best model
best_mse_refined = mean_squared_error(Z_test, Z_pred_refined)
print(f"Best Mean Squared Error after Refined Grid Search: {best_mse_refined}")

#+end_src

#+RESULTS:
: Best Mean Squared Error after Refined Grid Search: 3.1855368239520714

#+begin_src jupyter-python :kernel iotvar_powerprofiler :results silent
from sklearn.model_selection import RandomizedSearchCV
import numpy as np

# Define a refined parameter distribution based on the new best parameters
param_dist = {
    'n_estimators': np.arange(80, 121, 10),
    'max_depth': np.arange(1, 4, 1),
    'learning_rate': [0.05, 0.1, 0.15]
}

# Initialize Randomized Search
random_search = RandomizedSearchCV(estimator=xgb.XGBRegressor(objective='reg:squarederror'),
                                   param_distributions=param_dist,
                                   n_iter=50,  # Number of random configurations to try
                                   cv=5, scoring='neg_mean_squared_error',
                                   n_jobs=-1, verbose=2, random_state=42)

# Perform Randomized Search
random_search.fit(X_train, Z_train)

# Get the best estimator
best_xgb_reg_random = random_search.best_estimator_

# Predict on test set
Z_pred_random = best_xgb_reg_random.predict(X_test)

#+end_src

#+begin_src jupyter-python :kernel iotvar_powerprofiler
# Evaluate the best model from random search
best_mse_random = mean_squared_error(Z_test, Z_pred_random)
print(f"Best Mean Squared Error after Refined Randomized Search: {best_mse_random}")
#+end_src

#+RESULTS:
: Best Mean Squared Error after Refined Randomized Search: 3.187714047692544

#+begin_src jupyter-python :kernel iotvar_powerprofiler :results silent
xgb_reg_early_stopping = xgb.XGBRegressor(objective='reg:squarederror',
                                          n_estimators=1000,
                                          max_depth=2,
                                          learning_rate=0.1,
                                          early_stopping_rounds=50)

# Split the data into training and validation sets
X_train_split, X_val_split, Z_train_split, Z_val_split = train_test_split(X_train, Z_train, test_size=0.2, random_state=42)

# Fit the model with early stopping
xgb_reg_early_stopping.fit(X_train_split, Z_train_split,
                           eval_set=[(X_val_split, Z_val_split)],
                           verbose=True)

# Predict on test set
Z_pred_early_stopping = xgb_reg_early_stopping.predict(X_test)

#+end_src

#+begin_src jupyter-python :kernel iotvar_powerprofiler
# Evaluate the model
mse_early_stopping = mean_squared_error(Z_test, Z_pred_early_stopping)
print(f"Mean Squared Error with Early Stopping: {mse_early_stopping}")
#+end_src

#+RESULTS:
: Mean Squared Error with Early Stopping: 3.259030946108345
* Ensemble XGBoost
The results from the xgboost regressor are good when predicting slope (m) values, but when predicting the intersect values (b) the model has a big mse error of 3.4. As m and b come from the same equation, both values should interact when being predicted. Let's ensemble two xgboost models, to make m and b interact. The first xgboost model will predict slope values (m) and the second xgboost model will use the output of the first model as input to predict intersect (b) values.

#+begin_src jupyter-python :kernel iotvar_powerprofiler
import xgboost as xgb
import numpy as np

X_1 = np.zeros([len(m_b_df['number_sensors']),2])
X_1[:,0] = np.array(m_b_df['refresh_period'])
X_1[:,1] = np.array(m_b_df['number_sensors'])
X_2 = np.zeros([len(m_b_df['number_sensors']),2])
X_2[:,0] = np.array(m_b_df['refresh_period'])
X_2[:,1] = np.array(m_b_df['m'])

X_3 = np.array(m_b_df['refresh_period'])
#X_3 = np.array(m_b_df['number_sensors'])

y_m = np.array(m_b_df['m'])
y_b = np.array(m_b_df['b'])

X_train, X_test,X_b_train, X_b_test, X_3_train, X_3_test,y_m_train, y_m_test, y_b_train, y_b_test = train_test_split(X_1,X_2,X_3, y_m, y_b, test_size=0.2, random_state=16)

# Train the first XGBoost model for m
model_m = xgb.XGBRegressor(objective='reg:squarederror', n_estimators=64, max_depth=64, learning_rate=0.5)
model_m.fit(X_train, y_m_train)

# Predict m using the first model
m_pred_train = model_m.predict(X_train)
m_pred_test = model_m.predict(X_test)

# Combine m predictions with original X to train the second model
#X_train_with_m = np.column_stack((X_train, m_pred_train))
#X_test_with_m = np.column_stack((X_test, m_pred_test))

#X_train_with_m = X_b_train
#X_test_with_m = X_b_test

X_train_with_m = np.column_stack((X_3_train, m_pred_train))
X_test_with_m = np.column_stack((X_3_test, m_pred_test))


# Train the second XGBoost model for b
model_b = xgb.XGBRegressor(objective='reg:squarederror', n_estimators=128, max_depth=20, learning_rate=0.1)
model_b.fit(X_train_with_m, y_b_train)

b_pred_train = model_b.predict(X_train_with_m)
b_pred_test = model_b.predict(X_test_with_m)

# Evaluate model performance
mse_m_train = mean_squared_error(y_m_train,m_pred_train)
mse_m_test = mean_squared_error(y_m_test,m_pred_test)

mse_b_train = mean_squared_error(y_b_train,b_pred_train)
mse_b_test = mean_squared_error(y_b_test,b_pred_test)

print(f"Mean Squared Error m train: {mse_m_train}")
print(f"Mean Squared Error m test: {mse_m_test}")
print(f"Mean Squared Error b train: {mse_b_train}")
print(f"Mean Squared Error b test: {mse_b_test}")
#+end_src

#+RESULTS:
: Mean Squared Error m train: 0.00043567129661468577
: Mean Squared Error m test: 0.0004005301035525928
: Mean Squared Error b train: 3.804578894345164
: Mean Squared Error b test: 3.817247884019439

#+begin_src jupyter-python :kernel iotvar_powerprofiler
plt.figure(figsize=(14, 6))

plt.subplot(1, 2, 1)
plt.scatter(X_b_test[:, 0], y_b_test, color='blue', label='Actual')
plt.scatter(X_b_test[:, 0], b_pred_test, color='red', label='Predicted', marker='x')
plt.xlabel("Refresh time $R_{G}$")
plt.ylabel("Intercept $b$")
plt.title('$R_{G}$ vs $m$')
plt.legend()


plt.subplot(1, 2, 2)
plt.scatter(X_b_test[:, 1], y_b_test, color='blue', label='Actual')
plt.scatter(X_b_test[:, 1], b_pred_test, color='red', label='Predicted', marker='x')
plt.xlabel("Slope m")
plt.ylabel("Intercept $b$")
plt.title('$m$ vs $b$')
plt.legend()

plt.figure(figsize=(14, 6))

plt.subplot(1, 2, 1)
plt.scatter(X_test[:, 0], y_m_test, color='blue', label='Actual')
plt.scatter(X_test[:, 0], m_pred_test, color='red', label='Predicted', marker='x')
plt.xlabel("Refresh time $R_{G}$")
plt.ylabel("Slope $m$")
plt.title('$R_{G}$ vs $m$')
plt.legend()


plt.subplot(1, 2, 2)
plt.scatter(X_test[:, 1], y_m_test, color='blue', label='Actual')
plt.scatter(X_test[:, 1], m_pred_test, color='red', label='Predicted', marker='x')
plt.xlabel("Number of Sensors $nb_{V_{G}}$")
plt.ylabel("Slope $m$")
plt.title('$nb_{V_{G}}$ vs $m$')
plt.legend()


plt.tight_layout()
plt.show()
#+end_src

#+RESULTS:
:RESULTS:
[[./.ob-jupyter/de7d2aadca1195a68e6dd10a0561a24a09265534.png]]
[[./.ob-jupyter/e14f01338cf972a40120d2d8a6a56762e168f832.png]]
:END:

#+begin_src jupyter-python :kernel iotvar_powerprofiler
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score

mae = mean_absolute_error(y_b_test, b_pred_test)
mse = mean_squared_error(y_b_test, b_pred_test)
r2 = r2_score(y_b_test, b_pred_test)

print(f"Mean Absolute Error: {mae}")
print(f"Mean Squared Error: {mse}")
print(f"R-squared: {r2}")

# 2. Feature Importance
# Assuming you have trained model named `xgb_model`

xgb.plot_importance(model_b)
plt.title('Feature Importance')
plt.show()

# 3. Visualization
# Scatter plot of Actual vs Predicted
comparison_df = pd.DataFrame({'Actual': y_b_test, 'Predicted': b_pred_test})
plt.figure(figsize=(12, 6))
sns.scatterplot(x='Actual', y='Predicted', data=comparison_df)
plt.title('Actual vs Predicted b Values')
plt.xlabel('Actual b')
plt.ylabel('Predicted b')
plt.plot([comparison_df['Actual'].min(), comparison_df['Actual'].max()],
         [comparison_df['Actual'].min(), comparison_df['Actual'].max()],
         color='red', linestyle='--')
plt.show()

# Residual plot
residuals = y_b_test - b_pred_test
plt.figure(figsize=(12, 6))
sns.histplot(residuals, kde=True)
plt.title('Residuals Distribution')
plt.xlabel('Residuals')
plt.ylabel('Frequency')
plt.show()
#+end_src

#+RESULTS:
:RESULTS:
: Mean Absolute Error: 1.506173966015912
: Mean Squared Error: 3.817247884019439
: R-squared: 0.12321271652214238
#+attr_org: :width 734
[[./.ob-jupyter/0d4876a845074f78ed5f5f8812b2323b8f5ecefc.png]]
[[./.ob-jupyter/0ab1f9a7eeaa965060ab92f9c50b8f2f18c21bf3.png]]
[[./.ob-jupyter/f0c422ce35a841ea8c45e6194dab2af73f872579.png]]
:END:

** Hyperparameter tuning
#+begin_src jupyter-python :kernel iotvar_powerprofiler :results silent
from sklearn.model_selection import RandomizedSearchCV

# Define the parameter grid
param_dist = {
    'n_estimators': np.arange(50, 400, 50),
    'max_depth': np.arange(3, 10, 1),
    'learning_rate': [0.01, 0.05, 0.1, 0.15, 0.2],
    'subsample': [0.6, 0.7, 0.8, 0.9, 1.0],
    'colsample_bytree': [0.6, 0.7, 0.8, 0.9, 1.0],
    'gamma': [0, 0.1, 0.2, 0.3, 0.4]
}

# Initialize Randomized Search
random_search = RandomizedSearchCV(estimator=xgb.XGBRegressor(objective='reg:squarederror'),
                                   param_distributions=param_dist,
                                   n_iter=100,  # Number of random configurations to try
                                   cv=5, scoring='neg_mean_squared_error',
                                   n_jobs=-1, verbose=2, random_state=42)

# Perform Randomized Search
random_search.fit(X_train_with_m, y_b_train)
#model_b.fit(X_train_with_m, y_b_train)
# Get the best estimator
best_xgb_reg_random = random_search.best_estimator_

# Predict on test set
Z_pred_random = best_xgb_reg_random.predict(X_test_with_m)
#+end_src

#+begin_src jupyter-python :kernel iotvar_powerprofiler
# Evaluate the best model from random search
best_mse_random = mean_squared_error(y_b_test, Z_pred_random)
print(f"Best Mean Squared Error after Randomized Search: {best_mse_random}")
#+end_src

#+RESULTS:
: Best Mean Squared Error after Randomized Search: 3.565800475870267
* Multi-output XGBoost

#+begin_src jupyter-python :kernel iotvar_powerprofiler
X = np.zeros([len(m_b_df['number_sensors']),2])
X[:,0] = np.array(m_b_df['refresh_period'])
X[:,1] = np.array(m_b_df['number_sensors'])
y_m = np.array(m_b_df['m'])
y_b = np.array(m_b_df['b'])
Y = np.column_stack((y_m,y_b))

#print(Y.shape)
#print(X.shape)
# Split the dataset into training and test sets
X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)

# Train the XGBoost model for multi-output regression
#multi_output_model = xgb.XGBRegressor(objective='reg:squarederror')
multi_output_model =xgb.XGBRegressor(
        tree_method="hist",
        n_estimators=128,
        n_jobs=16,
        max_depth=3,
        subsample=0.6,
    )
multi_output_model.fit(X_train, Y_train)

# Predict m and b on the test set
Y_pred_test = multi_output_model.predict(X_test)
Y_pred_train = multi_output_model.predict(X_train)

# Evaluate model performance
mse_m_train = mean_squared_error(Y_train[:,0],Y_pred_train[:,0])
mse_m_test = mean_squared_error(Y_test[:,0],Y_pred_test[:,0])

mse_b_train = mean_squared_error(Y_train[:,1],Y_pred_train[:,1])
mse_b_test = mean_squared_error(Y_test[:,1],Y_pred_test[:,1])

print(f"Mean Squared Error m train: {mse_m_train}")
print(f"Mean Squared Error m test: {mse_m_test}")
print(f"Mean Squared Error b train: {mse_b_train}")
print(f"Mean Squared Error b test: {mse_b_test}")
#+end_src

#+RESULTS:
: Mean Squared Error m train: 0.00043113473831388346
: Mean Squared Error m test: 0.0004354930572212889
: Mean Squared Error b train: 3.910519441480899
: Mean Squared Error b test: 3.457212892553588
* Neural networks
** Dense
*** Individual
**** slope m
#+begin_src jupyter-python :kernel iotvar_powerprofiler :results silent
import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense
from tensorflow.keras.layers import Dropout

X = np.zeros([len(m_b_df['number_sensors']),2])
X[:,0] = np.array(m_b_df['refresh_period'])
X[:,1] = np.array(m_b_df['number_sensors'])

Z = np.array(m_b_df['m'])

X_train, X_test, Z_train, Z_test = train_test_split(X, Z, test_size=0.2, random_state=0)

# Define a neural network model
model = Sequential()
model.add(Dense(128, input_dim=X_train.shape[1], activation='relu'))
#model.add(Dropout(0.2))
model.add(Dense(64, activation='relu'))
#model.add(Dropout(0.2))
model.add(Dense(32, activation='relu'))
#model.add(Dropout(0.2))
model.add(Dense(1))

# Compile the model
model.compile(optimizer='adam', loss='mean_squared_error')

# Train the model
history = model.fit(X_train, Z_train, epochs=100, batch_size=32, validation_split=0.2, verbose=2)

# Predict on test set
Z_pred_nn = model.predict(X_test)
#+end_src

#+begin_src jupyter-python :kernel iotvar_powerprofiler
mse_nn = mean_squared_error(Z_test, Z_pred_nn)
print(f"Mean Squared Error with Neural Network: {mse_nn}")
# Plot the evolution of the loss function over the epochs
plt.figure(figsize=(12, 6))
plt.plot(history.history['loss'], label='Training Loss')
plt.plot(history.history['val_loss'], label='Validation Loss')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.title('Loss Function Evolution Over Epochs')
plt.legend()
plt.grid(True)
plt.show()
#+end_src

#+RESULTS:
:RESULTS:
: Mean Squared Error with Neural Network: 0.0012792745180523805
[[./.ob-jupyter/63046c1d68afe49bc38bb3fe6a619efa77e7bde1.png]]
:END:

#+begin_src jupyter-python :kernel iotvar_powerprofiler
# Visualize the predictions
plt.scatter(X_test[:, 0], Z_test, color='blue', label='Actual X vs Z')
plt.scatter(X_test[:, 0], Z_pred_nn, color='red', label='Predicted X vs Z', alpha=0.5)
plt.xlabel("Refresh time $R_{G}$")
plt.ylabel("Slope $m$")
plt.title('$R_{G}$ vs $m$')
plt.legend()
plt.show()

plt.scatter(X_test[:, 1], Z_test, color='blue', label='Actual Y vs Z')
plt.scatter(X_test[:, 1], Z_pred_nn, color='red', label='Predicted Y vs Z', alpha=0.5)
plt.xlabel("Number of Sensors")
plt.ylabel("Slope $m$")
plt.title('$R_{G}$ vs $m$')
plt.legend()
plt.show()
#+end_src

#+RESULTS:
:RESULTS:
#+attr_org: :width 744
[[./.ob-jupyter/c39b6252b1cebc083fc4df4b16620c52e1a4655e.png]]
#+attr_org: :width 744
[[./.ob-jupyter/9e01b066b78b5e39a593d86634897cf416436430.png]]
:END:
**** intersect b
#+begin_src jupyter-python :kernel iotvar_powerprofiler :results silent
import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Dropout
from sklearn.metrics import mean_squared_error

X = np.zeros([len(m_b_df['number_sensors']),3])
X[:,0] = np.array(m_b_df['refresh_period'])
X[:,1] = np.array(m_b_df['number_sensors'])
X[:,1] = np.array(m_b_df['m'])
Z = np.array(m_b_df['b'])

X_train, X_test, Z_train, Z_test = train_test_split(X, Z, test_size=0.2, random_state=42)
# Define a neural network model
model = Sequential()
model.add(Dense(128, input_dim=X_train.shape[1], activation='relu'))
model.add(Dense(64, activation='relu'))
model.add(Dense(32, activation='relu'))
model.add(Dense(1))

# Compile the model
model.compile(optimizer='adam', loss='mean_squared_error')


# Train the model
model.fit(X_train, Z_train, epochs=100, batch_size=32, validation_split=0.2, verbose=2)

# Predict on test set
Z_pred_nn = model.predict(X_test)
#+end_src

#+begin_src jupyter-python :kernel iotvar_powerprofiler
mse_nn = mean_squared_error(Z_test, Z_pred_nn)
print(f"Mean Squared Error with Neural Network: {mse_nn}")
#+end_src

#+RESULTS:
: Mean Squared Error with Neural Network: 3.736573122143258

#+begin_src jupyter-python :kernel iotvar_powerprofiler
# Visualize the predictions
plt.scatter(X_test[:, 0], Z_test, color='blue', label='Actual X vs Z')
plt.scatter(X_test[:, 0], Z_pred_nn, color='red', label='Predicted X vs Z', alpha=0.5)
plt.xlabel("Refresh time $R_{G}$")
plt.ylabel("Intersect $b$")
plt.title('$R_{G}$ vs $b$')
plt.legend()
plt.show()

plt.scatter(X_test[:, 1], Z_test, color='blue', label='Actual Y vs Z')
plt.scatter(X_test[:, 1], Z_pred_nn, color='red', label='Predicted Y vs Z', alpha=0.5)
plt.xlabel("Refresh time $R_{G}$")
plt.ylabel("Intersect $b$")
plt.title('$R_{G}$ vs $b$')
plt.legend()
plt.show()
#+end_src

#+RESULTS:
:RESULTS:
#+attr_org: :width 737
[[./.ob-jupyter/61243fa9c591e5b6443cc30d01e2f420379bdb15.png]]
#+attr_org: :width 737
[[./.ob-jupyter/64c2a8a3522cb1b64a067a9e9f778b1425e92b29.png]]
:END:

*** Multi-output
#+begin_src jupyter-python :kernel iotvar_powerprofiler :results silent
from sklearn.preprocessing import StandardScaler
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.regularizers import l2
from tensorflow.keras.callbacks import LearningRateScheduler

X = np.zeros([len(m_b_df['number_sensors']),2])
X[:,0] = np.array(m_b_df['refresh_period'])
X[:,1] = np.array(m_b_df['number_sensors'])
y_m = np.array(m_b_df['m'])
y_b = np.array(m_b_df['b'])
Z = np.column_stack((y_m,y_b))

scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

scaler_m = StandardScaler()
scaler_b = StandardScaler()
y_m_scaled = scaler_m.fit_transform(y_m.reshape(-1, 1)).flatten()
y_b_scaled = scaler_b.fit_transform(y_b.reshape(-1, 1)).flatten()

Z_scaled = np.column_stack((y_m_scaled, y_b_scaled))

X_train, X_test, Z_train, Z_test = train_test_split(X_scaled, Z_scaled, test_size=0.2, random_state=42)

def kl_divergence_loss(y_true, y_pred):
    epsilon = 1e-10
    y_true = tf.clip_by_value(y_true, epsilon, 1.0)
    y_pred = tf.clip_by_value(y_pred, epsilon, 1.0)
    kl_div = y_true * tf.math.log(y_true / y_pred)
    # Debugging: Print intermediate values
    tf.print("y_true:", y_true)
    tf.print("y_pred:", y_pred)
    tf.print("kl_div:", kl_div)
    return tf.reduce_sum(kl_div, axis=-1)

# Learning rate scheduler
def scheduler(epoch, lr):
    if epoch < 100:
        return lr
    else:
        return lr * tf.math.exp(-0.01)

# Define the model architecture
inputs = Input(shape=(X_train.shape[1],))
x = Dense(64, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.001))(inputs)
x = Dropout(0.4)(x)
x = Dense(32, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.001))(x)
x = Dropout(0.4)(x)
x = Dense(16, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.001))(x)
x = Dropout(0.4)(x)

# Separate outputs
output_m = Dense(1, activation='linear', name='m_output')(x)
output_b = Dense(1, activation='linear', name='b_output')(x)

# Build the model
model = Model(inputs=inputs, outputs=[output_m, output_b])

# Compile the model with the custom loss
model.compile(optimizer=Adam(learning_rate=0.001),
              loss={'m_output': kl_divergence_loss, 'b_output': kl_divergence_loss})

# Train the model with learning rate scheduler
history = model.fit(X_train,
                    {'m_output': Z_train[:,0], 'b_output': Z_train[:,1]},
                    epochs=300,
                    batch_size=16,
                    validation_split=0.2,
                    callbacks=[LearningRateScheduler(scheduler)],
                    verbose=2)

Z_pred_multi_train = model.predict(X_train)
Z_pred_multi_test = model.predict(X_test)

# Z_pred_multi_train and Z_pred_multi_test are lists of arrays
# Inverse transform the predictions to the original scale
Z_pred_multi_train_m = scaler_m.inverse_transform(Z_pred_multi_train[0].reshape(-1, 1)).flatten()
Z_pred_multi_train_b = scaler_b.inverse_transform(Z_pred_multi_train[1].reshape(-1, 1)).flatten()
Z_pred_multi_test_m = scaler_m.inverse_transform(Z_pred_multi_test[0].reshape(-1, 1)).flatten()
Z_pred_multi_test_b = scaler_b.inverse_transform(Z_pred_multi_test[1].reshape(-1, 1)).flatten()

# Inverse transform the true values to the original scale for evaluation
Z_train_m = scaler_m.inverse_transform(Z_train[:,0].reshape(-1, 1)).flatten()
Z_train_b = scaler_b.inverse_transform(Z_train[:,1].reshape(-1, 1)).flatten()
Z_test_m = scaler_m.inverse_transform(Z_test[:,0].reshape(-1, 1)).flatten()
Z_test_b = scaler_b.inverse_transform(Z_test[:,1].reshape(-1, 1)).flatten()
#+end_src

#+begin_src jupyter-python :kernel iotvar_powerprofiler
from sklearn.metrics import mean_absolute_error

mse_m_train = mean_absolute_error(Z_train_m, Z_pred_multi_train_m)
mse_m_test = mean_absolute_error(Z_test_m, Z_pred_multi_test_m)
mse_b_train = mean_absolute_error(Z_train_b, Z_pred_multi_train_b)
mse_b_test = mean_absolute_error(Z_test_b, Z_pred_multi_test_b)


#mse_m_train = mean_squared_error(Z_train_m, Z_pred_multi_train_m)
#mse_m_test = mean_squared_error(Z_test_m, Z_pred_multi_test_m)
#mse_b_train = mean_squared_error(Z_train_b, Z_pred_multi_train_b)
#mse_b_test = mean_squared_error(Z_test_b, Z_pred_multi_test_b)

print(f"Mean Squared Error m train: {mse_m_train}")
print(f"Mean Squared Error m test: {mse_m_test}")
print(f"Mean Squared Error b train: {mse_b_train}")
print(f"Mean Squared Error b test: {mse_b_test}")

# Plot the evolution of the loss function over the epochs
plt.figure(figsize=(12, 6))
plt.plot(history.history['loss'], label='Training Loss')
plt.plot(history.history['val_loss'], label='Validation Loss')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.title('Loss Function Evolution Over Epochs')
plt.legend()
plt.grid(True)
plt.show()
#+end_src

#+RESULTS:
:RESULTS:
: Mean Squared Error m train: 0.49029393947681404
: Mean Squared Error m test: 0.4890883841253725
: Mean Squared Error b train: 7.271629057946908
: Mean Squared Error b test: 7.3196453347284365
[[./.ob-jupyter/634637e593ab283c4056fef1b5039763871cb394.png]]
:END:



Data distribution
#+begin_src jupyter-python :kernel iotvar_powerprofiler
X = np.zeros([len(m_b_df['number_sensors']), 2])
X[:, 0] = np.array(m_b_df['refresh_period'])
X[:, 1] = np.array(m_b_df['number_sensors'])
y_m = np.array(m_b_df['m'])
y_b = np.array(m_b_df['b'])

# Normalize the input data
scaler_X = StandardScaler()
X_scaled = scaler_X.fit_transform(X)

# Normalize the output data
scaler_m = StandardScaler()
scaler_b = StandardScaler()

y_m_scaled = scaler_m.fit_transform(y_m.reshape(-1, 1)).flatten()
y_b_scaled = scaler_b.fit_transform(y_b.reshape(-1, 1)).flatten()

Z_scaled = np.column_stack((y_m_scaled, y_b_scaled))

# Plot the distribution of 'm' and 'b'
plt.figure(figsize=(12, 6))

plt.subplot(1, 2, 1)
plt.hist(y_m_scaled, bins=50, color='blue', alpha=0.7, label='m values')
plt.xlabel('m')
plt.ylabel('Frequency')
plt.title('Distribution of m values')
plt.legend()

plt.subplot(1, 2, 2)
plt.hist(y_b_scaled, bins=50, color='green', alpha=0.7, label='b values')
plt.xlabel('b')
plt.ylabel('Frequency')
plt.title('Distribution of b values')
plt.legend()

plt.tight_layout()
plt.show()
#+end_src

#+RESULTS:
[[./.ob-jupyter/910674becae49dddc70e446712162cb790d9f7c2.png]]

Normalization
#+begin_src jupyter-python :kernel iotvar_powerprofiler
Z_scaled
#+end_src

#+RESULTS:
: array([[-0.93431541, -1.03710195],
:        [-0.83507979,  1.17716909],
:        [-0.86790815,  0.8167906 ],
:        ...,
:        [-0.75512118, -0.28283286],
:        [-0.4476898 , -1.72557472],
:        [-0.69597819,  0.529941  ]])
**** Hyperparameter tuning
#+begin_src jupyter-python :kernel iotvar_powerprofiler :results silent
import optuna
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Dropout
from tensorflow.keras.optimizers import Adam
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error
from sklearn.preprocessing import StandardScaler
import numpy as np

# Create the input features X and outputs y_m, y_b
X = np.zeros([len(m_b_df['number_sensors']), 3])
X[:, 0] = np.array(m_b_df['refresh_period'])
X[:, 1] = np.array(m_b_df['m'])
X[:, 2] = np.array(m_b_df['number_sensors'])
y_m = np.array(m_b_df['m'])
y_b = np.array(m_b_df['b'])

# Normalize the input data
scaler_X = StandardScaler()
X_scaled = scaler_X.fit_transform(X)

# Normalize the output data
scaler_m = StandardScaler()
scaler_b = StandardScaler()

y_m_scaled = scaler_m.fit_transform(y_m.reshape(-1, 1)).flatten()
y_b_scaled = scaler_b.fit_transform(y_b.reshape(-1, 1)).flatten()

#Z_scaled = np.column_stack((y_m_scaled, y_b_scaled))
Z_scaled = y_b_scaled

# Split the data into training and testing sets
X_train, X_test, Z_train, Z_test = train_test_split(X_scaled, Z_scaled, test_size=0.2, random_state=42)

def create_model(trial):
    # Suggest hyperparameters
    n_layers = trial.suggest_int('n_layers', 1, 3, 8)
    units = trial.suggest_int('units', 16, 64, 128)
    dropout_rate = trial.suggest_float('dropout_rate', 0.1, 0.5)
    learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-2)

    model = Sequential()
    model.add(Dense(units, activation='relu', input_dim=X_train.shape[1]))
    for _ in range(n_layers):
        model.add(Dense(units, activation='relu'))
        model.add(Dropout(dropout_rate))
    model.add(Dense(1, activation='linear'))

    #model.compile(optimizer=Adam(learning_rate=learning_rate), loss='mse')
    model.compile(optimizer=Adam(learning_rate=learning_rate), loss='mape')

    return model

def objective(trial):
    model = create_model(trial)
    history = model.fit(X_train, Z_train, epochs=50, batch_size=32, validation_split=0.2, verbose=0)
    val_loss = min(history.history['val_loss'])
    return val_loss

# Create a study and optimize the objective function
study = optuna.create_study(direction='minimize')
study.optimize(objective, n_trials=50)

# Best trial
trial = study.best_trial
print(f"Best trial: Value: {trial.value}")
print("Params: ")
for key, value in trial.params.items():
    print(f"    {key}: {value}")

# Train the final model using the best hyperparameters
best_model = create_model(trial)
#history = best_model.fit(X_train, Z_train, epochs=100, batch_size=32, validation_split=0.2, verbose=2)
history = best_model.fit(X_train, Z_train, epochs=300, batch_size=32, validation_split=0.2, verbose=2)

# Predict on the test set
Z_pred_multi_train = best_model.predict(X_train)
Z_pred_multi_test = best_model.predict(X_test)
#+end_src

#+begin_src jupyter-python :kernel iotvar_powerprofiler
Z_pred_multi_train_m = scaler_m.inverse_transform(Z_pred_multi_train[:,0].reshape(-1, 1)).flatten()
#Z_pred_multi_train_b = scaler_b.inverse_transform(Z_pred_multi_train[:,1].reshape(-1, 1)).flatten()
Z_pred_multi_test_m = scaler_m.inverse_transform(Z_pred_multi_test[:,0].reshape(-1, 1)).flatten()
#Z_pred_multi_test_b = scaler_b.inverse_transform(Z_pred_multi_test[:,1].reshape(-1, 1)).flatten()

# Inverse transform the true values to the original scale for evaluation
Z_train_m = scaler_m.inverse_transform(Z_train.reshape(-1, 1)).flatten()
#Z_train_b = scaler_b.inverse_transform(Z_train[:,1].reshape(-1, 1)).flatten()
Z_test_m = scaler_m.inverse_transform(Z_test.reshape(-1, 1)).flatten()
#Z_test_b = scaler_b.inverse_transform(Z_test[:,1].reshape(-1, 1)).flatten()

X_train_original = scaler_X.inverse_transform(X_train)
#X_0_test = scaler_X.inverse_transform(X_test[:,0].reshape(-1, 1)).flatten()
#X_1_train = scaler_X.inverse_transform(X_train.reshape(-1, 1)).flatten()
X_test_original = scaler_X.inverse_transform(X_test)
print(X_train_original.shape)
#+end_src

#+RESULTS:
: (992, 3)

#+begin_src jupyter-python :kernel iotvar_powerprofiler
from sklearn.metrics import mean_squared_error
mse_m_train = mean_squared_error(Z_train_m, Z_pred_multi_train_m)
mse_m_test = mean_squared_error(Z_test_m, Z_pred_multi_test_m)

#mse_m_train = mean_squared_error(Z_train_m, Z_pred_multi_train_m)
#mse_m_test = mean_squared_error(Z_test_m, Z_pred_multi_test_m)
#mse_b_train = mean_squared_error(Z_train_b, Z_pred_multi_train_b)
#mse_b_test = mean_squared_error(Z_test_b, Z_pred_multi_test_b)

print(f"Mean Squared Error m train: {mse_m_train}")
print(f"Mean Squared Error m test: {mse_m_test}")

# Plot the evolution of the loss function over the epochs
plt.figure(figsize=(12, 6))
plt.plot(history.history['loss'], label='Training Loss')
plt.plot(history.history['val_loss'], label='Validation Loss')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.title('Loss Function Evolution Over Epochs')
plt.legend()
plt.grid(True)
plt.show()
#+end_src

#+RESULTS:
:RESULTS:
: Mean Squared Error m train: 0.027538622879820195
: Mean Squared Error m test: 0.026537733418183714
[[./.ob-jupyter/181240afaaed76c19a2b0e6de077bf80e8013113.png]]
:END:

#+begin_src jupyter-python :kernel iotvar_powerprofiler
# Visualize the predictions
plt.scatter(X_test_original[:,0], Z_test_m, color='blue', label='Actual X vs Z')
plt.scatter(X_test_original[:,0], Z_pred_multi_test_m, color='red', label='Predicted X vs Z', alpha=0.5)
plt.xlabel("Refresh time $R_{G}$")
plt.ylabel("Slope $m$")
plt.title('$R_{G}$ vs $m$')
plt.legend()
plt.show()

plt.scatter(X_test_original[:,1], Z_test_b, color='blue', label='Actual Y vs Z')
plt.scatter(X_test_original[:,1], Z_pred_multi_test_b, color='red', label='Predicted Y vs Z', alpha=0.5)
plt.xlabel("Number of sensors in group $nb_{V_{G}}$")
plt.ylabel("Slope $m$")
plt.title('$R_{G}$ vs $m$')
plt.legend()
plt.show()
#+end_src

#+RESULTS:
:RESULTS:
#+attr_org: :width 744
[[./.ob-jupyter/4564c8becab5af94bb0028b6376ef869bd227015.png]]
#+attr_org: :width 741
[[./.ob-jupyter/ae670d5d1e947833cdf26aa2c393448b2e423729.png]]
:END:

** Ensemble
*** slope m
#+begin_src jupyter-python :kernel iotvar_powerprofiler :results silent
Z = np.array(m_b_df['m'])
X_train, X_test, Z_train, Z_test = train_test_split(X, Z, test_size=0.2, random_state=42)

def create_model():
    model = Sequential()
    model.add(Dense(128, input_dim=X_train.shape[1], activation='relu'))
    model.add(Dropout(0.2))
    model.add(Dense(64, activation='relu'))
    model.add(Dropout(0.2))
    model.add(Dense(32, activation='relu'))
    model.add(Dropout(0.2))
    model.add(Dense(1))

    # Compile the model
    model.compile(optimizer='adam', loss='mean_squared_error')
    return model

# Train multiple models (ensemble)
n_models = 10
models = [create_model() for _ in range(n_models)]

for i, model in enumerate(models):
    print(f"Training model {i+1}")
    model.fit(X_train, Z_train, epochs=100, batch_size=32, validation_split=0.2, verbose=2)

# Predict on test set and average predictions
Z_preds = np.array([model.predict(X_test) for model in models])
Z_pred_ensemble = np.mean(Z_preds, axis=0)
#+end_src

#+begin_src jupyter-python :kernel iotvar_powerprofiler
# Evaluate the ensemble model
mse_ensemble = mean_squared_error(Z_test, Z_pred_ensemble)
print(f"Mean Squared Error with Neural Network Ensemble: {mse_ensemble}")

# Visualize the predictions
plt.scatter(X_test[:, 0], Z_test, color='blue', label='Actual X vs Z')
plt.scatter(X_test[:, 0], Z_pred_ensemble, color='red', label='Predicted X vs Z', alpha=0.5)
plt.xlabel("Refresh time $R_{G}$")
plt.ylabel("Slope $m$")
plt.title('$R_{G}$ vs $m$')
plt.legend()
plt.show()

plt.scatter(X_test[:, 1], Z_test, color='blue', label='Actual Y vs Z')
plt.scatter(X_test[:, 1], Z_pred_ensemble, color='red', label='Predicted Y vs Z', alpha=0.5)
plt.xlabel("Refresh time $R_{G}$")
plt.ylabel("Slope $m$")
plt.title('$R_{G}$ vs $m$')
plt.legend()
plt.show()
#+end_src

#+RESULTS:
:RESULTS:
: Mean Squared Error with Neural Network Ensemble: 0.15455983584126992
#+attr_org: :width 744
[[./.ob-jupyter/c08907435b54fff0bad8ac69058ac6895bd4d366.png]]
#+attr_org: :width 744
[[./.ob-jupyter/a771c10fd9b1395d7176799d94fceb34873fab0f.png]]
:END:
*** intersect b

#+begin_src jupyter-python :kernel iotvar_powerprofiler :results silent
Z = np.array(m_b_df['b'])
X_train, X_test, Z_train, Z_test = train_test_split(X, Z, test_size=0.2, random_state=42)

def create_model():
    model = Sequential()
    model.add(Dense(128, input_dim=X_train.shape[1], activation='relu'))
    model.add(Dropout(0.2))
    model.add(Dense(64, activation='relu'))
    model.add(Dropout(0.2))
    model.add(Dense(32, activation='relu'))
    model.add(Dropout(0.2))
    model.add(Dense(1))

    # Compile the model
    model.compile(optimizer='adam', loss='mean_squared_error')
    return model

# Train multiple models (ensemble)
n_models = 20
models = [create_model() for _ in range(n_models)]
for i, model in enumerate(models):
    print(f"Training model {i+1}")
    model.fit(X_train, Z_train, epochs=100, batch_size=32, validation_split=0.2, verbose=2)

# Predict on test set and average predictions
Z_preds = np.array([model.predict(X_test) for model in models])
Z_pred_ensemble = np.mean(Z_preds, axis=0)
#+end_src

#+begin_src jupyter-python :kernel iotvar_powerprofiler
# Evaluate the ensemble model
mse_ensemble = mean_squared_error(Z_test, Z_pred_ensemble)
print(f"Mean Squared Error with Neural Network Ensemble: {mse_ensemble}")

# Visualize the predictions
plt.scatter(X_test[:, 0], Z_test, color='blue', label='Actual X vs Z')
plt.scatter(X_test[:, 0], Z_pred_ensemble, color='red', label='Predicted X vs Z', alpha=0.5)
plt.xlabel("Refresh time $R_{G}$")
plt.ylabel("Intersect $b$")
plt.title('$R_{G}$ vs $b$')
plt.legend()
plt.show()

plt.scatter(X_test[:, 1], Z_test, color='blue', label='Actual Y vs Z')
plt.scatter(X_test[:, 1], Z_pred_ensemble, color='red', label='Predicted Y vs Z', alpha=0.5)
plt.xlabel("Refresh time $R_{G}$")
plt.ylabel("Intersect $b$")
plt.title('$R_{G}$ vs $b$')
plt.legend()
plt.show()
#+end_src

#+RESULTS:
:RESULTS:
: Mean Squared Error with Neural Network Ensemble: 3.778632072446469
#+attr_org: :width 737
[[./.ob-jupyter/63e1cf902a0464ef8d43c52b070a43d0ee228039.png]]
#+attr_org: :width 737
[[./.ob-jupyter/e75fb77b461b0d0a0715aa41a63dac5849b7ab46.png]]
:END:
* Using KL divergence as loss function

#+begin_src jupyter-python :kernel iotvar_powerprofiler
#km_b_df_multi = m_b_df.group_by(['refresh_period','number_sensors']).agg(pl.col('m'))
m_b_df_multi = m_b_df.group_by(['refresh_period','number_sensors']).agg(['m','b'])
m_b_df_multi
#+end_src

#+RESULTS:
#+begin_example
shape: (36, 4)
┌────────────────┬────────────────┬────────────────────────┬─────────────────────────────────┐
│ refresh_period ┆ number_sensors ┆ m                      ┆ b                               │
│ ---            ┆ ---            ┆ ---                    ┆ ---                             │
│ i64            ┆ i64            ┆ list[f64]              ┆ list[f64]                       │
╞════════════════╪════════════════╪════════════════════════╪═════════════════════════════════╡
│ 10             ┆ 150            ┆ [2.358368, 2.359778, … ┆ [-0.678109, 0.269536, … 1.6153… │
│                ┆                ┆ 2.34716…               ┆                                 │
│ 10             ┆ 50             ┆ [2.330397, 2.340528, … ┆ [-0.268501, 2.126542, … -0.374… │
│                ┆                ┆ 2.33107…               ┆                                 │
│ 20             ┆ 150            ┆ [2.203319, 2.20559, …  ┆ [-0.776807, 2.227719, … -1.382… │
│                ┆                ┆ 2.241636…              ┆                                 │
│ 5              ┆ 75             ┆ [2.373087, 2.327805, … ┆ [1.44886, 3.742374, … -3.27341… │
│                ┆                ┆ 2.35737…               ┆                                 │
│ 10             ┆ 200            ┆ [2.342896, 2.313995, … ┆ [-0.306708, -0.680086, … 0.353… │
│                ┆                ┆ 2.31678…               ┆                                 │
│ …              ┆ …              ┆ …                      ┆ …                               │
│ 15             ┆ 125            ┆ [2.256132, 2.285069, … ┆ [3.767868, 3.40195, … -1.80043… │
│                ┆                ┆ 2.29448…               ┆                                 │
│ 1              ┆ 150            ┆ [2.674797, 2.678396, … ┆ [4.127802, 4.19014, … 3.294844… │
│                ┆                ┆ 2.67704…               ┆                                 │
│ 1              ┆ 125            ┆ [2.700024, 2.694353, … ┆ [3.001407, 4.190707, … 0.59879… │
│                ┆                ┆ 2.70564…               ┆                                 │
│ 20             ┆ 200            ┆ [2.269784, 2.287611, … ┆ [0.537042, -2.473901, … -3.146… │
│                ┆                ┆ 2.30770…               ┆                                 │
│ 10             ┆ 125            ┆ [2.359891, 2.353762, … ┆ [-1.063473, 0.652839, … 1.1682… │
│                ┆                ┆ 2.36863…               ┆                                 │
└────────────────┴────────────────┴────────────────────────┴─────────────────────────────────┘
#+end_example

#+begin_src jupyter-python :kernel iotvar_powerprofiler
from tensorflow.keras.preprocessing.sequence import pad_sequences
import xgboost as xgb
X = m_b_df_multi.select(['refresh_period','number_sensors']).to_numpy()
y_m = m_b_df_multi['m'].to_numpy()
y_b = m_b_df_multi['b'].to_numpy()

y_m_padded = pad_sequences(y_m, dtype='float32', padding='post', value=-1)  # Use a value like -1 for padding
y_b_padded = pad_sequences(y_b, dtype='float32', padding='post', value=-1)  # Use a value like -1 for padding

X_train, X_test, y_m_train, y_m_test, y_b_train, y_b_test = train_test_split(X, y_m_padded, y_b_padded, test_size=0.2, random_state=42)

n_outputs = y_b_padded.shape[1]

#print(y_b_train.shape)
# List to store the models
models = []

# Train a separate model for each output column
for i in range(n_outputs):
    model = xgb.XGBRegressor(objective='reg:squarederror')
    # Mask the padded values (-1) by setting their targets to NaN and using a masked loss
    mask = y_b_train[:, i] != -1
    model.fit(X_train[mask],y_b_train[mask, i])
    models.append(model)


from sklearn.metrics import mean_squared_error

# Predict using the trained models
Z_pred_padded = np.column_stack([model.predict(X_test) for model in models])

print("Z_pred_padded:")
print(Z_pred_padded.shape)

# Evaluate the models using mean squared error, ignoring the padded values
mse_list = []
for i in range(n_outputs):
    mask = y_b_test[:, i] != -1
    mse = mean_squared_error(y_b_test[mask, i], Z_pred_padded[mask, i])
    mse_list.append(mse)

print("Mean Squared Error for each output dimension:", mse_list)
print(len(mse_list))

#+end_src

#+RESULTS:
: Z_pred_padded:
: (8, 30)
: Mean Squared Error for each output dimension: [7.7606416, 42.98607, 3.7509723, 4.2561564, 7.055361, 5.949973, 6.61572, 22.651962, 10.278215, 6.828606, 9.943451, 2.6640713, 14.40509, 5.218684, 12.912466, 12.599857, 6.6674304, 2.634577, 7.648043, 7.3363733, 4.941203, 5.566483, 5.770232, 6.142181, 5.5158644, 4.3327646, 0.18563595, 5.3205223, 3.570005, 2.5561986]
: 30
* Bayesian Neural Networks
#+begin_src jupyter-python :kernel iotvar_powerprofiler
#m_b_df_multi = m_b_df.group_by(['refresh_period','number_sensors']).agg(pl.col('m'))
m_b_df_multi = m_b_df.group_by(['refresh_period','number_sensors']).agg(['m','b'])
m_b_df_multi
#+end_src

#+RESULTS:
#+begin_example
shape: (36, 4)
┌────────────────┬────────────────┬─────────────────────────────────┬─────────────────────────┐
│ refresh_period ┆ number_sensors ┆ m                               ┆ b                       │
│ ---            ┆ ---            ┆ ---                             ┆ ---                     │
│ i64            ┆ i64            ┆ list[f64]                       ┆ list[f64]               │
╞════════════════╪════════════════╪═════════════════════════════════╪═════════════════════════╡
│ 5              ┆ 50             ┆ [2.355418, 2.348634, … 2.33717… ┆ [2.270711, 0.896441, …  │
│                ┆                ┆                                 ┆ 0.39851…                │
│ 20             ┆ 50             ┆ [2.276718, 2.22928, … 2.264]    ┆ [0.899157, 6.126538, …  │
│                ┆                ┆                                 ┆ 3.94981…                │
│ 15             ┆ 150            ┆ [2.282303, 2.27321, … 2.27892]  ┆ [0.910138, -0.291337, … │
│                ┆                ┆                                 ┆ 0.9128…                 │
│ 10             ┆ 100            ┆ [2.347285, 2.342523, … 2.33682… ┆ [-0.633532, 3.119234, … │
│                ┆                ┆                                 ┆ 1.7254…                 │
│ 5              ┆ 25             ┆ [2.347613, 2.368218, … 2.34701… ┆ [1.141659, 2.507027, …  │
│                ┆                ┆                                 ┆ -0.5187…                │
│ …              ┆ …              ┆ …                               ┆ …                       │
│ 1              ┆ 50             ┆ [2.713667, 2.694739, … 2.68646… ┆ [1.810044, 0.340439, …  │
│                ┆                ┆                                 ┆ 1.64038…                │
│ 15             ┆ 25             ┆ [2.287442, 2.306578, … 2.26211… ┆ [0.383612, -0.283177, … │
│                ┆                ┆                                 ┆ -0.810…                 │
│ 20             ┆ 175            ┆ [2.265169, 2.259511, … 2.25434… ┆ [3.605967, 2.810447, …  │
│                ┆                ┆                                 ┆ 1.14979…                │
│ 20             ┆ 150            ┆ [2.203319, 2.20559, … 2.241636… ┆ [-0.776807, 2.227719, … │
│                ┆                ┆                                 ┆ -1.382…                 │
│ 1              ┆ 125            ┆ [2.700024, 2.694353, … 2.70564… ┆ [3.001407, 4.190707, …  │
│                ┆                ┆                                 ┆ 0.59879…                │
└────────────────┴────────────────┴─────────────────────────────────┴─────────────────────────┘
#+end_example

#+begin_src jupyter-python :kernel iotvar_powerprofiler
X = m_b_df_multi.select(['refresh_period','number_sensors']).to_numpy()
m = m_b_df_multi['m'].to_numpy()
b = m_b_df_multi['b'].to_numpy()

X_train, X_test, m_train, m_test, b_train, b_test = train_test_split(X, m, b, test_size=0.2, random_state=42)
#+end_src

#+RESULTS:

#+begin_src jupyter-python :kernel iotvar_powerprofiler
import tensorflow as tf
import tensorflow_probability as tfp

tfd = tfp.distributions
tfpl = tfp.layers

# Define the Bayesian Neural Network model using Functional API
def build_bnn(input_shape):
    inputs = tf.keras.Input(shape=input_shape)
    x = tfpl.DenseFlipout(64, activation='relu')(inputs)
    x = tfpl.DenseFlipout(64, activation='relu')(x)
    outputs = tfpl.DenseFlipout(1)(x)  # Output single value
    model = tf.keras.Model(inputs=inputs, outputs=outputs)
    return model

# Loss function to use Mean Squared Error
def mse_loss(y_true, y_pred):
    return tf.reduce_mean(tf.square(y_true - y_pred))

# Train a BNN for each output list (m and b) for each set of input features
def train_bnn_for_each_output(X_train, y_train):
    models = []
    for i in range(len(X_train)):
        model = build_bnn(input_shape=(2,))
        model.compile(optimizer=tf.optimizers.Adam(learning_rate=0.01), loss=mse_loss)
        x_single = np.tile(X_train[i], (len(y_train[i]), 1))  # Repeat the input features for each output value
        y_single = np.array(y_train[i]).reshape(-1, 1)
        model.fit(x_single, y_single, epochs=100, verbose=0)
        models.append(model)
    return models

m_models = train_bnn_for_each_output(X_train, m_train)
b_models = train_bnn_for_each_output(X_train, b_train)
#+end_src

#+RESULTS:

#+begin_src jupyter-python :kernel iotvar_powerprofiler
from sklearn.metrics import mean_squared_error

# Predict using the trained models
def predict_with_models(models, X_test, y_test):
    predictions = []
    for i in range(len(X_test)):
        x_single = np.tile(X_test[i], (len(y_test[i]), 1))  # Repeat the input features for each output value
        preds = models[i].predict(x_single)
        predictions.append(preds.flatten())
    return predictions

m_predictions = predict_with_models(m_models, X_test, m_test)
b_predictions = predict_with_models(b_models, X_test, b_test)

# Evaluate the models using mean squared error for each set of output values
def evaluate_models(y_test, predictions):
    mse_list = []
    for i in range(len(y_test)):
        mse = mean_squared_error(y_test[i], predictions[i])
        mse_list.append(mse)
    return mse_list

m_mse_list = evaluate_models(m_test, m_predictions)
b_mse_list = evaluate_models(b_test, b_predictions)

print("Mean Squared Error for m:", m_mse_list)
print("Mean Squared Error for b:", b_mse_list)
#+end_src

#+RESULTS:
#+begin_example
Mean Squared Error for m: [10.107692780227687, 5.007534746124783, 7.411704078974716, 4.756180518782207, 3.0039770154444185, 4.989963631188211, 5.366719116716586, 69.48352457583887]
Mean Squared Error for b: [20.406434197097063, 11.048857257939996, 22.12455496307438, 8.261975259914056, 2.264122477987902, 3.4967839990745504, 9.451617778474686, 32.528785335765626]
#+end_example

#+begin_src jupyter-python :kernel iotvar_powerprofiler
print(len(m_predictions))
print(len(b_predictions))
print(len(X_test))
X_test
#+end_src

#+RESULTS:
:RESULTS:
: 8
: 8
: 8
: array([[  1, 125],
:        [ 15, 100],
:        [  1, 175],
:        [ 20, 125],
:        [ 15,  50],
:        [  1,  50],
:        [ 10, 150],
:        [ 10, 175]])
:END:

#+begin_src jupyter-python :kernel iotvar_powerprofiler
plt.hist(m_test[1])
plt.show()
plt.hist(m_predictions[1])
plt.show()
#+end_src

#+RESULTS:
:RESULTS:
#+attr_org: :width 713
[[./.ob-jupyter/06b2945cc8c04cf6e76a9cd8c03557ab5fabecf2.png]]
#+attr_org: :width 696
[[./.ob-jupyter/9f38ba97b4c5ee15a1661d20b51d6b9aac539ca0.png]]
:END:

#+begin_src jupyter-python :kernel iotvar_powerprofiler
import tensorflow as tf
import tensorflow_probability as tfp
tfd = tfp.distributions
tfpl = tfp.layers

import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
#+end_src

#+RESULTS:
: 2024-06-02 16:51:08.930177: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.
: 2024-06-02 16:51:09.116945: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
: 2024-06-02 16:51:09.116982: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
: 2024-06-02 16:51:09.117027: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
: 2024-06-02 16:51:09.125418: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.
: 2024-06-02 16:51:09.126526: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
: To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
: 2024-06-02 16:51:11.185088: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
: /home/han4n/anaconda3/envs/IoTVar_PowerProfiler/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5
:   warnings.warn(f"A NumPy version >={np_minversion} and <{np_maxversion}"

#+begin_src jupyter-python :kernel iotvar_powerprofiler
# Generate some non-linear noisy training data
n_points = 500
x_train = np.linspace(-1, 1, n_points)[:, np.newaxis]
y_train = np.power(x_train, 5) + 0.4 * x_train * np.random.randn(n_points)[:, np.newaxis]
plt.scatter(x_train, y_train, alpha=0.2);
plt.xlabel('x')
plt.ylabel('y')
plt.show();
#+end_src

#+RESULTS:
:RESULTS:
#+attr_org: :width 754
[[./.ob-jupyter/3b87475d36be4eabf2b8a3258f38c7fd2110f115.png]]
:END:

#+begin_src jupyter-python :kernel iotvar_powerprofiler
def get_prior(kernel_size, bias_size, dtype=None):
    n = kernel_size + bias_size
    prior_model = tf.keras.Sequential([
        tfpl.DistributionLambda(lambda t: tfd.MultivariateNormalDiag(
        loc=tf.zeros(n), scale_diag=tf.ones(n)))
    ])
    return prior_model
# Define the mean vector mu

mu = np.array([1, 2]).reshape(2, 1)

# Define the covariance matrix (it must be positive definite)
K = np.array([[2, 1],
              [1, 2]])

# Apply Cholesky decomposition of K to LL^T
L = np.linalg.cholesky(K)
L = L.T

# The variable z follows a multinormal distribution
n_samples = 100000
x = np.random.normal(loc=0, scale=1, size=2*n_samples).reshape(2, n_samples)
z = mu + np.dot(L, x)

sns.jointplot(x=z[0], y=z[1], kind="kde");
#+end_src

#+RESULTS:
:RESULTS:
#+attr_org: :width 766
[[./.ob-jupyter/6090d15c69e102b70109a81addbdf3870c2c7791.png]]
:END:

#+begin_src jupyter-python :kernel iotvar_powerprofiler
def get_posterior(kernel_size, bias_size, dtype=None):
    n = kernel_size + bias_size
    posterior_model = tf.keras.Sequential([
        tfpl.VariableLayer(tfpl.MultivariateNormalTriL.params_size(n), dtype=dtype),
        tfpl.MultivariateNormalTriL(n)
    ])
    return posterior_model

# The prior distribution has no trainable variables
prior_model = get_prior(3, 1)
print('Trainable variables for prior model: ', prior_model.layers[0].trainable_variables)
print('Sampling from the prior distribution:\n', prior_model.call(tf.constant(1.0)).sample(5))

# The posterior distribution for kernel_size = 3, bias_size = 1, is expected to
# have (3 + 1) + ((4^2 - 4)/2 + 4) = 14 parameters. Note that the default initializer
# according to the docs is 'zeros'.
posterior_model = get_posterior(3, 1)
print('\nTrainable variables for posterior model: ', posterior_model.layers[0].trainable_variables)
print('Sampling from the posterior distribution:\n', posterior_model.call(tf.constant(1.0)).sample(5))
#+end_src

#+RESULTS:
#+begin_example
Trainable variables for prior model:  []
Sampling from the prior distribution:
 tf.Tensor(
[[ 0.72393996  1.0600994  -0.4810712   0.0176721 ]
 [-0.94217616 -0.19501838 -2.2957745  -1.2886643 ]
 [ 0.01709052 -1.523235   -0.7798844  -0.7555743 ]
 [ 0.62847054 -1.299732    0.8554973  -0.25060973]
 [-0.5460316   0.23143329  1.0101801  -1.4045913 ]], shape=(5, 4), dtype=float32)

Trainable variables for posterior model:  [<tf.Variable 'constant:0' shape=(14,) dtype=float32, numpy=
array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
      dtype=float32)>]
Sampling from the posterior distribution:
 tf.Tensor(
[[ 0.41257143 -0.6110683  -0.949757    1.0859674 ]
 [-0.49780217 -0.07879207 -0.17371184  0.33620626]
 [ 0.14279504  0.5164238   0.07726895  0.77019256]
 [ 0.10906743  0.7625871  -1.1751683   0.22529186]
 [ 0.4690943  -0.62860304  0.28487402  1.3361923 ]], shape=(5, 4), dtype=float32)
#+end_example

#+begin_src jupyter-python :kernel iotvar_powerprofiler
# Define the model, negative-log likelihood as the loss function
# and compile the model with the RMSprop optimizer
model = tf.keras.Sequential([
    tfpl.DenseVariational(input_shape=(1,), units=8,
                          make_prior_fn=get_prior,
                          make_posterior_fn=get_posterior,
                          kl_weight=1/x_train.shape[0],
                          activation='sigmoid'),
    tfpl.DenseVariational(units=tfpl.IndependentNormal.params_size(1),
                          make_prior_fn=get_prior,
                          make_posterior_fn=get_posterior,
                          kl_weight=1/x_train.shape[0]),
    tfpl.IndependentNormal(1)
])

def nll(y_true, y_pred):
    return -y_pred.log_prob(y_true)

model.compile(loss=nll, optimizer=tf.keras.optimizers.RMSprop(learning_rate=0.005))
model.summary()
#+end_src

#+RESULTS:
#+begin_example
Model: "sequential_2"
_________________________________________________________________
 Layer (type)                Output Shape              Param #
=================================================================
 dense_variational (DenseVa  (None, 8)                 152
 riational)

 dense_variational_1 (Dense  (None, 2)                 189
 Variational)

 independent_normal (Indepe  ((None, 1),               0
 ndentNormal)                 (None, 1))

=================================================================
Total params: 341 (1.33 KB)
Trainable params: 341 (1.33 KB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________
#+end_example

#+begin_src jupyter-python :kernel iotvar_powerprofiler
# Train the model for 1000 epochs
history = model.fit(x_train, y_train, epochs=1000, verbose=0)
plt.plot(history.history['loss'])
plt.xlabel('Epochs')
plt.ylabel('Loss');
#+end_src

#+RESULTS:
:RESULTS:
#+attr_org: :width 734
[[./.ob-jupyter/39adae3e1023462a8dd56cdce40f853bb065196f.png]]
:END:

#+begin_src jupyter-python :kernel iotvar_powerprofiler
plt.scatter(x_train, y_train, marker='.', alpha=0.2, label='data')
for _ in range(5):
    y_model = model(x_train)
    y_hat = y_model.mean()
    y_hat_minus_2sd = y_hat - 2 * y_model.stddev()
    y_hat_plus_2sd = y_hat + 2 * y_model.stddev()
    plt.plot(x_train, y_hat, color='red', label='model $\mu$' if _ == 0 else '')
    plt.plot(x_train, y_hat_minus_2sd, color='blue', label='$\mu - 2SD$' if _ == 0 else '')
    plt.plot(x_train, y_hat_plus_2sd, color='green', label='$\mu + 2SD$' if _ == 0 else '')
plt.xlabel('x')
plt.ylabel('y')
plt.legend()
plt.show()
#+end_src

#+RESULTS:
:RESULTS:
#+attr_org: :width 754
[[./.ob-jupyter/ec44757c835fb22d842aee9529135e8428f0fe5a.png]]
:END:
** Ensemble

#+begin_src jupyter-python :kernel iotvar_powerprofiler :results silent
import numpy as np
from sklearn import datasets
import torch
import torch.nn as nn
import torch.optim as optim
import torchbnn as bnn
import matplotlib.pyplot as plt
#+end_src

#+begin_src jupyter-python :kernel iotvar_powerprofiler
X = np.zeros([len(m_b_df['number_sensors']),2])
X[:,0] = np.array(m_b_df['refresh_period'])
X[:,1] = np.array(m_b_df['number_sensors'])
y_m = np.array(m_b_df['m'])
y_b = np.array(m_b_df['b'])
Y = np.column_stack((y_m,y_b))

X_t = torch.from_numpy(X)
y_m_t = torch.from_numpy(y_m)
y_b_t = torch.from_numpy(y_b)
Y_t = torch.from_numpy(Y)

X_train, X_test, Y_train, Y_test = train_test_split(X_t, Y_t, test_size=0.1, random_state=42)

X_train = X_train.float()
X_test = X_test.float()
Y_train = Y_train.float()
Y_test = Y_test.float()

model = nn.Sequential(
    bnn.BayesLinear(prior_mu=0, prior_sigma=0.1, in_features=2, out_features=50),
    nn.ReLU(),
    bnn.BayesLinear(prior_mu=0, prior_sigma=0.1, in_features=50, out_features=2),
)

mse_loss = nn.MSELoss()
kl_loss = bnn.BKLLoss(reduction='mean', last_layer_only=False)
kl_weight = 0.01

optimizer = optim.Adam(model.parameters(), lr=0.01)

# Lists to store the loss values
mse_list = []
kl_list = []
total_loss_list = []

# Training loop
for step in range(10000):
    model.train()
    pre = model(X_train)
    mse = mse_loss(pre, Y_train)
    kl = kl_loss(model)
    cost = mse + kl_weight * kl

    optimizer.zero_grad()
    cost.backward()
    optimizer.step()

    # Store the loss values
    mse_list.append(mse.item())
    kl_list.append(kl.item())
    total_loss_list.append(cost.item())

    if step % 100 == 0:
        print(f'Step {step} - MSE : {mse.item():.2f}, KL : {kl.item():.2f}')

plt.figure(figsize=(10, 5))
plt.plot(mse_list, label='MSE Loss')
plt.plot(kl_list, label='KL Loss')
plt.plot(total_loss_list, label='Total Loss')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.title('Loss Function Evolution')
plt.legend()
plt.show()

#+end_src

#+RESULTS:
:RESULTS:
#+begin_example
Step 0 - MSE : 2524.49, KL : 4.53
Step 100 - MSE : 327.54, KL : 3.32
Step 200 - MSE : 40.23, KL : 3.39
Step 300 - MSE : 4.36, KL : 3.68
Step 400 - MSE : 21.49, KL : 3.86
Step 500 - MSE : 22.06, KL : 4.02
Step 600 - MSE : 5.31, KL : 4.08
Step 700 - MSE : 6.95, KL : 4.17
Step 800 - MSE : 3.75, KL : 4.30
Step 900 - MSE : 12.59, KL : 4.43
Step 1000 - MSE : 4.94, KL : 4.45
Step 1100 - MSE : 2.88, KL : 4.57
Step 1200 - MSE : 3.29, KL : 4.66
Step 1300 - MSE : 3.07, KL : 4.79
Step 1400 - MSE : 3.37, KL : 4.84
Step 1500 - MSE : 3.39, KL : 4.87
Step 1600 - MSE : 2.54, KL : 4.91
Step 1700 - MSE : 2.77, KL : 4.94
Step 1800 - MSE : 3.23, KL : 5.00
Step 1900 - MSE : 2.90, KL : 5.02
Step 2000 - MSE : 2.64, KL : 5.03
Step 2100 - MSE : 2.65, KL : 5.04
Step 2200 - MSE : 2.53, KL : 5.07
Step 2300 - MSE : 4.43, KL : 5.11
Step 2400 - MSE : 2.41, KL : 5.12
Step 2500 - MSE : 3.41, KL : 5.14
Step 2600 - MSE : 3.27, KL : 5.16
Step 2700 - MSE : 2.27, KL : 5.18
Step 2800 - MSE : 2.45, KL : 5.19
Step 2900 - MSE : 2.49, KL : 5.17
Step 3000 - MSE : 2.47, KL : 5.15
Step 3100 - MSE : 2.46, KL : 5.15
Step 3200 - MSE : 2.34, KL : 5.12
Step 3300 - MSE : 2.44, KL : 5.09
Step 3400 - MSE : 2.44, KL : 5.05
Step 3500 - MSE : 2.37, KL : 5.02
Step 3600 - MSE : 2.44, KL : 5.00
Step 3700 - MSE : 2.45, KL : 4.96
Step 3800 - MSE : 2.45, KL : 4.94
Step 3900 - MSE : 2.45, KL : 4.90
Step 4000 - MSE : 2.46, KL : 4.88
Step 4100 - MSE : 2.38, KL : 4.82
Step 4200 - MSE : 2.45, KL : 4.79
Step 4300 - MSE : 2.36, KL : 4.86
Step 4400 - MSE : 2.47, KL : 4.81
Step 4500 - MSE : 2.45, KL : 4.77
Step 4600 - MSE : 2.43, KL : 4.70
Step 4700 - MSE : 2.45, KL : 4.66
Step 4800 - MSE : 2.45, KL : 4.59
Step 4900 - MSE : 2.35, KL : 4.57
Step 5000 - MSE : 2.45, KL : 4.53
Step 5100 - MSE : 2.45, KL : 4.48
Step 5200 - MSE : 2.44, KL : 4.41
Step 5300 - MSE : 2.29, KL : 4.36
Step 5400 - MSE : 2.46, KL : 4.33
Step 5500 - MSE : 2.37, KL : 4.31
Step 5600 - MSE : 2.46, KL : 4.37
Step 5700 - MSE : 2.45, KL : 4.30
Step 5800 - MSE : 2.45, KL : 4.26
Step 5900 - MSE : 2.42, KL : 4.20
Step 6000 - MSE : 2.45, KL : 4.18
Step 6100 - MSE : 2.28, KL : 4.10
Step 6200 - MSE : 2.47, KL : 4.05
Step 6300 - MSE : 2.32, KL : 4.03
Step 6400 - MSE : 2.26, KL : 4.03
Step 6500 - MSE : 2.34, KL : 3.98
Step 6600 - MSE : 2.24, KL : 3.95
Step 6700 - MSE : 2.25, KL : 3.99
Step 6800 - MSE : 2.42, KL : 3.95
Step 6900 - MSE : 2.31, KL : 3.92
Step 7000 - MSE : 2.18, KL : 3.91
Step 7100 - MSE : 2.23, KL : 3.87
Step 7200 - MSE : 2.41, KL : 3.84
Step 7300 - MSE : 2.38, KL : 3.88
Step 7400 - MSE : 2.26, KL : 3.85
Step 7500 - MSE : 2.19, KL : 3.96
Step 7600 - MSE : 2.19, KL : 3.92
Step 7700 - MSE : 2.18, KL : 3.89
Step 7800 - MSE : 2.21, KL : 3.85
Step 7900 - MSE : 2.21, KL : 3.86
Step 8000 - MSE : 2.21, KL : 3.85
Step 8100 - MSE : 2.24, KL : 3.80
Step 8200 - MSE : 2.21, KL : 3.79
Step 8300 - MSE : 2.41, KL : 3.75
Step 8400 - MSE : 2.19, KL : 3.72
Step 8500 - MSE : 2.17, KL : 3.68
Step 8600 - MSE : 2.18, KL : 3.64
Step 8700 - MSE : 2.28, KL : 3.62
Step 8800 - MSE : 2.26, KL : 3.70
Step 8900 - MSE : 2.24, KL : 3.69
Step 9000 - MSE : 2.17, KL : 3.62
Step 9100 - MSE : 2.18, KL : 3.54
Step 9200 - MSE : 2.16, KL : 3.60
Step 9300 - MSE : 2.46, KL : 3.53
Step 9400 - MSE : 2.17, KL : 3.67
Step 9500 - MSE : 2.16, KL : 3.59
Step 9600 - MSE : 2.17, KL : 3.50
Step 9700 - MSE : 2.25, KL : 3.50
Step 9800 - MSE : 2.20, KL : 3.41
Step 9900 - MSE : 2.16, KL : 3.36
#+end_example
[[./.ob-jupyter/9c37fb3ec4847bacd29bb877a4c1b9e98e0271cc.png]]
:END:

#+begin_src jupyter-python :kernel iotvar_powerprofiler
# Model evaluation with prediction intervals
model.eval()
num_samples = 1000  # Number of samples to draw from the model

with torch.no_grad():
    predictions_samples = [model(X_test).unsqueeze(0) for _ in range(num_samples)]
    predictions_samples = torch.cat(predictions_samples, 0)

# Calculate mean and prediction intervals
pred_mean = predictions_samples.mean(0)
pred_std = predictions_samples.std(0)
pred_interval_low = pred_mean - 1.96 * pred_std  # 95% prediction interval
pred_interval_high = pred_mean + 1.96 * pred_std

# Convert predictions and true values to numpy for easier plotting
pred_mean_np = pred_mean.numpy()
pred_interval_low_np = pred_interval_low.numpy()
pred_interval_high_np = pred_interval_high.numpy()
Y_test_np = Y_test.numpy()

# Plot predictions vs real data with prediction intervals for 'm'
plt.figure(figsize=(10, 5))
plt.plot(pred_mean_np[:, 0], label='Predicted m')
plt.fill_between(range(len(pred_mean_np[:, 0])), pred_interval_low_np[:, 0], pred_interval_high_np[:, 0], color='blue', alpha=0.2, label='95% Prediction Interval')
plt.plot(Y_test_np[:, 0], label='True m', linestyle='dashed')
plt.xlabel('Sample')
plt.ylabel('Value of m')
plt.title('Predicted vs True values of m with Prediction Intervals')
plt.legend()
plt.show()

# Plot predictions vs real data with prediction intervals for 'b'
plt.figure(figsize=(10, 5))
plt.plot(pred_mean_np[:, 1], label='Predicted b')
plt.fill_between(range(len(pred_mean_np[:, 1])), pred_interval_low_np[:, 1], pred_interval_high_np[:, 1], color='blue', alpha=0.2, label='95% Prediction Interval')
plt.plot(Y_test_np[:, 1], label='True b', linestyle='dashed')
plt.xlabel('Sample')
plt.ylabel('Value of b')
plt.title('Predicted vs True values of b with Prediction Intervals')
plt.legend()
plt.show()
#+end_src

#+RESULTS:
:RESULTS:
[[./.ob-jupyter/eb524efc644b4f8d48a04f7f948bd47507d97bc8.png]]
[[./.ob-jupyter/b96642e3c699f668207e1eb6f4d5af3e029eeb8a.png]]
:END:

#+begin_src jupyter-python :kernel iotvar_powerprofiler
model.eval()
num_samples = 10000  # Number of samples to draw from the model

with torch.no_grad():
    predictions_samples = [model(X_test).unsqueeze(0) for _ in range(num_samples)]
    predictions_samples = torch.cat(predictions_samples, 0)

# Calculate mean and prediction intervals
pred_mean = predictions_samples.mean(0)
pred_std = predictions_samples.std(0)
pred_interval_low = pred_mean - 1.96 * pred_std  # 95% prediction interval
pred_interval_high = pred_mean + 1.96 * pred_std

# Convert predictions and true values to numpy for easier plotting
pred_mean_np = pred_mean.numpy()
pred_interval_low_np = pred_interval_low.numpy()
pred_interval_high_np = pred_interval_high.numpy()
Y_test_np = Y_test.numpy()
X_test_np = X_test.numpy()

# Plot predictions vs real data with prediction intervals for 'm' against 'refresh_period'
plt.figure(figsize=(10, 5))
plt.plot(X_test_np[:, 0], pred_mean_np[:, 0], 'o', label='Predicted m')
#plt.fill_between(X_test_np[:, 0], pred_interval_low_np[:, 0], pred_interval_high_np[:, 0], color='blue', alpha=0.2, label='95% Prediction Interval')
plt.plot(X_test_np[:, 0], Y_test_np[:, 0], 'x', label='True m')
plt.xlabel('Refresh Period')
plt.ylabel('Value of m')
plt.title('Predicted vs True values of m with Prediction Intervals')
plt.legend()
plt.show()

# Plot predictions vs real data with prediction intervals for 'm' against 'number_sensors'
plt.figure(figsize=(10, 5))
plt.plot(X_test_np[:, 1], pred_mean_np[:, 0], 'o', label='Predicted m')
#plt.fill_between(X_test_np[:, 1], pred_interval_low_np[:, 0], pred_interval_high_np[:, 0], color='blue', alpha=0.2, label='95% Prediction Interval')
plt.plot(X_test_np[:, 1], Y_test_np[:, 0], 'x', label='True m')
plt.xlabel('Number of Sensors')
plt.ylabel('Value of m')
plt.title('Predicted vs True values of m with Prediction Intervals')
plt.legend()
plt.show()

# Plot predictions vs real data with prediction intervals for 'b' against 'refresh_period'
plt.figure(figsize=(10, 5))
plt.plot(X_test_np[:, 0], pred_mean_np[:, 1], 'o', label='Predicted b')
#plt.fill_between(X_test_np[:, 0], pred_interval_low_np[:, 1], pred_interval_high_np[:, 1], color='blue', alpha=0.2, label='95% Prediction Interval')
plt.plot(X_test_np[:, 0], Y_test_np[:, 1], 'x', label='True b')
plt.xlabel('Refresh Period')
plt.ylabel('Value of b')
plt.title('Predicted vs True values of b with Prediction Intervals')
plt.legend()
plt.show()

# Plot predictions vs real data with prediction intervals for 'b' against 'number_sensors'
plt.figure(figsize=(10, 5))
plt.plot(X_test_np[:, 1], pred_mean_np[:, 1], 'o', label='Predicted b')
#plt.fill_between(X_test_np[:, 1], pred_interval_low_np[:, 1], pred_interval_high_np[:, 1], color='blue', alpha=0.2, label='95% Prediction Interval')
plt.plot(X_test_np[:, 1], Y_test_np[:, 1], 'x', label='True b')
plt.xlabel('Number of Sensors'); plt.ylabel('Value of b')
plt.title('Predicted vs True values of b with Prediction Intervals')
plt.legend()
plt.show()
#+end_src

#+RESULTS:
:RESULTS:
[[./.ob-jupyter/68b9413bb5e6dde3bed0ddb9943633b3bc6fccbc.png]]
[[./.ob-jupyter/26c183b70dc3676536834736bfc60a5ebd110005.png]]
[[./.ob-jupyter/fa869515d857d9a09edf2d592f0912339daff7d5.png]]
[[./.ob-jupyter/a752a65f15d8cd07642c4d31ad48e2b788836b22.png]]
:END:
** Individual
*** m
#+begin_src jupyter-python :kernel iotvar_powerprofiler
X = np.zeros([len(m_b_df['number_sensors']),2])
X[:,0] = np.array(m_b_df['refresh_period'])
X[:,1] = np.array(m_b_df['number_sensors'])
y_m = np.array(m_b_df['m'])
#y_b = np.array(m_b_df['b'])
Y = y_m

X_t = torch.from_numpy(X)
y_m_t = torch.from_numpy(y_m)
#y_b_t = torch.from_numpy(y_b)
Y_t = torch.from_numpy(Y)

X_train, X_test, Y_train, Y_test = train_test_split(X_t, Y_t, test_size=0.1, random_state=42)

Y_train = Y_train[:,None]
Y_test = Y_test[:,None]

X_train = X_train.float()
X_test = X_test.float()
Y_train = Y_train.float()
Y_test = Y_test.float()

model = nn.Sequential(
    bnn.BayesLinear(prior_mu=0, prior_sigma=0.1, in_features=2, out_features=50),
    nn.ReLU(),
    bnn.BayesLinear(prior_mu=0, prior_sigma=0.1, in_features=50, out_features=1),
)

mse_loss = nn.MSELoss()
kl_loss = bnn.BKLLoss(reduction='mean', last_layer_only=False)
kl_weight = 0.01

optimizer = optim.Adam(model.parameters(), lr=0.01)

# Lists to store the loss values
mse_list = []
kl_list = []
total_loss_list = []

# Training loop
for step in range(10000):
    model.train()
    pre = model(X_train)
    mse = mse_loss(pre, Y_train)
    kl = kl_loss(model)
    cost = mse + kl_weight * kl

    optimizer.zero_grad()
    cost.backward()
    optimizer.step()

    # Store the loss values
    mse_list.append(mse.item())
    kl_list.append(kl.item())
    total_loss_list.append(cost.item())

    if step % 100 == 0:
        print(f'Step {step} - MSE : {mse.item():.2f}, KL : {kl.item():.2f}')

plt.figure(figsize=(10, 5))
plt.plot(mse_list, label='MSE Loss')
plt.plot(kl_list, label='KL Loss')
plt.plot(total_loss_list, label='Total Loss')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.title('Loss Function Evolution')
plt.legend()
plt.show()

#+end_src

#+RESULTS:
:RESULTS:
#+begin_example
Step 0 - MSE : 491.05, KL : 7.00
Step 100 - MSE : 96.91, KL : 4.97
Step 200 - MSE : 259.80, KL : 4.78
Step 300 - MSE : 13.09, KL : 4.80
Step 400 - MSE : 10.64, KL : 4.72
Step 500 - MSE : 2.80, KL : 4.80
Step 600 - MSE : 2.41, KL : 4.85
Step 700 - MSE : 2.32, KL : 4.91
Step 800 - MSE : 4.14, KL : 4.96
Step 900 - MSE : 1.83, KL : 5.04
Step 1000 - MSE : 2.72, KL : 5.05
Step 1100 - MSE : 2.79, KL : 5.13
Step 1200 - MSE : 4.03, KL : 5.20
Step 1300 - MSE : 1.02, KL : 5.17
Step 1400 - MSE : 2.71, KL : 5.24
Step 1500 - MSE : 1.19, KL : 5.35
Step 1600 - MSE : 0.85, KL : 5.39
Step 1700 - MSE : 2.73, KL : 5.45
Step 1800 - MSE : 0.63, KL : 5.46
Step 1900 - MSE : 0.16, KL : 5.58
Step 2000 - MSE : 0.51, KL : 5.56
Step 2100 - MSE : 0.61, KL : 5.59
Step 2200 - MSE : 0.51, KL : 5.73
Step 2300 - MSE : 0.23, KL : 5.74
Step 2400 - MSE : 0.06, KL : 5.70
Step 2500 - MSE : 0.08, KL : 5.67
Step 2600 - MSE : 0.07, KL : 5.63
Step 2700 - MSE : 0.14, KL : 5.67
Step 2800 - MSE : 0.10, KL : 5.67
Step 2900 - MSE : 0.11, KL : 5.72
Step 3000 - MSE : 0.02, KL : 5.69
Step 3100 - MSE : 0.04, KL : 5.69
Step 3200 - MSE : 0.01, KL : 5.66
Step 3300 - MSE : 3.27, KL : 5.61
Step 3400 - MSE : 0.04, KL : 5.58
Step 3500 - MSE : 0.03, KL : 5.57
Step 3600 - MSE : 0.02, KL : 5.54
Step 3700 - MSE : 0.02, KL : 5.49
Step 3800 - MSE : 0.04, KL : 5.44
Step 3900 - MSE : 0.03, KL : 5.50
Step 4000 - MSE : 0.02, KL : 5.51
Step 4100 - MSE : 0.03, KL : 5.49
Step 4200 - MSE : 0.01, KL : 5.42
Step 4300 - MSE : 0.03, KL : 5.40
Step 4400 - MSE : 0.03, KL : 5.35
Step 4500 - MSE : 0.06, KL : 5.28
Step 4600 - MSE : 0.03, KL : 5.23
Step 4700 - MSE : 0.03, KL : 5.20
Step 4800 - MSE : 0.03, KL : 5.12
Step 4900 - MSE : 0.03, KL : 5.06
Step 5000 - MSE : 0.03, KL : 5.02
Step 5100 - MSE : 0.02, KL : 4.99
Step 5200 - MSE : 0.03, KL : 4.92
Step 5300 - MSE : 0.03, KL : 4.93
Step 5400 - MSE : 0.01, KL : 4.90
Step 5500 - MSE : 0.02, KL : 4.84
Step 5600 - MSE : 0.03, KL : 4.77
Step 5700 - MSE : 0.02, KL : 4.76
Step 5800 - MSE : 0.04, KL : 4.70
Step 5900 - MSE : 0.03, KL : 4.73
Step 6000 - MSE : 0.03, KL : 4.67
Step 6100 - MSE : 0.01, KL : 4.62
Step 6200 - MSE : 0.02, KL : 4.57
Step 6300 - MSE : 0.03, KL : 4.37
Step 6400 - MSE : 0.03, KL : 4.32
Step 6500 - MSE : 0.22, KL : 4.31
Step 6600 - MSE : 0.01, KL : 4.32
Step 6700 - MSE : 0.01, KL : 4.31
Step 6800 - MSE : 0.02, KL : 4.28
Step 6900 - MSE : 0.03, KL : 4.11
Step 7000 - MSE : 0.02, KL : 4.10
Step 7100 - MSE : 0.01, KL : 4.12
Step 7200 - MSE : 0.01, KL : 4.18
Step 7300 - MSE : 0.02, KL : 4.15
Step 7400 - MSE : 0.01, KL : 4.08
Step 7500 - MSE : 0.02, KL : 4.04
Step 7600 - MSE : 0.01, KL : 3.97
Step 7700 - MSE : 0.01, KL : 3.91
Step 7800 - MSE : 0.01, KL : 3.95
Step 7900 - MSE : 0.01, KL : 3.89
Step 8000 - MSE : 0.02, KL : 3.83
Step 8100 - MSE : 0.01, KL : 3.77
Step 8200 - MSE : 0.01, KL : 3.82
Step 8300 - MSE : 0.01, KL : 3.73
Step 8400 - MSE : 0.02, KL : 3.66
Step 8500 - MSE : 0.01, KL : 3.62
Step 8600 - MSE : 0.02, KL : 3.57
Step 8700 - MSE : 0.01, KL : 3.62
Step 8800 - MSE : 0.01, KL : 3.55
Step 8900 - MSE : 0.01, KL : 3.47
Step 9000 - MSE : 0.01, KL : 3.41
Step 9100 - MSE : 0.01, KL : 3.35
Step 9200 - MSE : 0.01, KL : 3.30
Step 9300 - MSE : 0.01, KL : 3.29
Step 9400 - MSE : 0.01, KL : 3.25
Step 9500 - MSE : 0.02, KL : 3.22
Step 9600 - MSE : 0.01, KL : 3.29
Step 9700 - MSE : 0.01, KL : 3.25
Step 9800 - MSE : 0.01, KL : 3.24
Step 9900 - MSE : 0.01, KL : 3.22
#+end_example
[[./.ob-jupyter/5ef5b4ae0cf9d72e3cdf8bd9c24de62ce829be01.png]]
:END:

#+begin_src jupyter-python :kernel iotvar_powerprofiler
# Model evaluation with prediction intervals
model.eval()
num_samples = 1000  # Number of samples to draw from the model

with torch.no_grad():
    predictions_samples = [model(X_test).unsqueeze(0) for _ in range(num_samples)]
    predictions_samples = torch.cat(predictions_samples, 0)

# Calculate mean and prediction intervals
pred_mean = predictions_samples.mean(0)
pred_std = predictions_samples.std(0)
pred_interval_low = pred_mean - 1.96 * pred_std  # 95% prediction interval
pred_interval_high = pred_mean + 1.96 * pred_std

# Convert predictions and true values to numpy for easier plotting
pred_mean_np = pred_mean.numpy()
pred_interval_low_np = pred_interval_low.numpy()
pred_interval_high_np = pred_interval_high.numpy()
Y_test_np = Y_test.numpy()

# Plot predictions vs real data with prediction intervals for 'm'
plt.figure(figsize=(10, 5))
plt.plot(pred_mean_np[:, 0], label='Predicted m')
plt.fill_between(range(len(pred_mean_np[:, 0])), pred_interval_low_np[:, 0], pred_interval_high_np[:, 0], color='blue', alpha=0.2, label='95% Prediction Interval')
plt.plot(Y_test_np[:, 0], label='True m', linestyle='dashed')
plt.xlabel('Sample')
plt.ylabel('Value of m')
plt.title('Predicted vs True values of m with Prediction Intervals')
plt.legend()
plt.show()
#+end_src

#+RESULTS:
[[./.ob-jupyter/6af816d6dde82fa38b686cf987df02dd17c9a8b8.png]]
*** b

#+begin_src jupyter-python :kernel iotvar_powerprofiler
X = np.zeros([len(m_b_df['number_sensors']),2])
X[:,0] = np.array(m_b_df['refresh_period'])
X[:,1] = np.array(m_b_df['number_sensors'])
#y_m = np.array(m_b_df['m'])
y_b = np.array(m_b_df['b'])
Y = y_b

X_t = torch.from_numpy(X)
#y_m_t = torch.from_numpy(y_m)
y_b_t = torch.from_numpy(y_b)
Y_t = torch.from_numpy(Y)

X_train, X_test, Y_train, Y_test = train_test_split(X_t, Y_t, test_size=0.1, random_state=42)

Y_train = Y_train[:,None]
Y_test = Y_test[:,None]

X_train = X_train.float()
X_test = X_test.float()
Y_train = Y_train.float()
Y_test = Y_test.float()

model = nn.Sequential(
    bnn.BayesLinear(prior_mu=0, prior_sigma=0.1, in_features=2, out_features=50),
    nn.ReLU(),
    #nn.Tanh(),
    bnn.BayesLinear(prior_mu=0, prior_sigma=0.1, in_features=50, out_features=1),
)

mse_loss = nn.MSELoss()
kl_loss = bnn.BKLLoss(reduction='mean', last_layer_only=False)
kl_weight = 0.0016023335316591755

optimizer = optim.Adam(model.parameters(), lr=0.003963960907992951)

# Lists to store the loss values
mse_list = []
kl_list = []
total_loss_list = []

# Training loop
for step in range(10000):
    model.train()
    pre = model(X_train)
    mse = mse_loss(pre, Y_train)
    kl = kl_loss(model)
    cost = mse + kl_weight * kl

    optimizer.zero_grad()
    cost.backward()
    optimizer.step()

    # Store the loss values
    mse_list.append(mse.item())
    kl_list.append(kl.item())
    total_loss_list.append(cost.item())

    if step % 100 == 0:
        print(f'Step {step} - MSE : {mse.item():.2f}, KL : {kl.item():.2f}')

plt.figure(figsize=(10, 5))
plt.plot(mse_list, label='MSE Loss')
plt.plot(kl_list, label='KL Loss')
plt.plot(total_loss_list, label='Total Loss')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.title('Loss Function Evolution')
plt.legend()
plt.show()

#+end_src

#+RESULTS:
:RESULTS:
#+begin_example
Step 0 - MSE : 1504.37, KL : 6.94
Step 100 - MSE : 39.16, KL : 4.84
Step 200 - MSE : 25.57, KL : 4.64
Step 300 - MSE : 162.73, KL : 4.56
Step 400 - MSE : 94.72, KL : 4.59
Step 500 - MSE : 400.26, KL : 4.53
Step 600 - MSE : 172.18, KL : 4.59
Step 700 - MSE : 10.38, KL : 4.62
Step 800 - MSE : 224.36, KL : 4.72
Step 900 - MSE : 296.01, KL : 4.77
Step 1000 - MSE : 37.56, KL : 4.84
Step 1100 - MSE : 31.09, KL : 4.90
Step 1200 - MSE : 7.06, KL : 4.95
Step 1300 - MSE : 14.73, KL : 5.00
Step 1400 - MSE : 18.59, KL : 5.03
Step 1500 - MSE : 10.20, KL : 5.10
Step 1600 - MSE : 8.04, KL : 5.15
Step 1700 - MSE : 15.75, KL : 5.22
Step 1800 - MSE : 30.81, KL : 5.27
Step 1900 - MSE : 5.77, KL : 5.36
Step 2000 - MSE : 6.77, KL : 5.42
Step 2100 - MSE : 6.47, KL : 5.45
Step 2200 - MSE : 23.24, KL : 5.52
Step 2300 - MSE : 5.11, KL : 5.56
Step 2400 - MSE : 5.44, KL : 5.59
Step 2500 - MSE : 5.49, KL : 5.62
Step 2600 - MSE : 5.51, KL : 5.67
Step 2700 - MSE : 5.60, KL : 5.71
Step 2800 - MSE : 7.25, KL : 5.74
Step 2900 - MSE : 4.89, KL : 5.78
Step 3000 - MSE : 4.85, KL : 5.80
Step 3100 - MSE : 4.67, KL : 5.82
Step 3200 - MSE : 4.80, KL : 5.85
Step 3300 - MSE : 5.46, KL : 5.87
Step 3400 - MSE : 4.68, KL : 5.89
Step 3500 - MSE : 5.01, KL : 5.91
Step 3600 - MSE : 5.35, KL : 5.94
Step 3700 - MSE : 4.50, KL : 5.98
Step 3800 - MSE : 4.47, KL : 6.00
Step 3900 - MSE : 5.70, KL : 6.02
Step 4000 - MSE : 4.96, KL : 6.04
Step 4100 - MSE : 5.11, KL : 6.06
Step 4200 - MSE : 5.47, KL : 6.08
Step 4300 - MSE : 4.45, KL : 6.11
Step 4400 - MSE : 4.93, KL : 6.13
Step 4500 - MSE : 4.60, KL : 6.15
Step 4600 - MSE : 5.83, KL : 6.16
Step 4700 - MSE : 5.91, KL : 6.18
Step 4800 - MSE : 4.53, KL : 6.20
Step 4900 - MSE : 4.87, KL : 6.21
Step 5000 - MSE : 4.51, KL : 6.22
Step 5100 - MSE : 5.03, KL : 6.23
Step 5200 - MSE : 4.69, KL : 6.22
Step 5300 - MSE : 4.79, KL : 6.23
Step 5400 - MSE : 4.60, KL : 6.23
Step 5500 - MSE : 4.92, KL : 6.24
Step 5600 - MSE : 5.00, KL : 6.24
Step 5700 - MSE : 4.66, KL : 6.26
Step 5800 - MSE : 4.84, KL : 6.27
Step 5900 - MSE : 4.54, KL : 6.26
Step 6000 - MSE : 4.85, KL : 6.27
Step 6100 - MSE : 8.43, KL : 6.30
Step 6200 - MSE : 4.57, KL : 6.30
Step 6300 - MSE : 4.86, KL : 6.30
Step 6400 - MSE : 4.72, KL : 6.31
Step 6500 - MSE : 4.72, KL : 6.32
Step 6600 - MSE : 4.41, KL : 6.31
Step 6700 - MSE : 4.62, KL : 6.32
Step 6800 - MSE : 4.58, KL : 6.35
Step 6900 - MSE : 4.57, KL : 6.34
Step 7000 - MSE : 4.67, KL : 6.38
Step 7100 - MSE : 4.61, KL : 6.40
Step 7200 - MSE : 4.60, KL : 6.41
Step 7300 - MSE : 4.52, KL : 6.44
Step 7400 - MSE : 4.48, KL : 6.44
Step 7500 - MSE : 4.51, KL : 6.44
Step 7600 - MSE : 4.51, KL : 6.47
Step 7700 - MSE : 4.52, KL : 6.48
Step 7800 - MSE : 4.61, KL : 6.50
Step 7900 - MSE : 4.46, KL : 6.51
Step 8000 - MSE : 4.66, KL : 6.54
Step 8100 - MSE : 4.48, KL : 6.56
Step 8200 - MSE : 4.48, KL : 6.56
Step 8300 - MSE : 4.50, KL : 6.59
Step 8400 - MSE : 4.51, KL : 6.63
Step 8500 - MSE : 4.80, KL : 6.65
Step 8600 - MSE : 4.48, KL : 6.65
Step 8700 - MSE : 4.64, KL : 6.65
Step 8800 - MSE : 4.60, KL : 6.67
Step 8900 - MSE : 4.46, KL : 6.71
Step 9000 - MSE : 4.42, KL : 6.72
Step 9100 - MSE : 4.36, KL : 6.73
Step 9200 - MSE : 4.48, KL : 6.74
Step 9300 - MSE : 4.55, KL : 6.73
Step 9400 - MSE : 4.38, KL : 6.73
Step 9500 - MSE : 4.67, KL : 6.74
Step 9600 - MSE : 4.37, KL : 6.73
Step 9700 - MSE : 4.36, KL : 6.72
Step 9800 - MSE : 4.38, KL : 6.71
Step 9900 - MSE : 4.43, KL : 6.68
#+end_example
[[./.ob-jupyter/399b71c21ec5cc9ca6266396ffb08404dca98813.png]]
:END:

#+begin_src jupyter-python :kernel iotvar_powerprofiler
# Model evaluation with prediction intervals
model.eval()
num_samples = 1000  # Number of samples to draw from the model

with torch.no_grad():
    predictions_samples = [model(X_test).unsqueeze(0) for _ in range(num_samples)]
    predictions_samples = torch.cat(predictions_samples, 0)

# Calculate mean and prediction intervals
pred_mean = predictions_samples.mean(0)
pred_std = predictions_samples.std(0)
pred_interval_low = pred_mean - 1.96 * pred_std  # 95% prediction interval
pred_interval_high = pred_mean + 1.96 * pred_std

# Convert predictions and true values to numpy for easier plotting
pred_mean_np = pred_mean.numpy()
pred_interval_low_np = pred_interval_low.numpy()
pred_interval_high_np = pred_interval_high.numpy()
Y_test_np = Y_test.numpy()


# Plot predictions vs real data with prediction intervals for 'b'
plt.figure(figsize=(10, 5))
plt.plot(pred_mean_np[:, 0], label='Predicted b')
plt.fill_between(range(len(pred_mean_np[:, 0])), pred_interval_low_np[:, 0], pred_interval_high_np[:, 0], color='blue', alpha=0.2, label='95% Prediction Interval')
plt.plot(Y_test_np[:, 0], label='True b', linestyle='dashed')
plt.xlabel('Sample')
plt.ylabel('Value of b')
plt.title('Predicted vs True values of b with Prediction Intervals')
plt.legend()
plt.show()
#+end_src

#+RESULTS:
[[./.ob-jupyter/0fb7c0309b6afbab545afd62286b3785eb8eade6.png]]

#+begin_src jupyter-python :kernel iotvar_powerprofiler
import torch
import torch.nn as nn
import torch.optim as optim
import torch.utils.data as data
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
import numpy as np

# Assuming m_b_df is a DataFrame with the relevant data
X = np.zeros([len(m_b_df['number_sensors']), 2])
X[:, 0] = np.array(m_b_df['refresh_period'])
X[:, 1] = np.array(m_b_df['number_sensors'])
y_b = np.array(m_b_df['b'])

X_t = torch.from_numpy(X).float()
y_b_t = torch.from_numpy(y_b).float()

X_train, X_test, Y_train, Y_test = train_test_split(X_t, y_b_t, test_size=0.1, random_state=42)

# Convert to datasets and dataloaders
train_dataset = data.TensorDataset(X_train, Y_train)
train_loader = data.DataLoader(train_dataset, batch_size=32, shuffle=True)
test_dataset = data.TensorDataset(X_test, Y_test)
test_loader = data.DataLoader(test_dataset, batch_size=32, shuffle=False)

class BayesianNN(nn.Module):
    def __init__(self):
        super(BayesianNN, self).__init__()
        self.layer1 = bnn.BayesLinear(prior_mu=0, prior_sigma=0.1, in_features=2, out_features=200)
        self.layer2 = bnn.BayesLinear(prior_mu=0, prior_sigma=0.1, in_features=200, out_features=200)
        self.layer3 = bnn.BayesLinear(prior_mu=0, prior_sigma=0.1, in_features=200, out_features=1)
        self.relu = nn.ReLU()
        self.dropout = nn.Dropout(0.5)

    def forward(self, x):
        x = self.relu(self.layer1(x))
        x = self.dropout(x)
        x = self.relu(self.layer2(x))
        x = self.dropout(x)
        return self.layer3(x)

model = BayesianNN()
mse_loss = nn.MSELoss()
kl_loss = bnn.BKLLoss(reduction='mean', last_layer_only=False)
kl_weight = 0.01
optimizer = optim.Adam(model.parameters(), lr=0.001)

# Lists to store the loss values
mse_list = []
kl_list = []
total_loss_list = []

# Training loop
for epoch in range(500):
    model.train()
    running_mse_loss = 0.0
    running_kl_loss = 0.0
    running_total_loss = 0.0

    for X_batch, Y_batch in train_loader:
        pre = model(X_batch)
        mse = mse_loss(pre, Y_batch[:, None])
        kl = kl_loss(model)
        cost = mse + kl_weight * kl

        optimizer.zero_grad()
        cost.backward()
        optimizer.step()

        running_mse_loss += mse.item() * X_batch.size(0)
        running_kl_loss += kl.item() * X_batch.size(0)
        running_total_loss += cost.item() * X_batch.size(0)

    epoch_mse_loss = running_mse_loss / len(train_loader.dataset)
    epoch_kl_loss = running_kl_loss / len(train_loader.dataset)
    epoch_total_loss = running_total_loss / len(train_loader.dataset)

    mse_list.append(epoch_mse_loss)
    kl_list.append(epoch_kl_loss)
    total_loss_list.append(epoch_total_loss)

    if epoch % 10 == 0:
        print(f'Epoch {epoch} - MSE : {epoch_mse_loss:.2f}, KL : {epoch_kl_loss:.2f}, Total Loss: {epoch_total_loss:.2f}')

plt.figure(figsize=(10, 5))
plt.plot(mse_list, label='MSE Loss')
plt.plot(kl_list, label='KL Loss')
plt.plot(total_loss_list, label='Total Loss')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.title('Loss Function Evolution')
plt.legend()
plt.show()

#+end_src

#+RESULTS:
:RESULTS:
#+begin_example
Epoch 0 - MSE : 9893.88, KL : 0.19, Total Loss: 9893.88
Epoch 10 - MSE : 1261.12, KL : 0.16, Total Loss: 1261.12
Epoch 20 - MSE : 404.25, KL : 0.17, Total Loss: 404.25
Epoch 30 - MSE : 144.96, KL : 0.18, Total Loss: 144.96
Epoch 40 - MSE : 96.10, KL : 0.19, Total Loss: 96.10
Epoch 50 - MSE : 71.99, KL : 0.19, Total Loss: 71.99
Epoch 60 - MSE : 39.18, KL : 0.20, Total Loss: 39.18
Epoch 70 - MSE : 32.50, KL : 0.20, Total Loss: 32.50
Epoch 80 - MSE : 22.42, KL : 0.21, Total Loss: 22.43
Epoch 90 - MSE : 28.68, KL : 0.21, Total Loss: 28.68
Epoch 100 - MSE : 23.98, KL : 0.21, Total Loss: 23.98
Epoch 110 - MSE : 18.58, KL : 0.22, Total Loss: 18.58
Epoch 120 - MSE : 9.66, KL : 0.22, Total Loss: 9.67
Epoch 130 - MSE : 13.05, KL : 0.23, Total Loss: 13.05
Epoch 140 - MSE : 9.55, KL : 0.23, Total Loss: 9.55
Epoch 150 - MSE : 8.49, KL : 0.24, Total Loss: 8.50
Epoch 160 - MSE : 9.19, KL : 0.24, Total Loss: 9.20
Epoch 170 - MSE : 7.51, KL : 0.24, Total Loss: 7.51
Epoch 180 - MSE : 6.50, KL : 0.25, Total Loss: 6.50
Epoch 190 - MSE : 5.66, KL : 0.25, Total Loss: 5.66
Epoch 200 - MSE : 6.54, KL : 0.25, Total Loss: 6.55
Epoch 210 - MSE : 5.63, KL : 0.26, Total Loss: 5.63
Epoch 220 - MSE : 5.84, KL : 0.26, Total Loss: 5.85
Epoch 230 - MSE : 6.42, KL : 0.26, Total Loss: 6.43
Epoch 240 - MSE : 5.02, KL : 0.26, Total Loss: 5.03
Epoch 250 - MSE : 5.03, KL : 0.27, Total Loss: 5.03
Epoch 260 - MSE : 5.18, KL : 0.27, Total Loss: 5.18
Epoch 270 - MSE : 5.15, KL : 0.27, Total Loss: 5.16
Epoch 280 - MSE : 5.09, KL : 0.27, Total Loss: 5.10
Epoch 290 - MSE : 5.15, KL : 0.28, Total Loss: 5.15
Epoch 300 - MSE : 4.93, KL : 0.28, Total Loss: 4.93
Epoch 310 - MSE : 4.95, KL : 0.28, Total Loss: 4.95
Epoch 320 - MSE : 5.14, KL : 0.28, Total Loss: 5.14
Epoch 330 - MSE : 4.91, KL : 0.28, Total Loss: 4.92
Epoch 340 - MSE : 5.01, KL : 0.29, Total Loss: 5.01
Epoch 350 - MSE : 4.90, KL : 0.29, Total Loss: 4.90
Epoch 360 - MSE : 4.84, KL : 0.29, Total Loss: 4.85
Epoch 370 - MSE : 4.89, KL : 0.29, Total Loss: 4.89
Epoch 380 - MSE : 5.14, KL : 0.29, Total Loss: 5.15
Epoch 390 - MSE : 4.89, KL : 0.29, Total Loss: 4.89
Epoch 400 - MSE : 4.89, KL : 0.29, Total Loss: 4.89
Epoch 410 - MSE : 4.86, KL : 0.30, Total Loss: 4.87
Epoch 420 - MSE : 4.89, KL : 0.30, Total Loss: 4.89
Epoch 430 - MSE : 5.75, KL : 0.30, Total Loss: 5.75
Epoch 440 - MSE : 5.17, KL : 0.30, Total Loss: 5.18
Epoch 450 - MSE : 4.88, KL : 0.30, Total Loss: 4.88
Epoch 460 - MSE : 4.87, KL : 0.30, Total Loss: 4.87
Epoch 470 - MSE : 4.88, KL : 0.30, Total Loss: 4.88
Epoch 480 - MSE : 4.89, KL : 0.30, Total Loss: 4.89
Epoch 490 - MSE : 4.86, KL : 0.30, Total Loss: 4.86
#+end_example
[[./.ob-jupyter/62ef1a992cef72d87f24810e68943ce115033ea3.png]]
:END:

#+begin_src jupyter-python :kernel iotvar_powerprofiler
import optuna
import torch
import torch.nn as nn
import torch.optim as optim
import torch.utils.data as data
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
import numpy as np

# Assuming m_b_df is a DataFrame with the relevant data
X = np.zeros([len(m_b_df['number_sensors']), 2])
X[:, 0] = np.array(m_b_df['refresh_period'])
X[:, 1] = np.array(m_b_df['number_sensors'])
y_b = np.array(m_b_df['b'])

X_t = torch.from_numpy(X).float()
y_b_t = torch.from_numpy(y_b).float()

X_train, X_test, Y_train, Y_test = train_test_split(X_t, y_b_t, test_size=0.1, random_state=42)

# Convert to datasets and dataloaders
train_dataset = data.TensorDataset(X_train, Y_train)
train_loader = data.DataLoader(train_dataset, batch_size=32, shuffle=True)
test_dataset = data.TensorDataset(X_test, Y_test)
test_loader = data.DataLoader(test_dataset, batch_size=32, shuffle=False)

# Define the model
class BayesianNN(nn.Module):
    def __init__(self, layer_size, dropout_rate):
        super(BayesianNN, self).__init__()
        self.layer1 = bnn.BayesLinear(prior_mu=0, prior_sigma=0.1, in_features=2, out_features=layer_size)
        self.layer2 = bnn.BayesLinear(prior_mu=0, prior_sigma=0.1, in_features=layer_size, out_features=layer_size)
        self.layer3 = bnn.BayesLinear(prior_mu=0, prior_sigma=0.1, in_features=layer_size, out_features=1)
        self.relu = nn.ReLU()
        self.dropout = nn.Dropout(dropout_rate)

    def forward(self, x):
        x = self.relu(self.layer1(x))
        x = self.dropout(x)
        x = self.relu(self.layer2(x))
        x = self.dropout(x)
        return self.layer3(x)

# Objective function for Optuna
def objective(trial):
    layer_size = trial.suggest_int('layer_size', 50, 400)
    dropout_rate = trial.suggest_float('dropout_rate', 0.1, 0.5)
    lr = trial.suggest_float('lr', 1e-5, 1e-2, log=True)
    kl_weight = trial.suggest_float('kl_weight', 1e-3, 1e-1, log=True)

    model = BayesianNN(layer_size, dropout_rate)
    mse_loss = nn.MSELoss()
    kl_loss = bnn.BKLLoss(reduction='mean', last_layer_only=False)
    optimizer = optim.Adam(model.parameters(), lr=lr)

    num_epochs = 100
    for epoch in range(num_epochs):
        model.train()
        for X_batch, Y_batch in train_loader:
            pre = model(X_batch)
            mse = mse_loss(pre, Y_batch[:, None])
            kl = kl_loss(model)
            cost = mse + kl_weight * kl

            optimizer.zero_grad()
            cost.backward()
            optimizer.step()

    # Validation loss
    model.eval()
    total_val_loss = 0
    with torch.no_grad():
        for X_batch, Y_batch in test_loader:
            pre = model(X_batch)
            mse = mse_loss(pre, Y_batch[:, None])
            total_val_loss += mse.item() * X_batch.size(0)

    val_loss = total_val_loss / len(test_loader.dataset)
    return val_loss

# Run the optimization
study = optuna.create_study(direction='minimize')
study.optimize(objective, n_trials=50)

print("Best trial:")
trial = study.best_trial
print(f"Value: {trial.value}")
print("Params:")
for key, value in trial.params.items():
    print(f"    {key}: {value}")

# Plot optimization history
optuna.visualization.matplotlib.plot_optimization_history(study)
plt.show()

# Plot parameter importance
optuna.visualization.matplotlib.plot_param_importances(study)
plt.show()

#+end_src

#+RESULTS:
:RESULTS:
#+begin_example
[I 2024-06-03 02:23:47,419] A new study created in memory with name: no-name-bb627459-b58b-45f0-8004-cd3f78d2ffbb
[I 2024-06-03 02:23:58,532] Trial 0 finished with value: 5.106119891871577 and parameters: {'layer_size': 89, 'dropout_rate': 0.32406087841026665, 'lr': 0.0015562191204300472, 'kl_weight': 0.07949087595019862}. Best is trial 0 with value: 5.106119891871577.
[I 2024-06-03 02:24:11,344] Trial 1 finished with value: 1750.994615306025 and parameters: {'layer_size': 161, 'dropout_rate': 0.3924657358420538, 'lr': 6.133314256165668e-05, 'kl_weight': 0.007993711701417059}. Best is trial 0 with value: 5.106119891871577.
[I 2024-06-03 02:24:25,870] Trial 2 finished with value: 5.572264153024425 and parameters: {'layer_size': 219, 'dropout_rate': 0.14805232378063762, 'lr': 0.0008595056308699565, 'kl_weight': 0.03151959342218498}. Best is trial 0 with value: 5.106119891871577.
[I 2024-06-03 02:24:36,832] Trial 3 finished with value: 5.200768346371858 and parameters: {'layer_size': 76, 'dropout_rate': 0.4273266864891879, 'lr': 0.0010490328164234623, 'kl_weight': 0.013933839832724974}. Best is trial 0 with value: 5.106119891871577.
[I 2024-06-03 02:24:47,717] Trial 4 finished with value: 9.296508250029191 and parameters: {'layer_size': 83, 'dropout_rate': 0.21998640518364596, 'lr': 8.914104962486267e-05, 'kl_weight': 0.0011612276621803725}. Best is trial 0 with value: 5.106119891871577.
[I 2024-06-03 02:24:58,780] Trial 5 finished with value: 283.2602054761804 and parameters: {'layer_size': 95, 'dropout_rate': 0.338451909442369, 'lr': 1.1409614762911625e-05, 'kl_weight': 0.014065410296610464}. Best is trial 0 with value: 5.106119891871577.
[I 2024-06-03 02:25:12,045] Trial 6 finished with value: 4.9835052490234375 and parameters: {'layer_size': 159, 'dropout_rate': 0.16814293818566953, 'lr': 0.005798232306243521, 'kl_weight': 0.0010483790181342728}. Best is trial 6 with value: 4.9835052490234375.
[I 2024-06-03 02:25:24,565] Trial 7 finished with value: 798.8504638671875 and parameters: {'layer_size': 155, 'dropout_rate': 0.49921413175219753, 'lr': 1.7651912308300256e-05, 'kl_weight': 0.03425023318363717}. Best is trial 6 with value: 4.9835052490234375.
[I 2024-06-03 02:25:40,678] Trial 8 finished with value: 2421.982867697011 and parameters: {'layer_size': 260, 'dropout_rate': 0.4462580580116101, 'lr': 2.6325806220692975e-05, 'kl_weight': 0.004942751924942122}. Best is trial 6 with value: 4.9835052490234375.
[I 2024-06-03 02:25:54,450] Trial 9 finished with value: 20.323775664619777 and parameters: {'layer_size': 193, 'dropout_rate': 0.17050275830723527, 'lr': 0.0004910886504062877, 'kl_weight': 0.021196516889190366}. Best is trial 6 with value: 4.9835052490234375.
[I 2024-06-03 02:26:18,253] Trial 10 finished with value: 5.16413430545641 and parameters: {'layer_size': 366, 'dropout_rate': 0.10765083084091903, 'lr': 0.005727213998509271, 'kl_weight': 0.001241411069041312}. Best is trial 6 with value: 4.9835052490234375.
[I 2024-06-03 02:26:37,162] Trial 11 finished with value: 5.00941829059435 and parameters: {'layer_size': 292, 'dropout_rate': 0.26752306662018427, 'lr': 0.00714741449120587, 'kl_weight': 0.08834486468917266}. Best is trial 6 with value: 4.9835052490234375.
[I 2024-06-03 02:26:57,402] Trial 12 finished with value: 4.956790654555611 and parameters: {'layer_size': 316, 'dropout_rate': 0.2571016176832328, 'lr': 0.007488852740406658, 'kl_weight': 0.002888959863212848}. Best is trial 12 with value: 4.956790654555611.
[I 2024-06-03 02:27:20,088] Trial 13 finished with value: 5.080472116884978 and parameters: {'layer_size': 365, 'dropout_rate': 0.2428842640952609, 'lr': 0.0033428866792650108, 'kl_weight': 0.0026110242717927398}. Best is trial 12 with value: 4.956790654555611.
[I 2024-06-03 02:27:39,419] Trial 14 finished with value: 5.134580021319182 and parameters: {'layer_size': 311, 'dropout_rate': 0.19585209033385964, 'lr': 0.002788772230330683, 'kl_weight': 0.00261343579113561}. Best is trial 12 with value: 4.956790654555611.
[I 2024-06-03 02:27:58,932] Trial 15 finished with value: 212.56363908104274 and parameters: {'layer_size': 319, 'dropout_rate': 0.28598290701190676, 'lr': 0.00022602137073664404, 'kl_weight': 0.0023051073426220044}. Best is trial 12 with value: 4.956790654555611.
[I 2024-06-03 02:28:26,175] Trial 16 finished with value: 5.029207820477693 and parameters: {'layer_size': 400, 'dropout_rate': 0.116532241742386, 'lr': 0.009209854650283593, 'kl_weight': 0.0045994654196139404}. Best is trial 12 with value: 4.956790654555611.
[I 2024-06-03 02:28:38,800] Trial 17 finished with value: 4.959591347238292 and parameters: {'layer_size': 141, 'dropout_rate': 0.2023739566373936, 'lr': 0.0025091287505974447, 'kl_weight': 0.001025575603980257}. Best is trial 12 with value: 4.956790654555611.
[I 2024-06-03 02:28:55,679] Trial 18 finished with value: 5.166464318399844 and parameters: {'layer_size': 264, 'dropout_rate': 0.33871621527752077, 'lr': 0.002269916889306218, 'kl_weight': 0.001897089886563279}. Best is trial 12 with value: 4.956790654555611.
[I 2024-06-03 02:29:07,722] Trial 19 finished with value: 6.605499174283898 and parameters: {'layer_size': 129, 'dropout_rate': 0.23639484174289002, 'lr': 0.0002493046975902267, 'kl_weight': 0.004551547276385637}. Best is trial 12 with value: 4.956790654555611.
[I 2024-06-03 02:29:23,126] Trial 20 finished with value: 6.209339286970056 and parameters: {'layer_size': 225, 'dropout_rate': 0.28876985715774667, 'lr': 0.0005383108964455727, 'kl_weight': 0.0017630475618331557}. Best is trial 12 with value: 4.956790654555611.
[I 2024-06-03 02:29:35,590] Trial 21 finished with value: 4.797438445298568 and parameters: {'layer_size': 130, 'dropout_rate': 0.1849659616217723, 'lr': 0.0044812834374806584, 'kl_weight': 0.0010058700958902812}. Best is trial 21 with value: 4.797438445298568.
[I 2024-06-03 02:29:47,221] Trial 22 finished with value: 4.916024228800898 and parameters: {'layer_size': 116, 'dropout_rate': 0.2030753634679754, 'lr': 0.00399810046111306, 'kl_weight': 0.0015198335204067584}. Best is trial 21 with value: 4.797438445298568.
[I 2024-06-03 02:29:57,685] Trial 23 finished with value: 4.868845877440079 and parameters: {'layer_size': 52, 'dropout_rate': 0.2576289094848141, 'lr': 0.0047853939060606325, 'kl_weight': 0.0036650478538140644}. Best is trial 21 with value: 4.797438445298568.
[I 2024-06-03 02:30:08,136] Trial 24 finished with value: 4.793102347332498 and parameters: {'layer_size': 50, 'dropout_rate': 0.14600996889658296, 'lr': 0.003963960907992951, 'kl_weight': 0.0016023335316591755}. Best is trial 24 with value: 4.793102347332498.
[I 2024-06-03 02:30:18,709] Trial 25 finished with value: 4.950604729030443 and parameters: {'layer_size': 61, 'dropout_rate': 0.1507021142098096, 'lr': 0.0014627927148462908, 'kl_weight': 0.00394037798803317}. Best is trial 24 with value: 4.793102347332498.
[I 2024-06-03 02:30:29,123] Trial 26 finished with value: 4.860629361608754 and parameters: {'layer_size': 52, 'dropout_rate': 0.15140239394796148, 'lr': 0.003834189359318808, 'kl_weight': 0.007261472660166316}. Best is trial 24 with value: 4.793102347332498.
[I 2024-06-03 02:30:39,520] Trial 27 finished with value: 4.834294671597688 and parameters: {'layer_size': 50, 'dropout_rate': 0.12987169332676735, 'lr': 0.009916463800410662, 'kl_weight': 0.01120037900144115}. Best is trial 24 with value: 4.793102347332498.
[I 2024-06-03 02:30:50,962] Trial 28 finished with value: 5.160814855409705 and parameters: {'layer_size': 108, 'dropout_rate': 0.12893023100391335, 'lr': 0.001842822286327372, 'kl_weight': 0.011289759257017655}. Best is trial 24 with value: 4.793102347332498.
[I 2024-06-03 02:31:04,753] Trial 29 finished with value: 12.026333425355995 and parameters: {'layer_size': 194, 'dropout_rate': 0.10283308825188406, 'lr': 0.001203175076613215, 'kl_weight': 0.006332522076142994}. Best is trial 24 with value: 4.793102347332498.
[I 2024-06-03 02:31:15,835] Trial 30 finished with value: 6.113129045652307 and parameters: {'layer_size': 91, 'dropout_rate': 0.19022257937979173, 'lr': 0.0006734065004175085, 'kl_weight': 0.05217871599543012}. Best is trial 24 with value: 4.793102347332498.
[I 2024-06-03 02:31:26,247] Trial 31 finished with value: 4.894734289335168 and parameters: {'layer_size': 50, 'dropout_rate': 0.1386862042793152, 'lr': 0.009142844245140233, 'kl_weight': 0.008057279171734719}. Best is trial 24 with value: 4.793102347332498.
[I 2024-06-03 02:31:36,894] Trial 32 finished with value: 4.86018389204274 and parameters: {'layer_size': 63, 'dropout_rate': 0.16884979155344917, 'lr': 0.0044781664128118025, 'kl_weight': 0.02230701547958216}. Best is trial 24 with value: 4.793102347332498.
[I 2024-06-03 02:31:47,673] Trial 33 finished with value: 4.88402071206466 and parameters: {'layer_size': 75, 'dropout_rate': 0.1743589939073685, 'lr': 0.0017189519460186515, 'kl_weight': 0.020888712664728873}. Best is trial 24 with value: 4.793102347332498.
[I 2024-06-03 02:31:59,261] Trial 34 finished with value: 4.860739884169205 and parameters: {'layer_size': 111, 'dropout_rate': 0.13046692064572848, 'lr': 0.004455928857720573, 'kl_weight': 0.018714487980039926}. Best is trial 24 with value: 4.793102347332498.
[I 2024-06-03 02:32:10,013] Trial 35 finished with value: 4.842539849488632 and parameters: {'layer_size': 69, 'dropout_rate': 0.21919360417733905, 'lr': 0.009945045085788355, 'kl_weight': 0.031341214769474775}. Best is trial 24 with value: 4.793102347332498.
[I 2024-06-03 02:32:21,077] Trial 36 finished with value: 4.923534393310547 and parameters: {'layer_size': 82, 'dropout_rate': 0.22683533408990547, 'lr': 0.009882363937307792, 'kl_weight': 0.03684664121050273}. Best is trial 24 with value: 4.793102347332498.
[I 2024-06-03 02:32:32,353] Trial 37 finished with value: 29.09313850817473 and parameters: {'layer_size': 102, 'dropout_rate': 0.2145468202777508, 'lr': 0.00014486379405690667, 'kl_weight': 0.059491465610529884}. Best is trial 24 with value: 4.793102347332498.
[I 2024-06-03 02:32:44,559] Trial 38 finished with value: 4.8401717310366426 and parameters: {'layer_size': 130, 'dropout_rate': 0.36799353349704, 'lr': 0.006118675304439832, 'kl_weight': 0.014414395157653099}. Best is trial 24 with value: 4.793102347332498.
[I 2024-06-03 02:32:58,442] Trial 39 finished with value: 4.8597296009893 and parameters: {'layer_size': 188, 'dropout_rate': 0.32294946665404634, 'lr': 0.00605304122570657, 'kl_weight': 0.010533114690063143}. Best is trial 24 with value: 4.793102347332498.
[I 2024-06-03 02:33:10,988] Trial 40 finished with value: 5.451246479283208 and parameters: {'layer_size': 139, 'dropout_rate': 0.3840454752737963, 'lr': 0.0009295840867037844, 'kl_weight': 0.01384628286844941}. Best is trial 24 with value: 4.793102347332498.
[I 2024-06-03 02:33:21,786] Trial 41 finished with value: 4.898947415144547 and parameters: {'layer_size': 70, 'dropout_rate': 0.4199820542053573, 'lr': 0.0068399954782374945, 'kl_weight': 0.028967671011357724}. Best is trial 24 with value: 4.793102347332498.
[I 2024-06-03 02:33:35,524] Trial 42 finished with value: 4.837756353875865 and parameters: {'layer_size': 177, 'dropout_rate': 0.3641205247718973, 'lr': 0.00290107591620009, 'kl_weight': 0.01570174474760742}. Best is trial 24 with value: 4.793102347332498.
[I 2024-06-03 02:33:49,033] Trial 43 finished with value: 4.962499556334122 and parameters: {'layer_size': 172, 'dropout_rate': 0.36810747101335634, 'lr': 0.0023984344098937436, 'kl_weight': 0.015428617191747962}. Best is trial 24 with value: 4.793102347332498.
[I 2024-06-03 02:34:03,834] Trial 44 finished with value: 1307.7078890593154 and parameters: {'layer_size': 229, 'dropout_rate': 0.36644324675373, 'lr': 4.851445065517899e-05, 'kl_weight': 0.008531404901498422}. Best is trial 24 with value: 4.793102347332498.
[I 2024-06-03 02:34:17,192] Trial 45 finished with value: 4.834380191305409 and parameters: {'layer_size': 168, 'dropout_rate': 0.4243545845451514, 'lr': 0.0029984094362723026, 'kl_weight': 0.011814450786790618}. Best is trial 24 with value: 4.793102347332498.
[I 2024-06-03 02:34:30,863] Trial 46 finished with value: 4.987334945927495 and parameters: {'layer_size': 170, 'dropout_rate': 0.4817716029807379, 'lr': 0.00299264597336512, 'kl_weight': 0.001337190887545049}. Best is trial 24 with value: 4.793102347332498.
[I 2024-06-03 02:34:44,852] Trial 47 finished with value: 5.3197779448136036 and parameters: {'layer_size': 203, 'dropout_rate': 0.47417142627529263, 'lr': 0.001294380786292107, 'kl_weight': 0.0062537442291169575}. Best is trial 24 with value: 4.793102347332498.
[I 2024-06-03 02:34:57,688] Trial 48 finished with value: 4.963282149770985 and parameters: {'layer_size': 152, 'dropout_rate': 0.42723512116007056, 'lr': 0.002015701769358288, 'kl_weight': 0.011612233635797551}. Best is trial 24 with value: 4.793102347332498.
[I 2024-06-03 02:35:13,802] Trial 49 finished with value: 4.978224847627723 and parameters: {'layer_size': 247, 'dropout_rate': 0.3925590826110139, 'lr': 0.0032971565704318076, 'kl_weight': 0.0061101796822943385}. Best is trial 24 with value: 4.793102347332498.
Best trial:
Value: 4.793102347332498
Params:
    layer_size: 50
    dropout_rate: 0.14600996889658296
    lr: 0.003963960907992951
    kl_weight: 0.0016023335316591755
/tmp/ipykernel_66765/2823118552.py:93: ExperimentalWarning: plot_optimization_history is experimental (supported from v2.2.0). The interface can change in the future.
  optuna.visualization.matplotlib.plot_optimization_history(study)
#+end_example
[[./.ob-jupyter/9ad63c01691e7fc99ec557664e8a79d2749e0848.png]]
: /tmp/ipykernel_66765/2823118552.py:97: ExperimentalWarning: plot_param_importances is experimental (supported from v2.2.0). The interface can change in the future.
:   optuna.visualization.matplotlib.plot_param_importances(study)
#+attr_org: :width 829
[[./.ob-jupyter/502c4fec5623a92809db46ddea578e67b2f047a1.png]]
:END:
* Gaussian Mixture
** GMM

#+begin_src jupyter-python :kernel iotvar_powerprofiler
from sklearn.mixture import GaussianMixture
from sklearn.preprocessing import StandardScaler

# Feature engineering: creating feature vectors from 'refresh_period' and 'number_sensors'
input_features = m_b_df[['refresh_period', 'number_sensors']]

# Output parameters: 'm' and 'b'
output_features = m_b_df[['m', 'b']]

# Scaling input features and output variables
input_scaler = StandardScaler()
scaled_input_features = input_scaler.fit_transform(input_features)

output_scaler = StandardScaler()
scaled_output_features = output_scaler.fit_transform(output_features)

# Combine scaled input and output features for GMM training
combined_scaled_features = np.hstack((scaled_input_features, scaled_output_features))

# Train a Gaussian Mixture Model (GMM)
gmm = GaussianMixture(n_components=5, random_state=42)  # 5 components as an example, can be tuned
gmm.fit(combined_scaled_features)

# Generate samples from the GMM
sampled_scaled_features, _ = gmm.sample(n_samples=10000)

# Separate sampled inputs and outputs
sampled_scaled_outputs = sampled_scaled_features[:, 2:]

# Inverse transform the scaled sampled outputs
sampled_outputs = output_scaler.inverse_transform(sampled_scaled_outputs)

# Create a DataFrame for the sampled outputs
sampled_df = pd.DataFrame(sampled_outputs, columns=['m', 'b'])

# Plot the distributions of the actual and sampled 'm' and 'b' values for comparison
plt.figure(figsize=(14, 6))
sns.histplot(m_b_df['m'], bins=30, kde=True, color='blue', label='Actual m', stat='density')
sns.histplot(sampled_df['m'], bins=30, kde=True, color='red', label='Sampled m', stat='density')
plt.title('Distribution of Actual vs Sampled m values')
plt.xlabel('m')
plt.ylabel('Density')
plt.legend()
plt.show()

plt.figure(figsize=(14, 6))
sns.histplot(m_b_df['b'], bins=30, kde=True, color='blue', label='Actual b', stat='density')
sns.histplot(sampled_df['b'], bins=30, kde=True, color='red', label='Sampled b', stat='density')
plt.title('Distribution of Actual vs Sampled b values')
plt.xlabel('b')
plt.ylabel('Density')
plt.legend()
plt.show()
#+end_src

#+RESULTS:
:RESULTS:
[[./.ob-jupyter/e97e76a5982d55f10eaf9c44882b31b25f63447a.png]]
[[./.ob-jupyter/1fa9f578ea6ff54c93e4bbe5fbfd0de2f676b55e.png]]
:END:

#+begin_src jupyter-python :kernel iotvar_powerprofiler
from scipy.stats import gaussian_kde
from scipy.special import rel_entr
# Compute KDE for the actual 'm' values
kde_actual_m = gaussian_kde(m_b_df['m'])
kde_sampled_m = gaussian_kde(sampled_df['m'])

# Compute KDE for the actual 'b' values
kde_actual_b = gaussian_kde(m_b_df['b'])
kde_sampled_b = gaussian_kde(sampled_df['b'])

# Define a range of values over which to evaluate the KDEs
m_values = np.linspace(min(m_b_df['m'].min(), sampled_df['m'].min()), max(m_b_df['m'].max(), sampled_df['m'].max()), 1000)
b_values = np.linspace(min(m_b_df['b'].min(), sampled_df['b'].min()), max(m_b_df['b'].max(), sampled_df['b'].max()), 1000)

# Evaluate the KDEs over the range of values
kde_actual_m_values = kde_actual_m(m_values)
kde_sampled_m_values = kde_sampled_m(m_values)

kde_actual_b_values = kde_actual_b(b_values)
kde_sampled_b_values = kde_sampled_b(b_values)

# Normalize the KDEs to ensure they sum to 1 (convert to proper probability distributions)
kde_actual_m_values /= kde_actual_m_values.sum()
kde_sampled_m_values /= kde_sampled_m_values.sum()

kde_actual_b_values /= kde_actual_b_values.sum()
kde_sampled_b_values /= kde_sampled_b_values.sum()

# Compute the KL divergence between the actual and sampled distributions for 'm' and 'b'
kl_divergence_m = np.sum(rel_entr(kde_actual_m_values, kde_sampled_m_values))
kl_divergence_b = np.sum(rel_entr(kde_actual_b_values, kde_sampled_b_values))

print(f"KL Divergence for 'm': {kl_divergence_m}")
print(f"KL Divergence for 'b': {kl_divergence_b}")
#+end_src

#+RESULTS:
: KL Divergence for 'm': 0.006260259563596923
: KL Divergence for 'b': 0.05949839730280555

*** Inference
#+begin_src jupyter-python :kernel iotvar_powerprofiler
# New input values
new_input = np.array([[17, 140]])

# Scale the new input values
scaled_new_input = input_scaler.transform(new_input)

# Number of samples to generate for the output distribution
n_samples = 1000

# Generate samples from the GMM
sampled_scaled_features, _ = gmm.sample(n_samples=n_samples)

# Separate sampled inputs and outputs
sampled_scaled_inputs = sampled_scaled_features[:, :2]
sampled_scaled_outputs = sampled_scaled_features[:, 2:]

# Find the samples that are close to the new input
distances = np.linalg.norm(sampled_scaled_inputs - scaled_new_input, axis=1)
close_samples_indices = np.argsort(distances)[:n_samples]

# Select the corresponding output samples
close_sampled_scaled_outputs = sampled_scaled_outputs[close_samples_indices]

# Inverse transform the scaled sampled outputs
close_sampled_outputs = output_scaler.inverse_transform(close_sampled_scaled_outputs)

# Create a DataFrame for the close sampled outputs
close_sampled_df = pd.DataFrame(close_sampled_outputs, columns=['m', 'b'])

# Plot the distributions of the close sampled 'm' and 'b' values
import matplotlib.pyplot as plt
import seaborn as sns

plt.figure(figsize=(14, 6))
sns.histplot(close_sampled_df['m'], bins=30, kde=True, color='red', label='Sampled m')
plt.title('Distribution of Sampled m values for new input')
plt.xlabel('m')
plt.ylabel('Density')
plt.legend()
plt.show()

plt.figure(figsize=(14, 6))
sns.histplot(close_sampled_df['b'], bins=30, kde=True, color='red', label='Sampled b')
plt.title('Distribution of Sampled b values for new input')
plt.xlabel('b')
plt.ylabel('Density')
plt.legend()
plt.show()
#+end_src

#+RESULTS:
:RESULTS:
: /home/han4n/anaconda3/envs/IoTVar_PowerProfiler/lib/python3.10/site-packages/sklearn/base.py:493: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names
:   warnings.warn(
[[./.ob-jupyter/acc1fc72a812f6c2198c33620bcbfff53b4058eb.png]]
[[./.ob-jupyter/74e48013f46df03ebd7c5ab7249264ef08d71ea9.png]]
:END:
*** Conditional GMMs

#+begin_src jupyter-python :kernel iotvar_powerprofiler
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.mixture import GaussianMixture
from scipy.stats import multivariate_normal, gaussian_kde
from scipy.special import rel_entr

# Combine the input and output features
input_features = m_b_df[['refresh_period', 'number_sensors']]
output_features = m_b_df[['m', 'b']]

# Split the data into training and test sets
input_train, input_test, output_train, output_test = train_test_split(input_features, output_features, test_size=0.2, random_state=42)

# Scale the input features and output variables
input_scaler = StandardScaler()
scaled_input_train = input_scaler.fit_transform(input_train)
scaled_input_test = input_scaler.transform(input_test)

output_scaler = StandardScaler()
scaled_output_train = output_scaler.fit_transform(output_train)
scaled_output_test = output_scaler.transform(output_test)

# Combine scaled input and output features for GMM training
combined_scaled_train = np.hstack((scaled_input_train, scaled_output_train))

# Train a Gaussian Mixture Model (GMM)
gmm = GaussianMixture(n_components=5, random_state=42)
gmm.fit(combined_scaled_train)

def condition_gmm(gmm, input_data, input_scaler, output_scaler, n_samples=1000):
    n_components = gmm.n_components
    means = gmm.means_
    covariances = gmm.covariances_

    d = input_data.shape[1]  # Dimension of the input
    d_y = means.shape[1] - d  # Dimension of the output

    scaled_input = input_scaler.transform(input_data)

    conditional_means = np.zeros((scaled_input.shape[0], d_y))
    conditional_covariances = np.zeros((scaled_input.shape[0], d_y, d_y))

    for i, x in enumerate(scaled_input):
        x = x.reshape(1, -1)

        log_prob = np.zeros(n_components)
        for k in range(n_components):
            mean_x = means[k, :d]
            cov_xx = covariances[k, :d, :d]
            log_prob[k] = gmm.weights_[k] * multivariate_normal(mean=mean_x, cov=cov_xx).pdf(x)

        responsibilities = log_prob / np.sum(log_prob)

        mean_cond = np.zeros(d_y)
        cov_cond = np.zeros((d_y, d_y))

        for k in range(n_components):
            mean_x = means[k, :d]
            mean_y = means[k, d:]
            cov_xx = covariances[k, :d, :d]
            cov_xy = covariances[k, :d, d:]
            cov_yx = covariances[k, d:, :d]
            cov_yy = covariances[k, d:, d:]

            inv_cov_xx = np.linalg.inv(cov_xx)

            diff = (x - mean_x).T
            mean_y_part = mean_y.flatten()
            mean_cond_part = cov_yx @ inv_cov_xx @ diff
            mean_cond_part = mean_cond_part.flatten()
            mean_cond += responsibilities[k] * (mean_y_part + mean_cond_part)
            cov_cond += responsibilities[k] * (cov_yy - cov_yx @ inv_cov_xx @ cov_xy)

        conditional_means[i] = mean_cond
        conditional_covariances[i] = cov_cond

    sampled_outputs = np.array([np.random.multivariate_normal(mean, cov, n_samples) for mean, cov in zip(conditional_means, conditional_covariances)])
    sampled_outputs = sampled_outputs.reshape(-1, d_y)
    sampled_outputs = output_scaler.inverse_transform(sampled_outputs)

    return sampled_outputs

sampled_outputs = condition_gmm(gmm, input_test, input_scaler, output_scaler)

# Create DataFrame for the sampled outputs
sampled_df = pd.DataFrame(sampled_outputs, columns=['m', 'b'])

# Now you can compare the sampled_df with the actual output_test
# For example, you can compute the KDE and KL divergence as described previously

# Compute KDE for the actual 'm' and 'b' values
kde_actual_m = gaussian_kde(output_test['m'])
kde_sampled_m = gaussian_kde(sampled_df['m'])

kde_actual_b = gaussian_kde(output_test['b'])
kde_sampled_b = gaussian_kde(sampled_df['b'])

# Define a range of values over which to evaluate the KDEs
m_values = np.linspace(min(output_test['m'].min(), sampled_df['m'].min()), max(output_test['m'].max(), sampled_df['m'].max()), 1000)
b_values = np.linspace(min(output_test['b'].min(), sampled_df['b'].min()), max(output_test['b'].max(), sampled_df['b'].max()), 1000)

# Evaluate the KDEs over the range of values
kde_actual_m_values = kde_actual_m(m_values)
kde_sampled_m_values = kde_sampled_m(m_values)

kde_actual_b_values = kde_actual_b(b_values)
kde_sampled_b_values = kde_sampled_b(b_values)

# Normalize the KDEs to ensure they sum to 1 (convert to proper probability distributions)
kde_actual_m_values /= kde_actual_m_values.sum()
kde_sampled_m_values /= kde_sampled_m_values.sum()

kde_actual_b_values /= kde_actual_b_values.sum()
kde_sampled_b_values /= kde_sampled_b_values.sum()

# Compute the KL divergence between the actual and sampled distributions for 'm' and 'b'
kl_divergence_m = np.sum(rel_entr(kde_actual_m_values, kde_sampled_m_values))
kl_divergence_b = np.sum(rel_entr(kde_actual_b_values, kde_sampled_b_values))

# Output the KL divergence values
print(f"KL Divergence for 'm': {kl_divergence_m}")
print(f"KL Divergence for 'b': {kl_divergence_b}")
#+end_src

#+RESULTS:
: KL Divergence for 'm': 0.7231841228836873
: KL Divergence for 'b': 0.010008559236014607

#+begin_src jupyter-python :kernel iotvar_powerprofiler

# Compute KDE for the actual 'm' and 'b' values
kde_actual_m = gaussian_kde(output_test['m'])
kde_sampled_m = gaussian_kde(sampled_df['m'])

kde_actual_b = gaussian_kde(output_test['b'])
kde_sampled_b = gaussian_kde(sampled_df['b'])

# Define a range of values over which to evaluate the KDEs
m_values = np.linspace(min(output_test['m'].min(), sampled_df['m'].min()), max(output_test['m'].max(), sampled_df['m'].max()), 1000)
b_values = np.linspace(min(output_test['b'].min(), sampled_df['b'].min()), max(output_test['b'].max(), sampled_df['b'].max()), 1000)

# Evaluate the KDEs over the range of values
kde_actual_m_values = kde_actual_m(m_values)
kde_sampled_m_values = kde_sampled_m(m_values)

kde_actual_b_values = kde_actual_b(b_values)
kde_sampled_b_values = kde_sampled_b(b_values)

# Normalize the KDEs to ensure they sum to 1 (convert to proper probability distributions)
kde_actual_m_values /= kde_actual_m_values.sum()
kde_sampled_m_values /= kde_sampled_m_values.sum()

kde_actual_b_values /= kde_actual_b_values.sum()
kde_sampled_b_values /= kde_sampled_b_values.sum()

# Compute the KL divergence between the actual and sampled distributions for 'm' and 'b'
kl_divergence_m = np.sum(rel_entr(kde_actual_m_values, kde_sampled_m_values))
kl_divergence_b = np.sum(rel_entr(kde_actual_b_values, kde_sampled_b_values))

# Output the KL divergence values
print(f"KL Divergence for 'm': {kl_divergence_m}")
print(f"KL Divergence for 'b': {kl_divergence_b}")

# Plot the KDEs for visual comparison
plt.figure(figsize=(14, 6))

plt.subplot(1, 2, 1)
plt.plot(m_values, kde_actual_m_values, label='Actual m', color='blue')
plt.plot(m_values, kde_sampled_m_values, label='Sampled m', color='red', linestyle='--')
plt.title('KDE of m')
plt.legend()

plt.subplot(1, 2, 2)
plt.plot(b_values, kde_actual_b_values, label='Actual b', color='blue')
plt.plot(b_values, kde_sampled_b_values, label='Sampled b', color='red', linestyle='--')
plt.title('KDE of b')
plt.legend()

plt.show()

#+end_src

#+RESULTS:
:RESULTS:
: KL Divergence for 'm': 0.7231841228836873
: KL Divergence for 'b': 0.010008559236014607
[[./.ob-jupyter/4b16d2c7faed563a1f1bf9fe7815e2f9f7b2d990.png]]
:END:
* Clustering analysis
#+begin_src jupyter-python :kernel iotvar_powerprofiler
# Plotting the distribution of 'm' values
plt.figure(figsize=(14, 6))
sns.histplot(m_b_df['m'], bins=30, kde=True)
plt.title('Distribution of m values')
plt.xlabel('m')
plt.ylabel('Frequency')
plt.show()

# Plotting the distribution of 'b' values
plt.figure(figsize=(14, 6))
sns.histplot(m_b_df['b'], bins=30, kde=True)
plt.title('Distribution of b values')
plt.xlabel('b')
plt.ylabel('Frequency')
plt.show()

# Scatter plot for 'm' vs 'b' colored by 'refresh_period'
plt.figure(figsize=(14, 6))
sns.scatterplot(data=m_b_df, x='m', y='b', hue='refresh_period', palette='viridis', alpha=0.7)
plt.title('Scatter plot of m vs b colored by refresh_period')
plt.xlabel('m')
plt.ylabel('b')
plt.legend(title='Refresh Period')
plt.show()

# Scatter plot for 'm' vs 'b' colored by 'number_sensors'
plt.figure(figsize=(14, 6))
sns.scatterplot(data=m_b_df, x='m', y='b', hue='number_sensors', palette='coolwarm', alpha=0.7)
plt.title('Scatter plot of m vs b colored by number_sensors')
plt.xlabel('m')
plt.ylabel('b')
plt.legend(title='Number of Sensors')
plt.show()
#+end_src

#+RESULTS:
:RESULTS:
[[./.ob-jupyter/6aa835cb6f10bcffd3484b0b5458ce63e4a8709d.png]]
[[./.ob-jupyter/d5a35aac95b0290086f28087fa90beeae42d805f.png]]
[[./.ob-jupyter/9dcd6a985a14c2f0730a92feb0b119f7e93d14e9.png]]
[[./.ob-jupyter/4c484a3f8d62824c31e6c9e2f4e290bb358f91b6.png]]
:END:

#+begin_src jupyter-python :kernel iotvar_powerprofiler
plt.figure(figsize=(14, 6))
sns.scatterplot(data=m_b_df, x='refresh_period', y='number_sensors', hue='m', palette='viridis', alpha=0.7)
plt.title('Scatter plot of refresh_period vs number_sensors colored by m')
plt.xlabel("Refresh time $R_{G}$")
plt.ylabel("Number of sensors in group $nb_{V_{G}}$")
plt.legend(title='m')
plt.show()

plt.figure(figsize=(14, 6))
sns.scatterplot(data=m_b_df, x='refresh_period', y='number_sensors', hue='b', palette='viridis', alpha=0.7)
plt.title('Scatter plot of refresh_period vs number_sensors colored by b')
plt.xlabel("Slope $m$")
plt.ylabel("Number of sensors in group $nb_{V_{G}}$")
plt.legend(title='b')
plt.show()

plt.figure(figsize=(14, 6))
sns.scatterplot(data=m_b_df, x='refresh_period', y='m', alpha=0.7)
plt.title('Scatter plot of refresh_period vs m colored by number_sensors')
plt.xlabel("Refresh time $R_{G}$")
plt.ylabel("Slope $m$")
#plt.legend(title='number_sensors')
plt.show()

plt.figure(figsize=(14, 6))
sns.scatterplot(data=m_b_df, x='refresh_period', y='b', hue='number_sensors', palette='viridis', alpha=0.7)
plt.title('Scatter plot of refresh_period vs b colored by number_sensors')
plt.xlabel("Refresh time $R_{G}$")
plt.ylabel("Intersect $b$")
plt.legend(title='number_sensors')
plt.show()

plt.figure(figsize=(42, 12))
plt.subplot(1,2,1)
sns.scatterplot(data=m_b_df, x='number_sensors', y='m', hue='refresh_period', palette='viridis', alpha=0.7)
plt.title('Scatter plot of number_sensors vs m colored by refresh_period')
plt.xlabel("number_sensors")
plt.ylabel("Slope $m$")
plt.legend(title='refresh_period')
#plt.show()

#plt.figure(figsize=(14, 6))
plt.subplot(1,2,2)
sns.scatterplot(data=m_b_df, x='number_sensors', y='b', hue='refresh_period', palette='viridis', alpha=0.7)
plt.title('Scatter plot of number_sensors vs b colored by refresh_period')
plt.xlabel("number_sensors")
plt.ylabel("Intersect $b$")
plt.legend(title='refresh_period')
plt.show()

#+end_src

#+RESULTS:
:RESULTS:
[[./.ob-jupyter/3e65b67956f774c412769f606ae94df12ca4e32b.png]]
[[./.ob-jupyter/1a482aca29b9535bcaf3ebcc2d1fff1c7947d26c.png]]
[[./.ob-jupyter/2f31bda33135120cac880cdcc65353d0a1104200.png]]
[[./.ob-jupyter/e0ee7836933954c81b8bd1f6f7cc0ccd9df23adb.png]]
[[./.ob-jupyter/cf43832eabb629705cc4ffffe7a2c0d5d7fc40fb.png]]
:END:

#+begin_src jupyter-python :kernel iotvar_powerprofiler
plt.figure(figsize=(16, 12))

plt.subplot(2, 1, 1)
sns.violinplot(data=m_b_df.to_pandas(), x='number_sensors', y='m', hue='refresh_period',  palette='muted', split=False)
#sns.violinplot(data=m_b_df.to_pandas(), x='number_sensors', y='m',  palette='muted', split=True)
plt.title('Distribution of Slope (m) for different Refresh Periods and Number of Sensors')
plt.xlabel('Number of Sensors')
plt.ylabel('Slope (m)')

plt.subplot(2, 1, 2)
sns.violinplot(x='number_sensors', y='b', hue='refresh_period', data=m_b_df.to_pandas(), palette='muted', split=False)
plt.title('Distribution of Intercept (b) for different Refresh Periods and Number of Sensors')
plt.xlabel('Number of Sensors')
plt.ylabel('Intercept (b)')

plt.tight_layout()
plt.show()
#+end_src

#+RESULTS:
[[./.ob-jupyter/b5d26555dee3c1694523d5be264d1fc797f24604.png]]

#+begin_src jupyter-python :kernel iotvar_powerprofiler
plt.figure(figsize=(16, 12))

plt.subplot(2, 1, 1)
sns.violinplot(data=m_b_df.to_pandas(), x='refresh_period', y='m', hue='number_sensors',  palette='muted', split=False)
plt.title('Distribution of Slope (m) for different Refresh Periods and Number of Sensors')
plt.xlabel('Refresh period')
plt.ylabel('Slope (m)')

plt.subplot(2, 1, 2)
sns.violinplot(x='refresh_period', y='b', hue='number_sensors', data=m_b_df.to_pandas(), palette='muted', split=False)
plt.title('Distribution of Intercept (b) for different Refresh Periods and Number of Sensors')
plt.xlabel('Refresh period')
plt.ylabel('Intercept (b)')

plt.tight_layout()
plt.show()
#+end_src

#+RESULTS:
[[./.ob-jupyter/19b3d63dbb2b3ef7e378cc68eafc1e6fbe8471d0.png]]


#+begin_src jupyter-python :kernel iotvar_powerprofiler
plt.figure(figsize=(16, 6))

# Density plot for 'm' values based on 'refresh_period' and 'number_sensors'
#plt.subplot(2, 1, 1)
sns.kdeplot(data=m_b_df, x='number_sensors', y='m', hue='refresh_period', fill=True, common_norm=False, palette='muted')
plt.title('Density Plot of Slope (m) for different Refresh Periods and Number of Sensors')
plt.xlabel('Number of Sensors')
plt.ylabel('Slope (m)')
plt.tight_layout()
plt.show()
plt.figure(figsize=(16, 6))
# Density plot for 'b' values based on 'refresh_period' and 'number_sensors'
#plt.subplot(2, 1, 2)
sns.kdeplot(data=m_b_df, x='number_sensors', y='b', hue='refresh_period', fill=True, common_norm=False, palette='muted')
#sns.scatterplot(y = m_b_df['m'],x = m_b_df['refresh_period'],hue = m_b_df['b'] )
plt.title('Density Plot of Intercept (b) for different Refresh Periods and Number of Sensors')
plt.xlabel('Number of Sensors')
plt.ylabel('Intercept (b)')

plt.tight_layout()
plt.show()
#+end_src

#+RESULTS:
:RESULTS:
[[./.ob-jupyter/0b6856365c9d26d8df8c52d1a12bcdce81dd60b8.png]]
[[./.ob-jupyter/11dc1b699cd6c98656fc0118098849ae179ecb5f.png]]
:END:

let's plot another predictors for b.

#+begin_src jupyter-python :kernel iotvar_powerprofiler
# Scatter plot for 'm' vs 'b' colored by 'refresh_period'
plt.figure(figsize=(14, 6))
sns.scatterplot(data=m_b_df, x='m', y='b', hue='refresh_period', palette='muted', alpha=0.7)
plt.title('Scatter plot of m vs b colored by refresh_period')
plt.xlabel('m')
plt.ylabel('b')
plt.legend(title='Refresh Period')
plt.show()

plt.figure(figsize=(14, 6))
sns.kdeplot(data=m_b_df, x='m', y='b', hue='refresh_period', fill=True, common_norm=False, palette='muted')
plt.title('Distribution of Intercept (b) for slope values (m) and different Refresh Periods')
plt.xlabel('Slope m')
plt.ylabel('Intercept (b)')
plt.show()

plt.figure(figsize=(14, 6))
sns.scatterplot(data=m_b_df, x='refresh_period', y='b', hue='m', palette='viridis', alpha=0.7)
plt.title('Distribution of Intercept (b) for slope values (m) and different Refresh Periods')
plt.xlabel('Refresh period')
plt.ylabel('Intercept (b)')
plt.show()

plt.figure(figsize=(14, 6))
sns.scatterplot(data=m_b_df, x='number_sensors', y='m', hue='b', palette='viridis', alpha=0.7)
plt.title('Distribution of Intercept (b) for slope values (m) and different Refresh Periods')
plt.xlabel('Refresh period')
plt.ylabel('Slope (m)')
plt.show()

#+end_src

#+RESULTS:
:RESULTS:
[[./.ob-jupyter/bd52ddd5c3838a215173f7dac8a6824064b6ebf8.png]]
[[./.ob-jupyter/3b2f56512a353f61542940f368d67e692cf8bf1c.png]]
[[./.ob-jupyter/c3dddae1bf521a6b19e1a46f1006cca4d1dbfac2.png]]
[[./.ob-jupyter/8654bfc02128eee4bed2b00112d7da4b55fdc046.png]]
:END:

#+begin_src jupyter-python :kernel iotvar_powerprofiler
from mpl_toolkits.mplot3d import Axes3D

# Assuming your data is in a DataFrame called df with columns 'm', 'refresh_period', and 'b'
X = m_b_df[['m', 'refresh_period']]
y = m_b_df['b']

#+begin_src jupyter-python :kernel iotvar_powerprofiler
plt.figure(figsize=(15, 8))
sns.violinplot(x='number_sensors', y='b', hue='refresh_period', data=m_b_df.to_pandas(), palette='muted', split=False)
plt.title('Distribution of Intercept (b) for different Refresh Periods and Number of Sensors')
plt.xlabel('Number Sensors')
plt.ylabel('Intercept (b)')

#plt.tight_layout()
plt.show()

#+end_src

#+RESULTS:
[[./.ob-jupyter/788c481d6ef20f0d276dbd04ff0ae061ba1830d1.png]]

* Predicting slope m values
** Quantile regression
#+begin_src jupyter-python :kernel iotvar_powerprofiler
from sklearn.utils.fixes import parse_version, sp_version
solver = "highs" if sp_version >= parse_version("1.6.0") else "interior-point"
from sklearn.linear_model import QuantileRegressor

quantiles = [0.05, 0.5, 0.95]
predictions = {}

X = m_b_df['refresh_period'].to_numpy()[:,np.newaxis]
Y = m_b_df['m'].to_numpy()

for quantile in quantiles:
    qr = QuantileRegressor(quantile=quantile, alpha=0, solver=solver)
    y_pred = qr.fit(X, Y).predict(X)
    predictions[quantile] = y_pred

for quantile, y_pred in predictions.items():
    plt.plot(X, y_pred, label=f"Quantile: {quantile}")
plt.plot(X,Y,'.',label='measurements')
plt.xlabel('Refresh Period')
plt.ylabel('Slope m')
plt.legend()
plt.show()
#+end_src

#+RESULTS:
:RESULTS:
#+attr_org: :width 739
[[./.ob-jupyter/65cca2c4c409fb0b381fa76b0221b1622dc74240.png]]
:END:
** Gradient Boosting Regression
#+begin_src jupyter-python :kernel iotvar_powerprofiler
from sklearn.ensemble import GradientBoostingRegressor
from sklearn.metrics import mean_pinball_loss, mean_squared_error

X = np.zeros([len(m_b_df['number_sensors']),2])
X[:,0] = np.array(m_b_df['refresh_period'])
X[:,1] = np.array(m_b_df['number_sensors'])

#X = m_b_df['refresh_period'].to_numpy()[:,np.newaxis]
y = m_b_df['m'].to_numpy()
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)

all_models = {}
common_params = dict(
    learning_rate=0.05,
    n_estimators=200,
    max_depth=2,
    min_samples_leaf=9,
    min_samples_split=9,
)
for alpha in [0.05, 0.5, 0.95]:
    gbr = GradientBoostingRegressor(loss="quantile", alpha=alpha, **common_params)
    all_models["q %1.2f" % alpha] = gbr.fit(X_train, y_train)

gbr_ls = GradientBoostingRegressor(loss="squared_error", **common_params)
all_models["mse"] = gbr_ls.fit(X_train, y_train)

#xx = np.atleast_2d(np.linspace(0, 20, 1000)).T
xx = X_test
#xx =np.column_stack((np.linspace(0,20,1000),np.linspace(0,200,1000)))
#xx = X_test[:2,:]
#xx = np.array([[1,100],[2,100],[3,100],[4,100],[5,100]])
#xx = np.array([[1,30],[1,80],[1,120],[1,160],[1,190]])
#print(xx)
#print(xx.shape)

y_pred = all_models["mse"].predict(xx)
y_lower = all_models["q 0.05"].predict(xx)
y_upper = all_models["q 0.95"].predict(xx)
y_med = all_models["q 0.50"].predict(xx)

fig = plt.figure(figsize=(10, 10))

#plt.subplot(1,2,1)
plt.plot(X_test[:,0], y_test,'.', markersize=10, label="Test observations")
plt.plot(xx[:,0], y_med, "r.", label="Predicted median")
plt.plot(xx[:,0], y_pred, "r.", label="Predicted mean")
plt.plot(xx[:,0], y_upper, "k.")
plt.plot(xx[:,0], y_lower, "k.")
#plt.fill_between(
#    xx[:,0].ravel(), y_lower, y_upper, alpha=0.4, label="Predicted 90% interval"
#)

plt.xlabel("Refresh period")
plt.ylabel("Slope $m$")
plt.legend(loc="upper right")
plt.show()

fig = plt.figure(figsize=(10, 10))
#plt.subplot(1,2,2)
plt.plot(X_test[:,1], y_test,'.', markersize=10, label="Test observations")
plt.plot(xx[:,1], y_med, "r.", label="Predicted median")
plt.plot(xx[:,1], y_pred, "r.", label="Predicted mean")
plt.plot(xx[:,1], y_upper, "k.")
plt.plot(xx[:,1], y_lower, "k.")
plt.xlabel("Number Sensors")
plt.ylabel("Slope $m$")


#plt.plot(xx, y_med, "r-", label="Predicted median")
#plt.plot(xx, y_pred, "r-", label="Predicted mean")
#plt.plot(xx, y_upper, "k-")
#plt.plot(xx, y_lower, "k-")
#plt.fill_between(
#    xx.ravel(), y_lower, y_upper, alpha=0.4, label="Predicted 90% interval"
#)
#plt.ylim(-10, 25)
plt.legend()
plt.show()
#+end_src

#+RESULTS:
:RESULTS:
[[./.ob-jupyter/105dd66059a086666cfa2f110fe93d6ceb7959b8.png]]
[[./.ob-jupyter/c09d616e2236878800eed52fd65894b8ba9d3658.png]]
:END:

#+begin_src jupyter-python :kernel iotvar_powerprofiler
def highlight_min(x):
    x_min = x.min()
    return ["font-weight: bold" if v == x_min else "" for v in x]


results = []
for name, gbr in sorted(all_models.items()):
    metrics = {"model": name}
    y_pred = gbr.predict(X_train)
    for alpha in [0.05, 0.5, 0.95]:
        metrics["pbl=%1.2f" % alpha] = mean_pinball_loss(y_train, y_pred, alpha=alpha)
    metrics["MSE"] = mean_squared_error(y_train, y_pred)
    results.append(metrics)

print(pd.DataFrame(results).set_index("model").style.apply(highlight_min))
print(results)
#+end_src

#+RESULTS:
: <pandas.io.formats.style.Styler object at 0x7bcbfdde8760>
: [{'model': 'mse', 'pbl=0.05': 0.008277541139456153, 'pbl=0.50': 0.008277541139456206, 'pbl=0.95': 0.008277541139456262, 'MSE': 0.00047492437416087296}, {'model': 'q 0.05', 'pbl=0.05': 0.0022061340811675204, 'pbl=0.50': 0.018279350094757122, 'pbl=0.95': 0.03435256610834673, 'MSE': 0.0018589815965274722}, {'model': 'q 0.50', 'pbl=0.05': 0.008277168193207318, 'pbl=0.50': 0.008223624746037292, 'pbl=0.95': 0.008170081298867263, 'MSE': 0.0004854245758499631}, {'model': 'q 0.95', 'pbl=0.05': 0.031722045235182364, 'pbl=0.50': 0.016904712030278993, 'pbl=0.95': 0.0020873788253756263, 'MSE': 0.0016125127568166705}]

#+begin_src jupyter-python :kernel iotvar_powerprofiler
def coverage_fraction(y, y_low, y_high):
    return np.mean(np.logical_and(y >= y_low, y <= y_high))

coverage_fraction(
    y_train,
    all_models["q 0.05"].predict(X_train),
    all_models["q 0.95"].predict(X_train),
)

#+end_src

#+RESULTS:
: 0.894808743169399

#+begin_src jupyter-python :kernel iotvar_powerprofiler
coverage_fraction(
    y_test, all_models["q 0.05"].predict(X_test), all_models["q 0.95"].predict(X_test)
)
#+end_src

#+RESULTS:
: 0.907103825136612

#+begin_src jupyter-python :kernel iotvar_powerprofiler
from sklearn.experimental import enable_halving_search_cv
from sklearn.model_selection import HalvingRandomSearchCV
from sklearn.metrics import make_scorer
from pprint import pprint

param_grid = dict(
    learning_rate=[0.05, 0.1, 0.2],
    max_depth=[2, 5, 10],
    min_samples_leaf=[1, 5, 10, 20],
    min_samples_split=[5, 10, 20, 30, 50],
)
alpha = 0.05
neg_mean_pinball_loss_05p_scorer = make_scorer(
    mean_pinball_loss,
    alpha=alpha,
    greater_is_better=False,  # maximize the negative loss
)
gbr = GradientBoostingRegressor(loss="quantile", alpha=alpha, random_state=0)
search_05p = HalvingRandomSearchCV(
    gbr,
    param_grid,
    resource="n_estimators",
    max_resources=250,
    min_resources=50,
    scoring=neg_mean_pinball_loss_05p_scorer,
    n_jobs=2,
    random_state=0,
).fit(X_train, y_train)
pprint(search_05p.best_params_)
#+end_src

#+RESULTS:
: /home/han4n/anaconda3/envs/IoTVar_PowerProfiler/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5
:   warnings.warn(f"A NumPy version >={np_minversion} and <{np_maxversion}"
: /home/han4n/anaconda3/envs/IoTVar_PowerProfiler/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5
:   warnings.warn(f"A NumPy version >={np_minversion} and <{np_maxversion}"
: {'learning_rate': 0.2,
:  'max_depth': 2,
:  'min_samples_leaf': 5,
:  'min_samples_split': 5,
:  'n_estimators': 150}

#+begin_src jupyter-python :kernel iotvar_powerprofiler
from sklearn.base import clone

alpha = 0.95
neg_mean_pinball_loss_95p_scorer = make_scorer(
    mean_pinball_loss,
    alpha=alpha,
    greater_is_better=False,  # maximize the negative loss
)
search_95p = clone(search_05p).set_params(
    estimator__alpha=alpha,
    scoring=neg_mean_pinball_loss_95p_scorer,
)
search_95p.fit(X_train, y_train)
pprint(search_95p.best_params_)
#+end_src

#+RESULTS:
: {'learning_rate': 0.2,
:  'max_depth': 2,
:  'min_samples_leaf': 5,
:  'min_samples_split': 5,
:  'n_estimators': 150}

#+begin_src jupyter-python :kernel iotvar_powerprofiler
from sklearn.base import clone

alpha = 0.5
neg_mean_pinball_loss_50p_scorer = make_scorer(
    mean_pinball_loss,
    alpha=alpha,
    greater_is_better=False,  # maximize the negative loss
)
search_50p = clone(search_95p).set_params(
    estimator__alpha=alpha,
    scoring=neg_mean_pinball_loss_95p_scorer,
)
search_50p.fit(X_train, y_train)
pprint(search_95p.best_params_)
#+end_src

#+RESULTS:
: /home/han4n/anaconda3/envs/IoTVar_PowerProfiler/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5
:   warnings.warn(f"A NumPy version >={np_minversion} and <{np_maxversion}"
: /home/han4n/anaconda3/envs/IoTVar_PowerProfiler/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5
:   warnings.warn(f"A NumPy version >={np_minversion} and <{np_maxversion}"
: {'learning_rate': 0.2,
:  'max_depth': 2,
:  'min_samples_leaf': 5,
:  'min_samples_split': 5,
:  'n_estimators': 150}


#+begin_src jupyter-python :kernel iotvar_powerprofiler
y_lower = search_05p.predict(xx)
y_upper = search_95p.predict(xx)
y_med = search_50p.predict(xx)


fig = plt.figure(figsize=(10, 10))
plt.plot(X_test[:,0], y_test, "b.", markersize=10, label="Test observations")
plt.plot(xx[:,0], y_upper, "r.")
plt.plot(xx[:,0], y_lower, "r.")
plt.plot(xx[:,0], y_med, "k.", label="Predicted median")
#plt.fill_between(
#    xx[:,0].ravel(), y_lower, y_upper, alpha=0.4, label="Predicted 90% interval"
#)
plt.xlabel("$Refresh Period$")
plt.ylabel("Slope $m$")
plt.legend(loc="upper right")
plt.title("Prediction with tuned hyper-parameters")
plt.show()

fig = plt.figure(figsize=(10, 10))
plt.plot(X_test[:,1], y_test, "b.", markersize=10, label="Test observations")
plt.plot(xx[:,1], y_upper, "r.")
plt.plot(xx[:,1], y_lower, "r.")
plt.plot(xx[:,1], y_med, "k.", label="Predicted median")
#plt.fill_between(
#    xx[:,0].ravel(), y_lower, y_upper, alpha=0.4, label="Predicted 90% interval"
#)
plt.xlabel("$Refresh Period$")
plt.ylabel("Slope $m$")
plt.legend(loc="upper right")
plt.title("Prediction with tuned hyper-parameters")
plt.show()

#+end_src

#+RESULTS:
:RESULTS:
[[./.ob-jupyter/500662dc5a34e3f91b0f6ba56c9fbf01a3093bdf.png]]
[[./.ob-jupyter/1acfc17d3a4d815c391b3cf535455205bbaf4583.png]]
:END:

#+begin_src jupyter-python :kernel iotvar_powerprofiler
coverage_fraction(y_train, search_05p.predict(X_train), search_95p.predict(X_train))
#+end_src

#+RESULTS:
: 0.8989071038251366

#+begin_src jupyter-python :kernel iotvar_powerprofiler
coverage_fraction(y_test, search_05p.predict(X_test), search_95p.predict(X_test))
#+end_src

#+RESULTS:
: 0.9234972677595629

#+begin_src jupyter-python :kernel iotvar_powerprofiler
refresh_periods = np.arange(1, 21)
number_sensors = np.arange(1, 201)
grid_refresh_periods, grid_number_sensors = np.meshgrid(refresh_periods, number_sensors)
xx = np.c_[grid_refresh_periods.ravel(), grid_number_sensors.ravel()]

y_lower = search_05p.predict(xx)
y_upper = search_95p.predict(xx)
y_med = search_50p.predict(xx)

plt.figure(figsize=(10, 10))
plt.plot(X_test[:,0], y_test, "b.", markersize=10, label="Test observations")
plt.plot(xx[:,0], y_upper, "r.")
plt.plot(xx[:,0], y_lower, "r.")
plt.plot(xx[:,0], y_med, "k.", label="Predicted median")

plt.legend()
plt.xlabel('Refresh Period')
plt.ylabel('m')
plt.title('Quantile Regression Predictions vs Actual Values')
plt.grid()
plt.show()

plt.figure(figsize=(10, 10))
plt.plot(X_test[:,1], y_test, "b.", markersize=10, label="Test observations")
plt.plot(xx[:,1], y_upper, "r.")
plt.plot(xx[:,1], y_lower, "r.")
plt.plot(xx[:,1], y_med, "k.", label="Predicted median")
plt.legend()
plt.xlabel('Number of Sensors')
plt.ylabel('m')
plt.title('Quantile Regression Predictions vs Actual Values')
plt.grid()
plt.show()
#+end_src

#+RESULTS:
:RESULTS:
[[./.ob-jupyter/e39cd0724a1f1c385a2d484198cdb771f009d844.png]]
[[./.ob-jupyter/94fc142e457b13b7efd8811e4b72bc613cfcd9b5.png]]
:END:

** Quantile loss NN
#+begin_src jupyter-python :kernel iotvar_powerprofiler :results silent
import tensorflow.keras.backend as K

# Custom quantile loss function
def quantile_loss(alpha):
    def loss(y_true, y_pred):
        e = y_true - y_pred
        return K.mean(K.maximum(alpha * e, (alpha - 1) * e), axis=-1)
    return loss

X = np.zeros([len(m_b_df['number_sensors']), 2])
X[:, 0] = np.array(m_b_df['refresh_period'])
X[:, 1] = np.array(m_b_df['number_sensors'])
y = m_b_df['m'].to_numpy()

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)

# Neural network model
def create_model():
    model = Sequential()
    model.add(Dense(8, input_dim=2, activation='relu'))
    model.add(Dense(16, activation='relu'))
    model.add(Dense(1, activation='linear'))
    return model

# Train models for different quantiles
alphas = [0.05, 0.5, 0.95]
models = {}
histories = {}

for alpha in alphas:
    model = create_model()
    model.compile(loss=quantile_loss(alpha), optimizer=Adam(learning_rate=0.01))
    history = model.fit(X_train, y_train, epochs=200, batch_size=8, verbose=0)
    models[alpha] = model
    histories[alpha] = history
#+end_src

#+begin_src jupyter-python :kernel iotvar_powerprofiler
# Predictions
#xx = np.array([[1, 30], [1, 80], [1, 120], [1, 160], [1, 190]])
xx = X_test
#xx = np.array([[1,100],[2,100],[3,100],[4,100],[5,100],[30,100]])
y_pred = models[0.5].predict(xx).flatten()  # Median
y_lower = models[0.05].predict(xx).flatten()
y_upper = models[0.95].predict(xx).flatten()

# Plot results
fig= plt.subplots(figsize=(10, 10))
plt.plot(X_test[:, 0], y_test, '.', markersize=10, label="Test observations")
plt.plot(xx[:, 0], y_pred, "r.", label="Predicted median")
plt.plot(xx[:, 0], y_upper, "y.")
plt.plot(xx[:, 0], y_lower, "y.")
plt.xlabel("Refresh period")
plt.ylabel("Slope $m$")
plt.legend(loc="upper right")
plt.show()

fig= plt.subplots(figsize=(10, 10))
plt.plot(X_test[:, 1], y_test, '.', markersize=10, label="Test observations")
plt.plot(xx[:, 1], y_pred, "r.", label="Predicted median")
plt.plot(xx[:, 1], y_upper, "y.")
plt.plot(xx[:, 1], y_lower, "y.")
plt.xlabel("Number Sensors")
plt.ylabel("Slope $m$")
plt.legend(loc="upper right")

plt.show()

# Plot the evolution of the loss function
plt.figure(figsize=(10, 6))
for alpha in alphas:
    plt.plot(histories[alpha].history['loss'], label=f'Quantile {alpha}')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.title('Evolution of Loss Function Over Epochs')
plt.legend()
plt.show()
#+end_src

#+RESULTS:
:RESULTS:
: 1/6 [====>.........................] - ETA: 0s6/6 [==============================] - 0s 1ms/step
: 1/6 [====>.........................] - ETA: 0s6/6 [==============================] - 0s 2ms/step
: 1/6 [====>.........................] - ETA: 0s6/6 [==============================] - 0s 2ms/step
[[./.ob-jupyter/48f8826a9eaebd4f60b23f16497d4a0c08fa48e5.png]]
[[./.ob-jupyter/836b38809d2e2bdb06cb51ad2507077214661dc7.png]]
[[./.ob-jupyter/f657b35a6f1d034cfe591f77eba6ba33a18b0f40.png]]
:END:

#+begin_src jupyter-python :kernel iotvar_powerprofiler
def coverage_fraction(y, y_low, y_high):
    return np.mean(np.logical_and(y >= y_low, y <= y_high))
coverage_fraction(y_train,models[0.05].predict(X_train),models[0.95].predict(X_train))
#+end_src

#+RESULTS:
:RESULTS:
:  1/23 [>.............................] - ETA: 0s23/23 [==============================] - 0s 1ms/step
:  1/23 [>.............................] - ETA: 0s23/23 [==============================] - 0s 1ms/step
: 0.7806238615664846
:END:

#+begin_src jupyter-python :kernel iotvar_powerprofiler
coverage_fraction(y_test,models[0.05].predict(X_test),models[0.95].predict(X_test))
#+end_src

#+RESULTS:
:RESULTS:
: 1/6 [====>.........................] - ETA: 0s6/6 [==============================] - 0s 1ms/step
: 1/6 [====>.........................] - ETA: 0s6/6 [==============================] - 0s 2ms/step
: 0.7835408641643524
:END:
*** Hyperparameter tuning
#+begin_src jupyter-python :kernel iotvar_powerprofiler
import optuna
from optuna.integration import TFKerasPruningCallback
# Custom quantile loss function
def quantile_loss(alpha):
    def loss(y_true, y_pred):
        e = y_true - y_pred
        return K.mean(K.maximum(alpha * e, (alpha - 1) * e), axis=-1)
    return loss

X = np.zeros([len(m_b_df['number_sensors']), 2])
X[:, 0] = np.array(m_b_df['refresh_period'])
X[:, 1] = np.array(m_b_df['number_sensors'])
y = m_b_df['m'].to_numpy()

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)

# Neural network model
def create_model(hidden_units, learning_rate):
    model = Sequential()
    model.add(Dense(hidden_units, input_dim=2, activation='relu'))
    model.add(Dense(hidden_units, activation='relu'))
    model.add(Dense(1, activation='linear'))
    model.compile(loss=quantile_loss(alpha), optimizer=Adam(learning_rate=learning_rate))
    return model

# Objective function for Optuna
def objective(trial):
    hidden_units = trial.suggest_int('hidden_units', 32, 128)
    learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-1)
    batch_size = trial.suggest_int('batch_size', 8, 64)
    alpha = trial.suggest_categorical('alpha', [0.05, 0.5, 0.95])

    model = create_model(hidden_units, learning_rate)

    history = model.fit(
        X_train, y_train,
        epochs=100,
        batch_size=batch_size,
        verbose=0,
        validation_data=(X_test, y_test),
        callbacks=[TFKerasPruningCallback(trial, 'val_loss')]
    )

    val_loss = min(history.history['val_loss'])
    return val_loss

# Optuna study setup
study = optuna.create_study(direction='minimize')
study.optimize(objective, n_trials=50, timeout=600)

# Best hyperparameters
print('Best trial:')
trial = study.best_trial
print(f'  Value: {trial.value}')
print('  Params: ')
for key, value in trial.params.items():
    print(f'    {key}: {value}')

# Train final model with the best hyperparameters
best_hidden_units = trial.params['hidden_units']
best_learning_rate = trial.params['learning_rate']
best_batch_size = trial.params['batch_size']
best_alpha = trial.params['alpha']

final_model = create_model(best_hidden_units, best_learning_rate)
history = final_model.fit(X_train, y_train, epochs=100, batch_size=best_batch_size, verbose=0)

# Predictions with the final model
#xx = np.array([[1, 30], [1, 80], [1, 120], [1, 160], [1, 190]])
xx = X_test
y_pred = final_model.predict(xx).flatten()

# Plot results
plt.figure(figsize=(10, 6))
plt.plot(X_test[:, 0], y_test, '.', markersize=10, label="Test observations")
plt.plot(xx[:, 0], y_pred, "r.", label="Predicted values")
plt.xlabel("Refresh period")
plt.ylabel("Slope $m$")
plt.legend(loc="upper right")
plt.show()

# Plot the evolution of the loss function
plt.figure(figsize=(10, 6))
plt.plot(history.history['loss'], label='Training loss')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.title('Evolution of Loss Function Over Epochs')
plt.legend()
plt.show()
#+end_src

#+RESULTS:
:RESULTS:
#+begin_example
[I 2024-06-08 18:32:43,044] A new study created in memory with name: no-name-79829d53-6881-47c7-911a-1853fbb32f4a
/tmp/ipykernel_14801/2727289006.py:29: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 1e-1)
[I 2024-06-08 18:32:50,481] Trial 0 finished with value: 0.048212334513664246 and parameters: {'hidden_units': 118, 'learning_rate': 0.00010199360980032537, 'batch_size': 30, 'alpha': 0.05}. Best is trial 0 with value: 0.048212334513664246.
[I 2024-06-08 18:32:59,999] Trial 1 finished with value: 0.0021458070259541273 and parameters: {'hidden_units': 114, 'learning_rate': 0.0034026432597446103, 'batch_size': 20, 'alpha': 0.5}. Best is trial 1 with value: 0.0021458070259541273.
[I 2024-06-08 18:33:06,752] Trial 2 finished with value: 0.007606030907481909 and parameters: {'hidden_units': 60, 'learning_rate': 0.0004185557775977266, 'batch_size': 33, 'alpha': 0.5}. Best is trial 1 with value: 0.0021458070259541273.
[I 2024-06-08 18:33:12,261] Trial 3 finished with value: 0.015252530574798584 and parameters: {'hidden_units': 60, 'learning_rate': 0.000685106401237116, 'batch_size': 47, 'alpha': 0.5}. Best is trial 1 with value: 0.0021458070259541273.
[I 2024-06-08 18:33:18,645] Trial 4 finished with value: 0.0076019661501049995 and parameters: {'hidden_units': 116, 'learning_rate': 0.0007324681948533714, 'batch_size': 37, 'alpha': 0.95}. Best is trial 1 with value: 0.0021458070259541273.
[I 2024-06-08 18:33:19,405] Trial 5 pruned. Trial was pruned at epoch 0.
[I 2024-06-08 18:33:21,902] Trial 6 pruned. Trial was pruned at epoch 43.
[I 2024-06-08 18:33:31,071] Trial 7 finished with value: 0.015551501885056496 and parameters: {'hidden_units': 104, 'learning_rate': 0.07664821179547941, 'batch_size': 23, 'alpha': 0.5}. Best is trial 1 with value: 0.0021458070259541273.
[I 2024-06-08 18:33:31,812] Trial 8 pruned. Trial was pruned at epoch 0.
[I 2024-06-08 18:33:32,526] Trial 9 pruned. Trial was pruned at epoch 0.
[I 2024-06-08 18:33:48,090] Trial 10 finished with value: 0.0022991725709289312 and parameters: {'hidden_units': 88, 'learning_rate': 0.003011451791499705, 'batch_size': 11, 'alpha': 0.5}. Best is trial 1 with value: 0.0021458070259541273.
[I 2024-06-08 18:33:48,995] Trial 11 pruned. Trial was pruned at epoch 0.
[I 2024-06-08 18:34:04,203] Trial 12 finished with value: 0.0020891514141112566 and parameters: {'hidden_units': 128, 'learning_rate': 0.0038183578047325984, 'batch_size': 11, 'alpha': 0.5}. Best is trial 12 with value: 0.0020891514141112566.
[I 2024-06-08 18:34:04,996] Trial 13 pruned. Trial was pruned at epoch 0.
[I 2024-06-08 18:34:05,793] Trial 14 pruned. Trial was pruned at epoch 0.
[I 2024-06-08 18:34:06,552] Trial 15 pruned. Trial was pruned at epoch 0.
[I 2024-06-08 18:34:07,334] Trial 16 pruned. Trial was pruned at epoch 0.
[I 2024-06-08 18:34:19,441] Trial 17 finished with value: 0.0021050311625003815 and parameters: {'hidden_units': 76, 'learning_rate': 0.006340486219809502, 'batch_size': 14, 'alpha': 0.5}. Best is trial 12 with value: 0.0020891514141112566.
[I 2024-06-08 18:34:32,161] Trial 18 finished with value: 0.005661351606249809 and parameters: {'hidden_units': 41, 'learning_rate': 0.059970638660608595, 'batch_size': 13, 'alpha': 0.05}. Best is trial 12 with value: 0.0020891514141112566.
[I 2024-06-08 18:34:32,930] Trial 19 pruned. Trial was pruned at epoch 0.
[I 2024-06-08 18:34:33,670] Trial 20 pruned. Trial was pruned at epoch 0.
[I 2024-06-08 18:34:34,465] Trial 21 pruned. Trial was pruned at epoch 0.
[I 2024-06-08 18:34:36,373] Trial 22 pruned. Trial was pruned at epoch 7.
[I 2024-06-08 18:34:37,144] Trial 23 pruned. Trial was pruned at epoch 0.
[I 2024-06-08 18:34:38,094] Trial 24 pruned. Trial was pruned at epoch 0.
[I 2024-06-08 18:34:47,639] Trial 25 finished with value: 0.008954979479312897 and parameters: {'hidden_units': 109, 'learning_rate': 0.0358098923193052, 'batch_size': 20, 'alpha': 0.5}. Best is trial 12 with value: 0.0020891514141112566.
[I 2024-06-08 18:34:48,709] Trial 26 pruned. Trial was pruned at epoch 1.
[I 2024-06-08 18:34:49,487] Trial 27 pruned. Trial was pruned at epoch 0.
[I 2024-06-08 18:35:03,151] Trial 28 finished with value: 0.002859683707356453 and parameters: {'hidden_units': 122, 'learning_rate': 0.011965792677962446, 'batch_size': 13, 'alpha': 0.95}. Best is trial 12 with value: 0.0020891514141112566.
[I 2024-06-08 18:35:03,929] Trial 29 pruned. Trial was pruned at epoch 0.
[I 2024-06-08 18:35:04,817] Trial 30 pruned. Trial was pruned at epoch 0.
[I 2024-06-08 18:35:05,660] Trial 31 pruned. Trial was pruned at epoch 0.
[I 2024-06-08 18:35:08,224] Trial 32 pruned. Trial was pruned at epoch 11.
[I 2024-06-08 18:35:09,185] Trial 33 pruned. Trial was pruned at epoch 1.
[I 2024-06-08 18:35:10,145] Trial 34 pruned. Trial was pruned at epoch 1.
[I 2024-06-08 18:35:29,369] Trial 35 finished with value: 0.0019114479655399919 and parameters: {'hidden_units': 51, 'learning_rate': 0.012003854856303236, 'batch_size': 8, 'alpha': 0.5}. Best is trial 35 with value: 0.0019114479655399919.
[I 2024-06-08 18:35:30,134] Trial 36 pruned. Trial was pruned at epoch 0.
[I 2024-06-08 18:35:30,924] Trial 37 pruned. Trial was pruned at epoch 0.
[I 2024-06-08 18:35:43,978] Trial 38 pruned. Trial was pruned at epoch 66.
[I 2024-06-08 18:35:52,903] Trial 39 pruned. Trial was pruned at epoch 0.
[I 2024-06-08 18:35:53,640] Trial 40 pruned. Trial was pruned at epoch 0.
[I 2024-06-08 18:35:54,602] Trial 41 pruned. Trial was pruned at epoch 1.
[I 2024-06-08 18:35:55,406] Trial 42 pruned. Trial was pruned at epoch 0.
[I 2024-06-08 18:35:56,398] Trial 43 pruned. Trial was pruned at epoch 1.
[I 2024-06-08 18:36:15,175] Trial 44 finished with value: 0.003050223458558321 and parameters: {'hidden_units': 58, 'learning_rate': 0.008391117415527812, 'batch_size': 8, 'alpha': 0.5}. Best is trial 35 with value: 0.0019114479655399919.
[I 2024-06-08 18:36:16,042] Trial 45 pruned. Trial was pruned at epoch 1.
[I 2024-06-08 18:36:16,977] Trial 46 pruned. Trial was pruned at epoch 1.
[I 2024-06-08 18:36:27,801] Trial 47 finished with value: 0.0026944326236844063 and parameters: {'hidden_units': 63, 'learning_rate': 0.023047313698771454, 'batch_size': 16, 'alpha': 0.5}. Best is trial 35 with value: 0.0019114479655399919.
[I 2024-06-08 18:36:28,564] Trial 48 pruned. Trial was pruned at epoch 0.
[I 2024-06-08 18:36:29,405] Trial 49 pruned. Trial was pruned at epoch 0.
Best trial:
  Value: 0.0019114479655399919
  Params:
    hidden_units: 51
    learning_rate: 0.012003854856303236
    batch_size: 8
    alpha: 0.5
1/6 [====>.........................] - ETA: 0s6/6 [==============================] - 0s 1ms/step
#+end_example
[[./.ob-jupyter/5f07cb3fd494f2550b2708699bfdf4e336acabc3.png]]
[[./.ob-jupyter/4e463a21383c1bdfa985dda350a035916be13acc.png]]
:END:
** NN for predicting quantiles
#+begin_src jupyter-python :kernel iotvar_powerprofiler :results silent
from tensorflow.keras import backend as K
# Define the pinball loss function
def pinball_loss(tau):
    def loss(y_true, y_pred):
        err = y_true - y_pred
        return K.mean(K.maximum(tau * err, (tau - 1) * err), axis=-1)
    return loss

# Assuming m_b_df is defined somewhere

X = np.zeros([len(m_b_df['number_sensors']), 2])
X[:, 0] = np.array(m_b_df['refresh_period'])
X[:, 1] = np.array(m_b_df['number_sensors'])

y = np.array(m_b_df['m']).reshape(-1, 1)  # Reshape y to be a column vector

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)

# Define quantiles
quantiles = [0.05, 0.5, 0.95]

# Define the model
inputs = Input(shape=(2,))
x = Dense(4, activation='relu')(inputs)
x = Dense(16, activation='relu')(x)

# Output layers for each quantile
outputs = [Dense(1, name=f"quantile_{int(q*100)}")(x) for q in quantiles]

# Create the model
model = Model(inputs=inputs, outputs=outputs)

# Compile the model with the pinball loss for each quantile
model.compile(optimizer='adam', loss=[pinball_loss(q) for q in quantiles])

# Train the model
epochs = 200
history = model.fit(X_train, y_train, batch_size=8, epochs=epochs, verbose=1)

# Make predictions
predictions = model.predict(X_test)
#+end_src

#+begin_src jupyter-python :kernel iotvar_powerprofiler
test_input = X_test
predictions = model.predict(test_input)
plt.plot(X_test[:,0], y_test,'r.')

for i, prediction in enumerate(predictions):
    plt.plot(test_input[:,0],predictions[i],'.', label=f'{int(quantiles[i]*100)}th Quantile')

plt.legend()
plt.show()
#+end_src

#+RESULTS:
:RESULTS:
: 1/6 [====>.........................] - ETA: 0s6/6 [==============================] - 0s 2ms/step
#+attr_org: :width 713
[[./.ob-jupyter/3aeeac9d74f23f2eeec9684befccae21d2cc1dc7.png]]
:END:

*** Hyperparameter tuning
#+begin_src jupyter-python :kernel iotvar_powerprofiler :results silent
import optuna

# Define the pinball loss function
def pinball_loss(tau):
    def loss(y_true, y_pred):
        err = y_true - y_pred
        return K.mean(K.maximum(tau * err, (tau - 1) * err), axis=-1)
    return loss

# Define X and y based on the given structure
X = np.zeros([len(m_b_df['number_sensors']), 2])
X[:, 0] = np.array(m_b_df['refresh_period'])
X[:, 1] = np.array(m_b_df['number_sensors'])

y = np.array(m_b_df['m']).reshape(-1, 1)  # Reshape y to be a column vector

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)

# Define quantiles
quantiles = [0.05, 0.5, 0.95]

# Define the objective function for Optuna
def objective(trial):
    n_units_1 = trial.suggest_int('n_units_1', 4, 256)
    n_units_2 = trial.suggest_int('n_units_2', 4, 256)
    learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-1)
    batch_size = trial.suggest_int('batch_size', 8, 128)

    # Define the model
    inputs = Input(shape=(2,))
    x = Dense(n_units_1, activation='relu')(inputs)
    x = Dense(n_units_2, activation='relu')(x)
    # Output layers for each quantile
    outputs = [Dense(1, name=f"quantile_{int(q*100)}")(x) for q in quantiles]

    # Create the model
    model = Model(inputs=inputs, outputs=outputs)

    # Compile the model with the pinball loss for each quantile
    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate),
                  loss=[pinball_loss(q) for q in quantiles])

    # Train the model
    history = model.fit(X_train, y_train, batch_size=batch_size, epochs=50, verbose=0, validation_split=0.2)

    # Evaluate the model
    val_loss = history.history['val_loss'][-1]
    return val_loss

# Create an Optuna study and optimize the objective function
study = optuna.create_study(direction='minimize')
study.optimize(objective, n_trials=50)

# Print the best hyperparameters
print('Best hyperparameters: ', study.best_params)

# Train the model with the best hyperparameters
best_params = study.best_params
n_units_1 = best_params['n_units_1']
n_units_2 = best_params['n_units_2']
learning_rate = best_params['learning_rate']
batch_size = best_params['batch_size']

inputs = Input(shape=(2,))
x = Dense(n_units_1, activation='relu')(inputs)
x = Dense(n_units_2, activation='relu')(x)
outputs = [Dense(1, name=f"quantile_{int(q*100)}")(x) for q in quantiles]
model = Model(inputs=inputs, outputs=outputs)
model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate),
              loss=[pinball_loss(q) for q in quantiles])

history = model.fit(X_train, y_train, batch_size=batch_size, epochs=200, verbose=1)
#+end_src

#+begin_src jupyter-python :kernel iotvar_powerprofiler
test_input = X_test
predictions = model.predict(test_input)

fig = plt.figure(figsize=(10, 10))
plt.plot(X_test[:,0], y_test,'r.')
for i, prediction in enumerate(predictions):
    plt.plot(test_input[:,0],predictions[i],'.', label=f'{int(quantiles[i]*100)}th Quantile')
plt.legend()
plt.show()

fig = plt.figure(figsize=(10, 10))
plt.plot(X_test[:,1], y_test,'r.')
for i, prediction in enumerate(predictions):
    plt.plot(test_input[:,1],predictions[i],'.', label=f'{int(quantiles[i]*100)}th Quantile')
plt.legend()
plt.show()

#+end_src

#+RESULTS:
:RESULTS:
: 1/8 [==>...........................] - ETA: 0s8/8 [==============================] - 0s 3ms/step
[[./.ob-jupyter/1d7841e036dfe2761312f4e72b0321e387b9f685.png]]
[[./.ob-jupyter/7e03ea9f588f9093c2955f23453bbde87c8569b8.png]]
:END:

#+begin_src jupyter-python :kernel iotvar_powerprofiler :results silent
import optuna

# Define the pinball loss function
def pinball_loss(tau):
    def loss(y_true, y_pred):
        err = y_true - y_pred
        return K.mean(K.maximum(tau * err, (tau - 1) * err), axis=-1)
    return loss

# Define X and y based on the given structure
X = np.zeros([len(m_b_df['number_sensors']), 2])
X[:, 0] = np.array(m_b_df['refresh_period'])
X[:, 1] = np.array(m_b_df['number_sensors'])

y = np.array(m_b_df['m']).reshape(-1, 1)  # Reshape y to be a column vector

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)

# Define quantiles
quantiles = [0.05, 0.5, 0.95]

# Define the objective function for Optuna
def objective(trial):
    n_units_1 = trial.suggest_int('n_units_1', 4, 128)
    n_units_2 = trial.suggest_int('n_units_2', 4, 128)
    #n_units_3 = trial.suggest_int('n_units_3', 4, 128)
    learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-1)
    batch_size = trial.suggest_int('batch_size', 8, 128)

    # Define the model
    inputs = Input(shape=(2,))
    x = Dense(n_units_1, activation='relu')(inputs)
    x = Dense(n_units_2, activation='relu')(x)
    #x = Dense(n_units_3, activation='relu')(x)
    # Output layers for each quantile
    outputs = [Dense(1, name=f"quantile_{int(q*100)}")(x) for q in quantiles]

    # Create the model
    model = Model(inputs=inputs, outputs=outputs)

    # Compile the model with the pinball loss for each quantile
    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate),
                  loss=[pinball_loss(q) for q in quantiles])

    # Train the model
    history = model.fit(X_train, y_train, batch_size=batch_size, epochs=50, verbose=0, validation_split=0.2)

    # Evaluate the model
    val_loss = history.history['val_loss'][-1]
    return val_loss

# Create an Optuna study and optimize the objective function
study = optuna.create_study(direction='minimize')
study.optimize(objective, n_trials=50)

# Print the best hyperparameters
print('Best hyperparameters: ', study.best_params)

# Train the model with the best hyperparameters
best_params = study.best_params
n_units_1 = best_params['n_units_1']
n_units_2 = best_params['n_units_2']
#n_units_3 = best_params['n_units_3']
learning_rate = best_params['learning_rate']
batch_size = best_params['batch_size']

inputs = Input(shape=(2,))
x = Dense(n_units_1, activation='relu')(inputs)
x = Dense(n_units_2, activation='relu')(x)
#x = Dense(n_units_3, activation='relu')(x)
#x = Dense(n_units_1, activation='relu')(inputs)
outputs = [Dense(1, name=f"quantile_{int(q*100)}")(x) for q in quantiles]
model = Model(inputs=inputs, outputs=outputs)
model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate),
              loss=[pinball_loss(q) for q in quantiles])

history = model.fit(X_train, y_train, batch_size=batch_size, epochs=200, verbose=1)
#+end_src

#+begin_src jupyter-python :kernel iotvar_powerprofiler
#print(history.history.keys())
plt.figure(figsize=(12, 6))
plt.plot(history.history['loss'], label='Training Loss')
plt.plot(history.history['quantile_5_loss'], label='5th quantile loss')
plt.plot(history.history['quantile_50_loss'], label='50th quantile loss')
plt.plot(history.history['quantile_95_loss'], label='95th quantile loss')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.title('Loss Function Evolution Over Epochs')
plt.legend()
plt.grid(True)
plt.show()
#+end_src

#+RESULTS:
[[./.ob-jupyter/83d6d89f229f356fbe89b9ef450036dcae1ae81f.png]]


#+begin_src jupyter-python :kernel iotvar_powerprofiler
test_input = X_test
predictions = model.predict(test_input)

fig = plt.figure(figsize=(10, 10))
plt.plot(X_test[:,0], y_test,'.',label='Test data')
for i, prediction in enumerate(predictions):
    plt.plot(test_input[:,0],predictions[i],'.', label=f'{int(quantiles[i]*100)}th Quantile')
plt.legend()
plt.show()

fig = plt.figure(figsize=(10, 10))
plt.plot(X_test[:,1], y_test,'.',label='Test data')
for i, prediction in enumerate(predictions):
    plt.plot(test_input[:,1],predictions[i],'.', label=f'{int(quantiles[i]*100)}th Quantile')
plt.legend()
plt.show()

#+end_src

#+RESULTS:
:RESULTS:
: 1/8 [==>...........................] - ETA: 0s8/8 [==============================] - 0s 2ms/step
[[./.ob-jupyter/7f5dc7b3c096b346fb2976c4c376bb62f2370295.png]]
[[./.ob-jupyter/a336644d4f1b7558019d42bb303ca1e6dc6bb109.png]]
:END:
**** softplus
#+begin_src jupyter-python :kernel iotvar_powerprofiler :results silent
import optuna

# Define the pinball loss function
def pinball_loss(tau):
    def loss(y_true, y_pred):
        err = y_true - y_pred
        return K.mean(K.maximum(tau * err, (tau - 1) * err), axis=-1)
    return loss

# Define X and y based on the given structure
X = np.zeros([len(m_b_df['number_sensors']), 2])
X[:, 0] = np.array(m_b_df['refresh_period'])
X[:, 1] = np.array(m_b_df['number_sensors'])

y = np.array(m_b_df['m']).reshape(-1, 1)  # Reshape y to be a column vector

# Normalize inputs and outputs
scaler_X = StandardScaler()
scaler_y = StandardScaler()

X = scaler_X.fit_transform(X)
y = scaler_y.fit_transform(y)

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)

# Define quantiles
quantiles = [0.05, 0.5, 0.95]

# Define the objective function for Optuna
def objective(trial):
    n_units_1 = trial.suggest_int('n_units_1', 4, 128)
    n_units_2 = trial.suggest_int('n_units_2', 4, 128)
    learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-1)
    batch_size = trial.suggest_int('batch_size', 8, 128)

    # Define the model
    inputs = Input(shape=(2,))
    x = Dense(n_units_1, activation='softplus')(inputs)
    x = Dense(n_units_2, activation='softplus')(x)

    # Output layers for each quantile
    outputs = [Dense(1, name=f"quantile_{int(q*100)}")(x) for q in quantiles]

    # Create the model
    model = Model(inputs=inputs, outputs=outputs)

    # Compile the model with the pinball loss for each quantile
    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate),
                  loss=[pinball_loss(q) for q in quantiles])

    # Train the model
    history = model.fit(X_train, y_train, batch_size=batch_size, epochs=50, verbose=0, validation_split=0.2)

    # Evaluate the model
    val_loss = np.mean(history.history['val_loss'])
    return val_loss

# Create an Optuna study and optimize the objective function
study = optuna.create_study(direction='minimize')
study.optimize(objective, n_trials=50)

# Print the best hyperparameters
print('Best hyperparameters: ', study.best_params)

# Train the model with the best hyperparameters
best_params = study.best_params
n_units_1 = best_params['n_units_1']
n_units_2 = best_params['n_units_2']
learning_rate = best_params['learning_rate']
batch_size = best_params['batch_size']

inputs = Input(shape=(2,))
x = Dense(n_units_1, activation='softplus')(inputs)
x = Dense(n_units_2, activation='softplus')(x)
outputs = [Dense(1, name=f"quantile_{int(q*100)}")(x) for q in quantiles]
model = Model(inputs=inputs, outputs=outputs)
model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate),
              loss=[pinball_loss(q) for q in quantiles])

history = model.fit(X_train, y_train, batch_size=batch_size, epochs=200, verbose=1)
#+end_src

#+begin_src jupyter-python :kernel iotvar_powerprofiler
plt.figure(figsize=(12, 6))
plt.plot(history.history['loss'], label='Total Loss')
plt.plot(history.history['quantile_5_loss'], label='Quantile 5th Loss')
plt.plot(history.history['quantile_50_loss'], label='Quantile 50th Loss')
plt.plot(history.history['quantile_95_loss'], label='Quantile 95th Loss')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.title('Loss Function Evolution Over Epochs')
plt.legend()
plt.grid(True)
plt.show()
#+end_src

#+RESULTS:
[[./.ob-jupyter/417bfbe376f12ce27967747db4a36c1cc62474bd.png]]


#+begin_src jupyter-python :kernel iotvar_powerprofiler
predictions = model.predict(X_test)
print('Best hyperparameters: ', study.best_params)
# Inverse transform predictions to the original scale
predictions = [scaler_y.inverse_transform(pred) for pred in predictions]
y_test_inv = scaler_y.inverse_transform(y_test)

# Plotting predictions vs actual values for the test set
plt.figure(figsize=(12, 6))
plt.scatter(scaler_X.inverse_transform(X_test)[:, 0], y_test_inv, alpha=0.3, label='Actual Data')
for i, prediction in enumerate(predictions):
    plt.scatter(scaler_X.inverse_transform(X_test)[:, 0], prediction, alpha=0.3, label=f'{int(quantiles[i]*100)}th Quantile')

plt.legend()
plt.xlabel('Refresh Period')
plt.ylabel('m')
plt.title('Quantile Regression Predictions vs Actual Values')
plt.show()

plt.figure(figsize=(12, 6))
plt.scatter(scaler_X.inverse_transform(X_test)[:, 1], y_test_inv, alpha=0.3, label='Actual Data')
for i, prediction in enumerate(predictions):
    plt.scatter(scaler_X.inverse_transform(X_test)[:, 1], prediction, alpha=0.3, label=f'{int(quantiles[i]*100)}th Quantile')

plt.legend()
plt.xlabel('Number of Sensors')
plt.ylabel('m')
plt.title('Quantile Regression Predictions vs Actual Values')
plt.show()

#+end_src

#+RESULTS:
:RESULTS:
: 1/8 [==>...........................] - ETA: 0s8/8 [==============================] - 0s 2ms/step
: Best hyperparameters:  {'n_units_1': 9, 'n_units_2': 68, 'learning_rate': 0.03134673529716008, 'batch_size': 10}
[[./.ob-jupyter/6841733aaabf00e3b0de093cee4c77299d56eeb4.png]]
[[./.ob-jupyter/ab4cb014da928b4a7096081656bacafd705f4e53.png]]
:END:

#+begin_src jupyter-python :kernel iotvar_powerprofiler
refresh_periods = np.arange(1,61)
number_sensors = np.arange(1, 201)
grid_refresh_periods, grid_number_sensors = np.meshgrid(refresh_periods, number_sensors)
xx = np.c_[grid_refresh_periods.ravel(), grid_number_sensors.ravel()]

#print(xx)
xx = scaler_X.transform(xx)
predictions = model.predict(xx)

predictions = [scaler_y.inverse_transform(pred) for pred in predictions]
y_test_inv = scaler_y.inverse_transform(y_test)

#print(xx)

plt.figure(figsize=(10, 10))
plt.plot(scaler_X.inverse_transform(X_test)[:,0], y_test_inv,'x', label='Actual Data')
for i, prediction in enumerate(predictions):
    if(i==1):
        plt.plot(scaler_X.inverse_transform(xx)[:,0], prediction,'k.', label=f'{int(quantiles[i]*100)}th Quantile')
    else:
        plt.plot(scaler_X.inverse_transform(xx)[:,0], prediction,'r.', label=f'{int(quantiles[i]*100)}th Quantile')

plt.legend()
plt.xlabel('Refresh Period')
plt.ylabel('m')
plt.title('Quantile Regression Predictions vs Actual Values')
plt.grid()
plt.show()

plt.figure(figsize=(10, 10))
plt.plot(scaler_X.inverse_transform(X_test)[:, 1], y_test_inv,'x', label='Actual Data')
for i, prediction in enumerate(predictions):
    if(i==1):
        plt.plot(scaler_X.inverse_transform(xx)[:,1], prediction,'.', label=f'{int(quantiles[i]*100)}th Quantile')
    else:
        plt.plot(scaler_X.inverse_transform(xx)[:,1], prediction,'.', label=f'{int(quantiles[i]*100)}th Quantile')
plt.legend()
plt.xlabel('Number of Sensors')
plt.ylabel('m')
plt.title('Quantile Regression Predictions vs Actual Values')
plt.grid()
plt.show()
#+end_src

#+RESULTS:
:RESULTS:
:   1/375 [..............................] - ETA: 5s 35/375 [=>............................] - ETA: 0s 69/375 [====>.........................] - ETA: 0s103/375 [=======>......................] - ETA: 0s138/375 [==========>...................] - ETA: 0s173/375 [============>.................] - ETA: 0s209/375 [===============>..............] - ETA: 0s244/375 [==================>...........] - ETA: 0s279/375 [=====================>........] - ETA: 0s314/375 [========================>.....] - ETA: 0s349/375 [==========================>...] - ETA: 0s375/375 [==============================] - 1s 1ms/step
[[./.ob-jupyter/a7ab55290d9dc50b4645629c72f8651b450c5ee3.png]]
[[./.ob-jupyter/7d20fd08076157b962bd02ca223245247340aabd.png]]
:END:

**** tanh
#+begin_src jupyter-python :kernel iotvar_powerprofiler :results silent
import optuna

# Define the pinball loss function
def pinball_loss(tau):
    def loss(y_true, y_pred):
        err = y_true - y_pred
        return K.mean(K.maximum(tau * err, (tau - 1) * err), axis=-1)
    return loss

# Define X and y based on the given structure
X = np.zeros([len(m_b_df['number_sensors']), 2])
X[:, 0] = np.array(m_b_df['refresh_period'])
X[:, 1] = np.array(m_b_df['number_sensors'])

y = np.array(m_b_df['m']).reshape(-1, 1)  # Reshape y to be a column vector

# Normalize inputs and outputs
scaler_X = StandardScaler()
scaler_y = StandardScaler()

X = scaler_X.fit_transform(X)
y = scaler_y.fit_transform(y)

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)

# Define quantiles
quantiles = [0.05, 0.5, 0.95]

# Define the objective function for Optuna
def objective(trial):
    n_units_1 = trial.suggest_int('n_units_1', 4, 128)
    n_units_2 = trial.suggest_int('n_units_2', 4, 128)
    learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-1)
    batch_size = trial.suggest_int('batch_size', 8, 128)

    # Define the model
    inputs = Input(shape=(2,))
    x = Dense(n_units_1, activation='tanh')(inputs)
    x = Dense(n_units_2, activation='tanh')(x)

    # Output layers for each quantile
    outputs = [Dense(1, name=f"quantile_{int(q*100)}")(x) for q in quantiles]

    # Create the model
    model = Model(inputs=inputs, outputs=outputs)

    # Compile the model with the pinball loss for each quantile
    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate),
                  loss=[pinball_loss(q) for q in quantiles])

    # Train the model
    history = model.fit(X_train, y_train, batch_size=batch_size, epochs=50, verbose=0, validation_split=0.2)

    # Evaluate the model
    val_loss = np.mean(history.history['val_loss'])
    return val_loss

# Create an Optuna study and optimize the objective function
study = optuna.create_study(direction='minimize')
study.optimize(objective, n_trials=50)

# Print the best hyperparameters
print('Best hyperparameters: ', study.best_params)

# Train the model with the best hyperparameters
best_params = study.best_params
n_units_1 = best_params['n_units_1']
n_units_2 = best_params['n_units_2']
learning_rate = best_params['learning_rate']
batch_size = best_params['batch_size']

inputs = Input(shape=(2,))
x = Dense(n_units_1, activation='tanh')(inputs)
x = Dense(n_units_2, activation='tanh')(x)
outputs = [Dense(1, name=f"quantile_{int(q*100)}")(x) for q in quantiles]
model = Model(inputs=inputs, outputs=outputs)
model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate),
              loss=[pinball_loss(q) for q in quantiles])

history = model.fit(X_train, y_train, batch_size=batch_size, epochs=200, verbose=1)
#+end_src
#+begin_src jupyter-python :kernel iotvar_powerprofiler
plt.figure(figsize=(12, 6))
plt.plot(history.history['loss'], label='Total Loss')
plt.plot(history.history['quantile_5_loss'], label='Quantile 5th Loss')
plt.plot(history.history['quantile_50_loss'], label='Quantile 50th Loss')
plt.plot(history.history['quantile_95_loss'], label='Quantile 95th Loss')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.title('Loss Function Evolution Over Epochs')
plt.legend()
plt.grid(True)
plt.show()
#+end_src

#+RESULTS:
[[./.ob-jupyter/a9a20475a357a751a41229c39351cfcd704f4d9a.png]]


#+begin_src jupyter-python :kernel iotvar_powerprofiler
predictions = model.predict(X_test)
print('Best hyperparameters: ', study.best_params)
# Inverse transform predictions to the original scale
predictions = [scaler_y.inverse_transform(pred) for pred in predictions]
y_test_inv = scaler_y.inverse_transform(y_test)

# Plotting predictions vs actual values for the test set
plt.figure(figsize=(12, 6))
plt.scatter(scaler_X.inverse_transform(X_test)[:, 0], y_test_inv, alpha=0.3, label='Actual Data')
for i, prediction in enumerate(predictions):
    plt.scatter(scaler_X.inverse_transform(X_test)[:, 0], prediction, alpha=0.3, label=f'{int(quantiles[i]*100)}th Quantile')

plt.legend()
plt.xlabel('Refresh Period')
plt.ylabel('m')
plt.title('Quantile Regression Predictions vs Actual Values')
plt.show()

plt.figure(figsize=(12, 6))
plt.scatter(scaler_X.inverse_transform(X_test)[:, 1], y_test_inv, alpha=0.3, label='Actual Data')
for i, prediction in enumerate(predictions):
    plt.scatter(scaler_X.inverse_transform(X_test)[:, 1], prediction, alpha=0.3, label=f'{int(quantiles[i]*100)}th Quantile')

plt.legend()
plt.xlabel('Number of Sensors')
plt.ylabel('m')
plt.title('Quantile Regression Predictions vs Actual Values')
plt.show()
#+end_src

#+RESULTS:
:RESULTS:
: 1/8 [==>...........................] - ETA: 0s8/8 [==============================] - 0s 2ms/step
: Best hyperparameters:  {'n_units_1': 43, 'n_units_2': 20, 'learning_rate': 0.017218337932607897, 'batch_size': 20}
[[./.ob-jupyter/baf23cbca1bd0cf4252aa8ede67285cb90aab7c3.png]]
[[./.ob-jupyter/cf77dcf5aba43e4ddecac283529a0b7b32ee0228.png]]
:END:

#+begin_src jupyter-python :kernel iotvar_powerprofiler
refresh_periods = np.arange(1,61)
number_sensors = np.arange(1, 201)
grid_refresh_periods, grid_number_sensors = np.meshgrid(refresh_periods, number_sensors)
xx = np.c_[grid_refresh_periods.ravel(), grid_number_sensors.ravel()]

#print(xx)
xx = scaler_X.transform(xx)
predictions = model.predict(xx)

predictions = [scaler_y.inverse_transform(pred) for pred in predictions]
y_test_inv = scaler_y.inverse_transform(y_test)

#print(xx)

plt.figure(figsize=(10, 10))
plt.plot(scaler_X.inverse_transform(X_test)[:,0], y_test_inv,'x', label='Actual Data')
for i, prediction in enumerate(predictions):
    if(i==1):
        plt.plot(scaler_X.inverse_transform(xx)[:,0], prediction,'k.', label=f'{int(quantiles[i]*100)}th Quantile')
    else:
        plt.plot(scaler_X.inverse_transform(xx)[:,0], prediction,'r.', label=f'{int(quantiles[i]*100)}th Quantile')

plt.legend()
plt.xlabel('Refresh Period')
plt.ylabel('m')
plt.title('Quantile Regression Predictions vs Actual Values')
plt.grid()
plt.show()

plt.figure(figsize=(10, 10))
plt.plot(scaler_X.inverse_transform(X_test)[:, 1], y_test_inv,'x', label='Actual Data')
for i, prediction in enumerate(predictions):
    if(i==1):
        plt.plot(scaler_X.inverse_transform(xx)[:,1], prediction,'.', label=f'{int(quantiles[i]*100)}th Quantile')
    else:
        plt.plot(scaler_X.inverse_transform(xx)[:,1], prediction,'.', label=f'{int(quantiles[i]*100)}th Quantile')
plt.legend()
plt.xlabel('Number of Sensors')
plt.ylabel('m')
plt.title('Quantile Regression Predictions vs Actual Values')
plt.grid()
plt.show()
#+end_src

#+RESULTS:
:RESULTS:
:   1/375 [..............................] - ETA: 5s 35/375 [=>............................] - ETA: 0s 69/375 [====>.........................] - ETA: 0s103/375 [=======>......................] - ETA: 0s137/375 [=========>....................] - ETA: 0s172/375 [============>.................] - ETA: 0s206/375 [===============>..............] - ETA: 0s239/375 [==================>...........] - ETA: 0s274/375 [====================>.........] - ETA: 0s308/375 [=======================>......] - ETA: 0s342/375 [==========================>...] - ETA: 0s375/375 [==============================] - 1s 1ms/step
[[./.ob-jupyter/ff1b828ac02d4a905950566104772bbf662676c1.png]]
[[./.ob-jupyter/4cb758b66ec3713420a6a1249acb7e0e7d7d5d37.png]]
:END:

**** relu
#+begin_src jupyter-python :kernel iotvar_powerprofiler :results silent
import optuna

# Define the pinball loss function
def pinball_loss(tau):
    def loss(y_true, y_pred):
        err = y_true - y_pred
        return K.mean(K.maximum(tau * err, (tau - 1) * err), axis=-1)
    return loss

# Define X and y based on the given structure
X = np.zeros([len(m_b_df['number_sensors']), 2])
X[:, 0] = np.array(m_b_df['refresh_period'])
X[:, 1] = np.array(m_b_df['number_sensors'])

y = np.array(m_b_df['m']).reshape(-1, 1)  # Reshape y to be a column vector

# Normalize inputs and outputs
scaler_X = StandardScaler()
scaler_y = StandardScaler()

X = scaler_X.fit_transform(X)
y = scaler_y.fit_transform(y)

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)

# Define quantiles
quantiles = [0.05, 0.5, 0.95]

# Define the objective function for Optuna
def objective(trial):
    n_units_1 = trial.suggest_int('n_units_1', 4, 128)
    n_units_2 = trial.suggest_int('n_units_2', 4, 128)
    learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-1)
    batch_size = trial.suggest_int('batch_size', 8, 128)

    # Define the model
    inputs = Input(shape=(2,))
    x = Dense(n_units_1, activation='relu')(inputs)
    x = Dense(n_units_2, activation='relu')(x)

    # Output layers for each quantile
    outputs = [Dense(1, name=f"quantile_{int(q*100)}")(x) for q in quantiles]

    # Create the model
    model = Model(inputs=inputs, outputs=outputs)

    # Compile the model with the pinball loss for each quantile
    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate),
                  loss=[pinball_loss(q) for q in quantiles])

    # Train the model
    history = model.fit(X_train, y_train, batch_size=batch_size, epochs=50, verbose=0, validation_split=0.2)

    # Evaluate the model
    val_loss = np.mean(history.history['val_loss'])
    return val_loss

# Create an Optuna study and optimize the objective function
study = optuna.create_study(direction='minimize')
study.optimize(objective, n_trials=50)

# Print the best hyperparameters
print('Best hyperparameters: ', study.best_params)

# Train the model with the best hyperparameters
best_params = study.best_params
n_units_1 = best_params['n_units_1']
n_units_2 = best_params['n_units_2']
learning_rate = best_params['learning_rate']
batch_size = best_params['batch_size']

inputs = Input(shape=(2,))
x = Dense(n_units_1, activation='relu')(inputs)
x = Dense(n_units_2, activation='relu')(x)
outputs = [Dense(1, name=f"quantile_{int(q*100)}")(x) for q in quantiles]
model = Model(inputs=inputs, outputs=outputs)
model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate),
              loss=[pinball_loss(q) for q in quantiles])

history = model.fit(X_train, y_train, batch_size=batch_size, epochs=200, verbose=1)
#+end_src

#+begin_src jupyter-python :kernel iotvar_powerprofiler
plt.figure(figsize=(12, 6))
plt.plot(history.history['loss'], label='Total Loss')
plt.plot(history.history['quantile_5_loss'], label='Quantile 5th Loss')
plt.plot(history.history['quantile_50_loss'], label='Quantile 50th Loss')
plt.plot(history.history['quantile_95_loss'], label='Quantile 95th Loss')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.title('Loss Function Evolution Over Epochs')
plt.legend()
plt.grid(True)
plt.show()
#+end_src

#+RESULTS:
[[./.ob-jupyter/7a258b7fcca2a8ec4bbb7e9f96a1b121eb8ec33e.png]]


#+begin_src jupyter-python :kernel iotvar_powerprofiler
predictions = model.predict(X_test)
print('Best hyperparameters: ', study.best_params)
# Inverse transform predictions to the original scale
predictions = [scaler_y.inverse_transform(pred) for pred in predictions]
y_test_inv = scaler_y.inverse_transform(y_test)

# Plotting predictions vs actual values for the test set
plt.figure(figsize=(12, 6))
plt.scatter(scaler_X.inverse_transform(X_test)[:, 0], y_test_inv, alpha=0.3, label='Actual Data')
for i, prediction in enumerate(predictions):
    plt.scatter(scaler_X.inverse_transform(X_test)[:, 0], prediction, alpha=0.3, label=f'{int(quantiles[i]*100)}th Quantile')

plt.legend()
plt.xlabel('Refresh Period')
plt.ylabel('m')
plt.title('Quantile Regression Predictions vs Actual Values')
plt.show()

plt.figure(figsize=(12, 6))
plt.scatter(scaler_X.inverse_transform(X_test)[:, 1], y_test_inv, alpha=0.3, label='Actual Data')
for i, prediction in enumerate(predictions):
    plt.scatter(scaler_X.inverse_transform(X_test)[:, 1], prediction, alpha=0.3, label=f'{int(quantiles[i]*100)}th Quantile')

plt.legend()
plt.xlabel('Number of Sensors')
plt.ylabel('m')
plt.title('Quantile Regression Predictions vs Actual Values')
plt.show()
#+end_src

#+RESULTS:
:RESULTS:
: 1/8 [==>...........................] - ETA: 0s8/8 [==============================] - 0s 2ms/step
: Best hyperparameters:  {'n_units_1': 52, 'n_units_2': 102, 'learning_rate': 0.005129049480964481, 'batch_size': 18}
[[./.ob-jupyter/d58bb3e67dee1ea44066f5946f7ff39dc9c5dae0.png]]
[[./.ob-jupyter/ebe41307127f735bbbe33fd55dbdc63ef7f3e8e2.png]]
:END:
#+begin_src jupyter-python :kernel iotvar_powerprofiler
refresh_periods = np.arange(1,61)
number_sensors = np.arange(1, 201)
grid_refresh_periods, grid_number_sensors = np.meshgrid(refresh_periods, number_sensors)
xx = np.c_[grid_refresh_periods.ravel(), grid_number_sensors.ravel()]

#print(xx)
xx = scaler_X.transform(xx)
predictions = model.predict(xx)

predictions = [scaler_y.inverse_transform(pred) for pred in predictions]
y_test_inv = scaler_y.inverse_transform(y_test)

#print(xx)

plt.figure(figsize=(10, 10))
plt.plot(scaler_X.inverse_transform(X_test)[:,0], y_test_inv,'x', label='Actual Data')
for i, prediction in enumerate(predictions):
    if(i==1):
        plt.plot(scaler_X.inverse_transform(xx)[:,0], prediction,'k.', label=f'{int(quantiles[i]*100)}th Quantile')
    else:
        plt.plot(scaler_X.inverse_transform(xx)[:,0], prediction,'r.', label=f'{int(quantiles[i]*100)}th Quantile')

plt.legend()
plt.xlabel('Refresh Period')
plt.ylabel('m')
plt.title('Quantile Regression Predictions vs Actual Values')
plt.grid()
plt.show()

plt.figure(figsize=(10, 10))
plt.plot(scaler_X.inverse_transform(X_test)[:, 1], y_test_inv,'x', label='Actual Data')
for i, prediction in enumerate(predictions):
    if(i==1):
        plt.plot(scaler_X.inverse_transform(xx)[:,1], prediction,'.', label=f'{int(quantiles[i]*100)}th Quantile')
    else:
        plt.plot(scaler_X.inverse_transform(xx)[:,1], prediction,'.', label=f'{int(quantiles[i]*100)}th Quantile')
plt.legend()
plt.xlabel('Number of Sensors')
plt.ylabel('m')
plt.title('Quantile Regression Predictions vs Actual Values')
plt.grid()
plt.show()
#+end_src

#+RESULTS:
:RESULTS:
:   1/375 [..............................] - ETA: 6s 31/375 [=>............................] - ETA: 0s 61/375 [===>..........................] - ETA: 0s 91/375 [======>.......................] - ETA: 0s120/375 [========>.....................] - ETA: 0s149/375 [==========>...................] - ETA: 0s177/375 [=============>................] - ETA: 0s208/375 [===============>..............] - ETA: 0s239/375 [==================>...........] - ETA: 0s270/375 [====================>.........] - ETA: 0s301/375 [=======================>......] - ETA: 0s332/375 [=========================>....] - ETA: 0s363/375 [============================>.] - ETA: 0s375/375 [==============================] - 1s 2ms/step
[[./.ob-jupyter/fe04fe2ae67564b9049637092b152f6441589841.png]]
[[./.ob-jupyter/5ca80627ecdcc3cb8cf64a4895ce026b1c7c6f22.png]]
:END:

**** leaky_relu
#+begin_src jupyter-python :kernel iotvar_powerprofiler :results silent
import optuna

def pinball_loss(tau):
    def loss(y_true, y_pred):
        err = y_true - y_pred
        return K.mean(K.maximum(tau * err, (tau - 1) * err), axis=-1)
    return loss

# Define X and y based on the given structure
X = np.zeros([len(m_b_df['number_sensors']), 2])
X[:, 0] = np.array(m_b_df['refresh_period'])
X[:, 1] = np.array(m_b_df['number_sensors'])

y = np.array(m_b_df['m']).reshape(-1, 1)  # Reshape y to be a column vector

# Normalize inputs and outputs
scaler_X = StandardScaler()
scaler_y = StandardScaler()

X = scaler_X.fit_transform(X)
y = scaler_y.fit_transform(y)

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)

# Define quantiles
quantiles = [0.05, 0.5, 0.95]

# Define the objective function for Optuna
def objective(trial):
    n_units_1 = trial.suggest_int('n_units_1', 4, 128)
    n_units_2 = trial.suggest_int('n_units_2', 4, 128)
    learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-1)
    batch_size = trial.suggest_int('batch_size', 8, 128)

    # Define the model
    inputs = Input(shape=(2,))
    x = Dense(n_units_1, activation='leaky_relu')(inputs)
    x = Dense(n_units_2, activation='leaky_relu')(x)

    # Output layers for each quantile
    outputs = [Dense(1, name=f"quantile_{int(q*100)}")(x) for q in quantiles]

    # Create the model
    model = Model(inputs=inputs, outputs=outputs)

    # Compile the model with the pinball loss for each quantile
    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate),
                  loss=[pinball_loss(q) for q in quantiles])

    # Train the model
    history = model.fit(X_train, y_train, batch_size=batch_size, epochs=50, verbose=0, validation_split=0.2)

    # Evaluate the model
    val_loss = np.mean(history.history['val_loss'])
    return val_loss

# Create an Optuna study and optimize the objective function
study = optuna.create_study(direction='minimize')
study.optimize(objective, n_trials=50)

# Train the model with the best hyperparameters
best_params = study.best_params
n_units_1 = best_params['n_units_1']
n_units_2 = best_params['n_units_2']
learning_rate = best_params['learning_rate']
batch_size = best_params['batch_size']

inputs = Input(shape=(2,))
x = Dense(n_units_1, activation='leaky_relu')(inputs)
x = Dense(n_units_2, activation='leaky_relu')(x)
outputs = [Dense(1, name=f"quantile_{int(q*100)}")(x) for q in quantiles]
model = Model(inputs=inputs, outputs=outputs)
model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate),
              loss=[pinball_loss(q) for q in quantiles])

history = model.fit(X_train, y_train, batch_size=batch_size, epochs=200, verbose=1)
#+end_src

#+begin_src jupyter-python :kernel iotvar_powerprofiler
plt.figure(figsize=(12, 6))
plt.plot(history.history['loss'], label='Total Loss')
plt.plot(history.history['quantile_5_loss'], label='Quantile 5th Loss')
plt.plot(history.history['quantile_50_loss'], label='Quantile 50th Loss')
plt.plot(history.history['quantile_95_loss'], label='Quantile 95th Loss')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.title('Loss Function Evolution Over Epochs')
plt.legend()
plt.grid(True)
plt.show()
#+end_src

#+RESULTS:
[[./.ob-jupyter/474c4e597f4aada4565833a0330685b99358a000.png]]


#+begin_src jupyter-python :kernel iotvar_powerprofiler
predictions = model.predict(X_test)
print('Best hyperparameters: ', study.best_params)
# Inverse transform predictions to the original scale
predictions = [scaler_y.inverse_transform(pred) for pred in predictions]
y_test_inv = scaler_y.inverse_transform(y_test)

# Plotting predictions vs actual values for the test set
plt.figure(figsize=(12, 6))
plt.scatter(scaler_X.inverse_transform(X_test)[:, 0], y_test_inv, alpha=0.3, label='Actual Data')
for i, prediction in enumerate(predictions):
    plt.scatter(scaler_X.inverse_transform(X_test)[:, 0], prediction, alpha=0.3, label=f'{int(quantiles[i]*100)}th Quantile')

plt.legend()
plt.xlabel('Refresh Period')
plt.ylabel('m')
plt.title('Quantile Regression Predictions vs Actual Values')
plt.show()

plt.figure(figsize=(12, 6))
plt.scatter(scaler_X.inverse_transform(X_test)[:, 1], y_test_inv, alpha=0.3, label='Actual Data')
for i, prediction in enumerate(predictions):
    plt.scatter(scaler_X.inverse_transform(X_test)[:, 1], prediction, alpha=0.3, label=f'{int(quantiles[i]*100)}th Quantile')

plt.legend()
plt.xlabel('Number of Sensors')
plt.ylabel('m')
plt.title('Quantile Regression Predictions vs Actual Values')
plt.show()
#+end_src

#+RESULTS:
:RESULTS:
: 1/8 [==>...........................] - ETA: 2s8/8 [==============================] - 0s 2ms/step
: Best hyperparameters:  {'n_units_1': 27, 'n_units_2': 69, 'learning_rate': 0.011379105781918687, 'batch_size': 25}
[[./.ob-jupyter/d6b7e1a011d65dc17183441639530525fc928b56.png]]
[[./.ob-jupyter/890dd1784dd41a0c0cd53cfd5d55c25301f6621e.png]]
:END:
#+begin_src jupyter-python :kernel iotvar_powerprofiler
refresh_periods = np.arange(1,61)
number_sensors = np.arange(1, 201)
grid_refresh_periods, grid_number_sensors = np.meshgrid(refresh_periods, number_sensors)
xx = np.c_[grid_refresh_periods.ravel(), grid_number_sensors.ravel()]

#print(xx)
xx = scaler_X.transform(xx)
predictions = model.predict(xx)

predictions = [scaler_y.inverse_transform(pred) for pred in predictions]
y_test_inv = scaler_y.inverse_transform(y_test)

#print(xx)

plt.figure(figsize=(10, 10))
plt.plot(scaler_X.inverse_transform(X_test)[:,0], y_test_inv,'x', label='Actual Data')
for i, prediction in enumerate(predictions):
    if(i==1):
        plt.plot(scaler_X.inverse_transform(xx)[:,0], prediction,'k.', label=f'{int(quantiles[i]*100)}th Quantile')
    else:
        plt.plot(scaler_X.inverse_transform(xx)[:,0], prediction,'r.', label=f'{int(quantiles[i]*100)}th Quantile')

plt.legend()
plt.xlabel('Refresh Period')
plt.ylabel('m')
plt.title('Quantile Regression Predictions vs Actual Values')
plt.grid()
plt.show()

plt.figure(figsize=(10, 10))
plt.plot(scaler_X.inverse_transform(X_test)[:, 1], y_test_inv,'x', label='Actual Data')
for i, prediction in enumerate(predictions):
    if(i==1):
        plt.plot(scaler_X.inverse_transform(xx)[:,1], prediction,'.', label=f'{int(quantiles[i]*100)}th Quantile')
    else:
        plt.plot(scaler_X.inverse_transform(xx)[:,1], prediction,'.', label=f'{int(quantiles[i]*100)}th Quantile')
plt.legend()
plt.xlabel('Number of Sensors')
plt.ylabel('m')
plt.title('Quantile Regression Predictions vs Actual Values')
plt.grid()
plt.show()
#+end_src

#+RESULTS:
:RESULTS:
:   1/375 [..............................] - ETA: 5s 36/375 [=>............................] - ETA: 0s 72/375 [====>.........................] - ETA: 0s105/375 [=======>......................] - ETA: 0s139/375 [==========>...................] - ETA: 0s171/375 [============>.................] - ETA: 0s201/375 [===============>..............] - ETA: 0s231/375 [=================>............] - ETA: 0s263/375 [====================>.........] - ETA: 0s294/375 [======================>.......] - ETA: 0s329/375 [=========================>....] - ETA: 0s365/375 [============================>.] - ETA: 0s375/375 [==============================] - 1s 2ms/step
[[./.ob-jupyter/c6632c0cb231715f1fb0e821cd10e224ca06deaa.png]]
[[./.ob-jupyter/a7b19002a1e54778d063b25b6b8ab500b2bf1863.png]]
:END:

*** Benchmarking neural networks
With relu, softplus and tanh we got similar distributions, now let's compare them.
**** relu
#+begin_src jupyter-python :kernel iotvar_powerprofiler :results silent
def pinball_loss(tau):
    def loss(y_true, y_pred):
        err = y_true - y_pred
        return K.mean(K.maximum(tau * err, (tau - 1) * err), axis=-1)
    return loss

X = np.zeros([len(m_b_df['number_sensors']), 2])
X[:, 0] = np.array(m_b_df['refresh_period'])
X[:, 1] = np.array(m_b_df['number_sensors'])

y = np.array(m_b_df['m']).reshape(-1, 1)  # Reshape y to be a column vector

scaler_X = StandardScaler()
scaler_y = StandardScaler()

X = scaler_X.fit_transform(X)
y = scaler_y.fit_transform(y)

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=33)

# Define quantiles
quantiles = [0.05, 0.5, 0.95]

inputs = Input(shape=(2,))
x = Dense(117, activation='relu')(inputs)
x = Dense(125, activation='relu')(x)
outputs = [Dense(1, name=f"quantile_{int(q*100)}")(x) for q in quantiles]
model = Model(inputs=inputs, outputs=outputs)
model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.012652756967768256),
              loss=[pinball_loss(q) for q in quantiles])

history = model.fit(X_train, y_train, batch_size=62, epochs=200, verbose=1)
#+end_src

#+begin_src jupyter-python :kernel iotvar_powerprofiler
plt.figure(figsize=(12, 6))
plt.plot(history.history['loss'], label='Total Loss')
plt.plot(history.history['quantile_5_loss'], label='Quantile 5th Loss')
plt.plot(history.history['quantile_50_loss'], label='Quantile 50th Loss')
plt.plot(history.history['quantile_95_loss'], label='Quantile 95th Loss')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.title('Loss Function Evolution Over Epochs')
plt.legend()
plt.grid(True)
plt.show()
#+end_src

#+RESULTS:
[[./.ob-jupyter/85316742c6263b5a426d4d19b767bc115bb8eb13.png]]

***** Metrics
#+begin_src jupyter-python :kernel iotvar_powerprofiler
y_pred = model.predict(X_test)
y_pred_5th, y_pred_50th, y_pred_95th = y_pred

# Inverse transform the predictions and the test set true values
y_test_inv = scaler_y.inverse_transform(y_test)
y_pred_5th_inv = scaler_y.inverse_transform(y_pred_5th)
y_pred_50th_inv = scaler_y.inverse_transform(y_pred_50th)
y_pred_95th_inv = scaler_y.inverse_transform(y_pred_95th)

# Calculate coverage probability
coverage_90 = np.mean((y_test_inv >= y_pred_5th_inv) & (y_test_inv <= y_pred_95th_inv))
print(f'90% Coverage Probability: {coverage_90:.2%}')

# Define the pinball loss function for evaluation
def pinball_loss(y_true, y_pred, quantile):
    return np.mean([max(quantile * (y - y_hat), (quantile - 1) * (y_hat - y)) for y, y_hat in zip(y_true, y_pred)])

# Calculate pinball loss for each quantile
pinball_loss_5th = pinball_loss(y_test_inv, y_pred_5th_inv, 0.05)
pinball_loss_50th = pinball_loss(y_test_inv, y_pred_50th_inv, 0.50)
pinball_loss_95th = pinball_loss(y_test_inv, y_pred_95th_inv, 0.95)

avg_pinball_loss = (pinball_loss_5th + pinball_loss_50th + pinball_loss_95th) / 3
print(f'Average Pinball Loss: {avg_pinball_loss:.4f}')

# Calculate mean interval width
mean_interval_width = np.mean(y_pred_95th_inv - y_pred_5th_inv)
print(f'Mean Interval Width: {mean_interval_width:.4f}')
#+end_src

#+RESULTS:
: 1/8 [==>...........................] - ETA: 0s8/8 [==============================] - 0s 2ms/step
: 90% Coverage Probability: 90.76%
: Average Pinball Loss: 0.0117
: Mean Interval Width: 0.0857

#+begin_src jupyter-python :kernel iotvar_powerprofiler
# Function to plot QQ plot for a quantile
def qq_plot(y_true, y_pred, quantile):
    plt.figure()
    plt.scatter(y_true, y_pred, alpha=0.5)
    plt.plot([min(y_true), max(y_true)], [min(y_true), max(y_true)], 'r--')
    plt.xlabel('Observed')
    plt.ylabel('Predicted')
    plt.title(f'QQ Plot for {quantile * 100}th Quantile')
    plt.show()

# QQ plots for each quantile
qq_plot(y_test_inv, y_pred_5th_inv, 0.05)
qq_plot(y_test_inv, y_pred_50th_inv, 0.50)
qq_plot(y_test_inv, y_pred_95th_inv, 0.95)
#+end_src

#+RESULTS:
:RESULTS:
#+attr_org: :width 740
[[./.ob-jupyter/5d956b038d87e84d3bee6b467fa14339d04bae15.png]]
#+attr_org: :width 740
[[./.ob-jupyter/b455e318088e216623faef5ee30dd576b58f3d48.png]]
#+attr_org: :width 740
[[./.ob-jupyter/5512551fbf6a39f69cb534673461e62fc1c7b96e.png]]
:END:
***** Data distribution generated by the model
#+begin_src jupyter-python :kernel iotvar_powerprofiler
input_distribution = np.unique(scaler_X.inverse_transform(X_test),axis = 0)
y_pred = model.predict(scaler_X.transform(input_distribution))
y_pred_5th, y_pred_50th, y_pred_95th = y_pred

# Inverse transform the predictions and the test set true values
y_test_inv = scaler_y.inverse_transform(y_test)
y_pred_5th_inv = scaler_y.inverse_transform(y_pred_5th)
y_pred_50th_inv = scaler_y.inverse_transform(y_pred_50th)
y_pred_95th_inv = scaler_y.inverse_transform(y_pred_95th)

def generate_uniform_samples(y_pred_5th_inv, y_pred_95th_inv, num_samples):
    samples = np.random.uniform(y_pred_5th_inv, y_pred_95th_inv, num_samples)
    return samples

num_samples = 100  # Number of samples to generate per input
all_samples_uniform = []

for i in range(len(input_distribution)):
    samples = generate_uniform_samples(y_pred_5th_inv[i], y_pred_95th_inv[i], num_samples)
    all_samples_uniform.append(samples)

print(len(all_samples_uniform))
print(len(input_distribution))
m_b_df_test = pl.DataFrame({
    "refresh_period": np.ceil(input_distribution[:,0]).astype(int),
    "number_sensors": np.ceil(input_distribution[:,1]).astype(int),
    "m":all_samples_uniform
})

m_b_df_test.write_ndjson('./coeffis.json')
m_b_df_test
#+end_src

#+RESULTS:
:RESULTS:
: 1/2 [==============>...............] - ETA: 0s2/2 [==============================] - 0s 3ms/step
: 52
: 52
#+begin_example
shape: (52, 3)
┌────────────────┬────────────────┬─────────────────────────────────┐
│ refresh_period ┆ number_sensors ┆ m                               │
│ ---            ┆ ---            ┆ ---                             │
│ i64            ┆ i64            ┆ list[f64]                       │
╞════════════════╪════════════════╪═════════════════════════════════╡
│ 1              ┆ 25             ┆ [2.655644, 2.645416, … 2.69873… │
│ 1              ┆ 50             ┆ [2.692635, 2.668125, … 2.69874… │
│ 1              ┆ 75             ┆ [2.711206, 2.722822, … 2.71330… │
│ 1              ┆ 100            ┆ [2.652329, 2.652462, … 2.66299… │
│ 1              ┆ 125            ┆ [2.677514, 2.632162, … 2.68300… │
│ …              ┆ …              ┆ …                               │
│ 60             ┆ 100            ┆ [2.209271, 2.250958, … 2.22035… │
│ 60             ┆ 125            ┆ [2.210119, 2.230251, … 2.26129… │
│ 60             ┆ 150            ┆ [2.213769, 2.239228, … 2.20297… │
│ 60             ┆ 175            ┆ [2.266788, 2.216992, … 2.23041… │
│ 60             ┆ 200            ┆ [2.209918, 2.216803, … 2.25489… │
└────────────────┴────────────────┴─────────────────────────────────┘
#+end_example
:END:

#+begin_src jupyter-python :kernel iotvar_powerprofiler
#out = m_b_df_test.explode("m")
#out
plt.figure(figsize=(16, 6))
sns.kdeplot(data=m_b_df_test.explode("m"), x='number_sensors', y='m', hue='refresh_period', fill=True, common_norm=False, palette='muted')
plt.title('Density Plot of Slope (m) for different Refresh Periods and Number of Sensors')
plt.xlabel('Number of Sensors')
plt.ylabel('Slope (m)')
plt.show()
#+end_src

#+RESULTS:
[[./.ob-jupyter/e85807329680182763c1704fe3b8e2bfed9637e5.png]]

**** leaky relu
#+begin_src jupyter-python :kernel iotvar_powerprofiler :results silent
def pinball_loss(tau):
    def loss(y_true, y_pred):
        err = y_true - y_pred
        return K.mean(K.maximum(tau * err, (tau - 1) * err), axis=-1)
    return loss

X = np.zeros([len(m_b_df['number_sensors']), 2])
X[:, 0] = np.array(m_b_df['refresh_period'])
X[:, 1] = np.array(m_b_df['number_sensors'])

y = np.array(m_b_df['m']).reshape(-1, 1)  # Reshape y to be a column vector

scaler_X = StandardScaler()
scaler_y = StandardScaler()

X = scaler_X.fit_transform(X)
y = scaler_y.fit_transform(y)

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=33)

# Define quantiles
quantiles = [0.05, 0.5, 0.95]

inputs = Input(shape=(2,))
x = Dense(94, activation='leaky_relu')(inputs)
x = Dense(71, activation='leaky_relu')(x)
outputs = [Dense(1, name=f"quantile_{int(q*100)}")(x) for q in quantiles]
model = Model(inputs=inputs, outputs=outputs)
model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.017288929949619898),
              loss=[pinball_loss(q) for q in quantiles])

history = model.fit(X_train, y_train, batch_size=48, epochs=200, verbose=1)
#+end_src

#+begin_src jupyter-python :kernel iotvar_powerprofiler
plt.figure(figsize=(12, 6))
plt.plot(history.history['loss'], label='Total Loss')
plt.plot(history.history['quantile_5_loss'], label='Quantile 5th Loss')
plt.plot(history.history['quantile_50_loss'], label='Quantile 50th Loss')
plt.plot(history.history['quantile_95_loss'], label='Quantile 95th Loss')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.title('Loss Function Evolution Over Epochs')
plt.legend()
plt.grid(True)
plt.show()
#+end_src

#+RESULTS:
[[./.ob-jupyter/67ec48921c4f7519f746abd958e3bc6cb05e6e01.png]]

***** Metrics
#+begin_src jupyter-python :kernel iotvar_powerprofiler
y_pred = model.predict(X_test)
y_pred_5th, y_pred_50th, y_pred_95th = y_pred

# Inverse transform the predictions and the test set true values
y_test_inv = scaler_y.inverse_transform(y_test)
y_pred_5th_inv = scaler_y.inverse_transform(y_pred_5th)
y_pred_50th_inv = scaler_y.inverse_transform(y_pred_50th)
y_pred_95th_inv = scaler_y.inverse_transform(y_pred_95th)

# Calculate coverage probability
coverage_90 = np.mean((y_test_inv >= y_pred_5th_inv) & (y_test_inv <= y_pred_95th_inv))
print(f'90% Coverage Probability: {coverage_90:.2%}')

# Define the pinball loss function for evaluation
def pinball_loss(y_true, y_pred, quantile):
    return np.mean([max(quantile * (y - y_hat), (quantile - 1) * (y_hat - y)) for y, y_hat in zip(y_true, y_pred)])

# Calculate pinball loss for each quantile
pinball_loss_5th = pinball_loss(y_test_inv, y_pred_5th_inv, 0.05)
pinball_loss_50th = pinball_loss(y_test_inv, y_pred_50th_inv, 0.50)
pinball_loss_95th = pinball_loss(y_test_inv, y_pred_95th_inv, 0.95)

avg_pinball_loss = (pinball_loss_5th + pinball_loss_50th + pinball_loss_95th) / 3
print(f'Average Pinball Loss: {avg_pinball_loss:.4f}')

# Calculate mean interval width
mean_interval_width = np.mean(y_pred_95th_inv - y_pred_5th_inv)
print(f'Mean Interval Width: {mean_interval_width:.4f}')
#+end_src

#+RESULTS:
: 1/8 [==>...........................] - ETA: 0s8/8 [==============================] - 0s 2ms/step
: 90% Coverage Probability: 97.19%
: Average Pinball Loss: 0.0136
: Mean Interval Width: 0.0979

#+begin_src jupyter-python :kernel iotvar_powerprofiler
# Function to plot QQ plot for a quantile
def qq_plot(y_true, y_pred, quantile):
    plt.figure()
    plt.scatter(y_true, y_pred, alpha=0.5)
    plt.plot([min(y_true), max(y_true)], [min(y_true), max(y_true)], 'r--')
    plt.xlabel('Observed')
    plt.ylabel('Predicted')
    plt.title(f'QQ Plot for {quantile * 100}th Quantile')
    plt.show()

# QQ plots for each quantile
qq_plot(y_test_inv, y_pred_5th_inv, 0.05)
qq_plot(y_test_inv, y_pred_50th_inv, 0.50)
qq_plot(y_test_inv, y_pred_95th_inv, 0.95)
#+end_src

#+RESULTS:
:RESULTS:
#+attr_org: :width 740
[[./.ob-jupyter/cfbd7314aaf7f47d6ed9f0b8debaddc485cacc65.png]]
#+attr_org: :width 740
[[./.ob-jupyter/c30db07045e578b7bcf340ffea8eb09661362d61.png]]
#+attr_org: :width 740
[[./.ob-jupyter/c386dddc9e4e3ffcba7b94d47e766cf8506a2345.png]]
:END:

**** softplus

#+begin_src jupyter-python :kernel iotvar_powerprofiler :results silent
def pinball_loss(tau):
    def loss(y_true, y_pred):
        err = y_true - y_pred
        return K.mean(K.maximum(tau * err, (tau - 1) * err), axis=-1)
    return loss

X = np.zeros([len(m_b_df['number_sensors']), 2])
X[:, 0] = np.array(m_b_df['refresh_period'])
X[:, 1] = np.array(m_b_df['number_sensors'])

y = np.array(m_b_df['m']).reshape(-1, 1)  # Reshape y to be a column vector

scaler_X = StandardScaler()
scaler_y = StandardScaler()

X = scaler_X.fit_transform(X)
y = scaler_y.fit_transform(y)

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=33)

# Define quantiles
quantiles = [0.05, 0.5, 0.95]

inputs = Input(shape=(2,))
x = Dense(11, activation='softplus')(inputs)
x = Dense(21, activation='softplus')(x)
outputs = [Dense(1, name=f"quantile_{int(q*100)}")(x) for q in quantiles]
model = Model(inputs=inputs, outputs=outputs)
model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.025336987668335666),
              loss=[pinball_loss(q) for q in quantiles])

history = model.fit(X_train, y_train, batch_size=14, epochs=200, verbose=1)
#+end_src

#+begin_src jupyter-python :kernel iotvar_powerprofiler
plt.figure(figsize=(12, 6))
plt.plot(history.history['loss'], label='Total Loss')
plt.plot(history.history['quantile_5_loss'], label='Quantile 5th Loss')
plt.plot(history.history['quantile_50_loss'], label='Quantile 50th Loss')
plt.plot(history.history['quantile_95_loss'], label='Quantile 95th Loss')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.title('Loss Function Evolution Over Epochs softplus')
plt.legend()
plt.grid(True)
plt.show()
#+end_src

***** Metrics
#+begin_src jupyter-python :kernel iotvar_powerprofiler
y_pred = model.predict(X_test)
y_pred_5th, y_pred_50th, y_pred_95th = y_pred

# Inverse transform the predictions and the test set true values
y_test_inv = scaler_y.inverse_transform(y_test)
y_pred_5th_inv = scaler_y.inverse_transform(y_pred_5th)
y_pred_50th_inv = scaler_y.inverse_transform(y_pred_50th)
y_pred_95th_inv = scaler_y.inverse_transform(y_pred_95th)

# Calculate coverage probability
coverage_90 = np.mean((y_test_inv >= y_pred_5th_inv) & (y_test_inv <= y_pred_95th_inv))
print(f'90% Coverage Probability: {coverage_90:.2%}')

# Define the pinball loss function for evaluation
def pinball_loss(y_true, y_pred, quantile):
    return np.mean([max(quantile * (y - y_hat), (quantile - 1) * (y_hat - y)) for y, y_hat in zip(y_true, y_pred)])

# Calculate pinball loss for each quantile
pinball_loss_5th = pinball_loss(y_test_inv, y_pred_5th_inv, 0.05)
pinball_loss_50th = pinball_loss(y_test_inv, y_pred_50th_inv, 0.50)
pinball_loss_95th = pinball_loss(y_test_inv, y_pred_95th_inv, 0.95)

avg_pinball_loss = (pinball_loss_5th + pinball_loss_50th + pinball_loss_95th) / 3
print(f'Average Pinball Loss: {avg_pinball_loss:.4f}')

# Calculate mean interval width
mean_interval_width = np.mean(y_pred_95th_inv - y_pred_5th_inv)
print(f'Mean Interval Width: {mean_interval_width:.4f}')
#+end_src

#+RESULTS:
: 1/8 [==>...........................] - ETA: 0s8/8 [==============================] - 0s 2ms/step
: 90% Coverage Probability: 92.37%
: Average Pinball Loss: 0.0117
: Mean Interval Width: 0.0793

#+begin_src jupyter-python :kernel iotvar_powerprofiler
# Function to plot QQ plot for a quantile
def qq_plot(y_true, y_pred, quantile):
    plt.figure()
    plt.scatter(y_true, y_pred, alpha=0.5)
    plt.plot([min(y_true), max(y_true)], [min(y_true), max(y_true)], 'r--')
    plt.xlabel('Observed')
    plt.ylabel('Predicted')
    plt.title(f'QQ Plot for {quantile * 100}th Quantile')
    plt.show()

# QQ plots for each quantile
qq_plot(y_test_inv, y_pred_5th_inv, 0.05)
qq_plot(y_test_inv, y_pred_50th_inv, 0.50)
qq_plot(y_test_inv, y_pred_95th_inv, 0.95)
#+end_src

#+RESULTS:
:RESULTS:
#+attr_org: :width 740
[[./.ob-jupyter/b576806a3514d492ade87fca09edabb71001c1ae.png]]
#+attr_org: :width 740
[[./.ob-jupyter/2674f0fb6620bf0d88269a1e27259a095e136481.png]]
#+attr_org: :width 740
[[./.ob-jupyter/4ed92924450cb28e94e26f5a5229f73232df42c2.png]]
:END:

**** tanh
#+begin_src jupyter-python :kernel iotvar_powerprofiler :results silent
def pinball_loss(tau):
    def loss(y_true, y_pred):
        err = y_true - y_pred
        return K.mean(K.maximum(tau * err, (tau - 1) * err), axis=-1)
    return loss

X = np.zeros([len(m_b_df['number_sensors']), 2])
X[:, 0] = np.array(m_b_df['refresh_period'])
X[:, 1] = np.array(m_b_df['number_sensors'])

y = np.array(m_b_df['m']).reshape(-1, 1)  # Reshape y to be a column vector

scaler_X = StandardScaler()
scaler_y = StandardScaler()

X = scaler_X.fit_transform(X)
y = scaler_y.fit_transform(y)

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=33)

# Define quantiles
quantiles = [0.05, 0.5, 0.95]

inputs = Input(shape=(2,))
x = Dense(128, activation='tanh')(inputs)
x = Dense(11, activation='tanh')(x)
outputs = [Dense(1, name=f"quantile_{int(q*100)}")(x) for q in quantiles]
model = Model(inputs=inputs, outputs=outputs)
model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.016034548220092763),
              loss=[pinball_loss(q) for q in quantiles])

history = model.fit(X_train, y_train, batch_size=53, epochs=200, verbose=1)
#+end_src

#+begin_src jupyter-python :kernel iotvar_powerprofiler
plt.figure(figsize=(12, 6))
plt.plot(history.history['loss'], label='Total Loss')
plt.plot(history.history['quantile_5_loss'], label='Quantile 5th Loss')
plt.plot(history.history['quantile_50_loss'], label='Quantile 50th Loss')
plt.plot(history.history['quantile_95_loss'], label='Quantile 95th Loss')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.title('Loss Function Evolution Over Epochs tanh')
plt.legend()
plt.grid(True)
plt.show()
#+end_src

#+RESULTS:
[[./.ob-jupyter/57deb9a20136db7f655806148f2cf1041a9c895e.png]]

***** Metrics
#+begin_src jupyter-python :kernel iotvar_powerprofiler
y_pred = model.predict(X_test)
y_pred_5th, y_pred_50th, y_pred_95th = y_pred

# Inverse transform the predictions and the test set true values
y_test_inv = scaler_y.inverse_transform(y_test)
y_pred_5th_inv = scaler_y.inverse_transform(y_pred_5th)
y_pred_50th_inv = scaler_y.inverse_transform(y_pred_50th)
y_pred_95th_inv = scaler_y.inverse_transform(y_pred_95th)

# Calculate coverage probability
coverage_90 = np.mean((y_test_inv >= y_pred_5th_inv) & (y_test_inv <= y_pred_95th_inv))
print(f'90% Coverage Probability: {coverage_90:.2%}')

# Define the pinball loss function for evaluation
def pinball_loss(y_true, y_pred, quantile):
    return np.mean([max(quantile * (y - y_hat), (quantile - 1) * (y_hat - y)) for y, y_hat in zip(y_true, y_pred)])

# Calculate pinball loss for each quantile
pinball_loss_5th = pinball_loss(y_test_inv, y_pred_5th_inv, 0.05)
pinball_loss_50th = pinball_loss(y_test_inv, y_pred_50th_inv, 0.50)
pinball_loss_95th = pinball_loss(y_test_inv, y_pred_95th_inv, 0.95)

avg_pinball_loss = (pinball_loss_5th + pinball_loss_50th + pinball_loss_95th) / 3
print(f'Average Pinball Loss: {avg_pinball_loss:.4f}')

# Calculate mean interval width
mean_interval_width = np.mean(y_pred_95th_inv - y_pred_5th_inv)
print(f'Mean Interval Width: {mean_interval_width:.4f}')
#+end_src

#+RESULTS:
: 1/8 [==>...........................] - ETA: 0s8/8 [==============================] - 0s 2ms/step
: 90% Coverage Probability: 90.76%
: Average Pinball Loss: 0.0097
: Mean Interval Width: 0.0767

#+begin_src jupyter-python :kernel iotvar_powerprofiler
# Function to plot QQ plot for a quantile
def qq_plot(y_true, y_pred, quantile):
    plt.figure()
    plt.scatter(y_true, y_pred, alpha=0.5)
    plt.plot([min(y_true), max(y_true)], [min(y_true), max(y_true)], 'r--')
    plt.xlabel('Observed')
    plt.ylabel('Predicted')
    plt.title(f'QQ Plot for {quantile * 100}th Quantile')
    plt.show()

# QQ plots for each quantile
qq_plot(y_test_inv, y_pred_5th_inv, 0.05)
qq_plot(y_test_inv, y_pred_50th_inv, 0.50)
qq_plot(y_test_inv, y_pred_95th_inv, 0.95)
#+end_src

#+RESULTS:
:RESULTS:
#+attr_org: :width 570
[[./.ob-jupyter/a667673b2530e412ee77b56be7d5660768801e70.png]] | [[./.ob-jupyter/187085e1fcb3c6bbc4a6c13cb929d8c0b2368f3f.png]] | [[./.ob-jupyter/81e28f00e74e249aaaf070a8b0316e26f353b81e.png]]
:END:

*** Adding more layers

#+begin_src jupyter-python :kernel iotvar_powerprofiler :results silent
import optuna

# Define the pinball loss function
def pinball_loss(tau):
    def loss(y_true, y_pred):
        err = y_true - y_pred
        return K.mean(K.maximum(tau * err, (tau - 1) * err), axis=-1)
    return loss

# Define X and y based on the given structure
X = np.zeros([len(m_b_df['number_sensors']), 2])
X[:, 0] = np.array(m_b_df['refresh_period'])
X[:, 1] = np.array(m_b_df['number_sensors'])

y = np.array(m_b_df['m']).reshape(-1, 1)  # Reshape y to be a column vector

# Normalize inputs and outputs
scaler_X = StandardScaler()
scaler_y = StandardScaler()

X = scaler_X.fit_transform(X)
y = scaler_y.fit_transform(y)

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)

# Define quantiles
quantiles = [0.05, 0.5, 0.95]

# Define the objective function for Optuna
def objective(trial):
    n_units_1 = trial.suggest_int('n_units_1', 4, 128)
    n_units_2 = trial.suggest_int('n_units_2', 4, 128)
    n_units_3 = trial.suggest_int('n_units_3', 4, 128)
    #n_units_4 = trial.suggest_int('n_units_4', 4, 128)
    #n_units_5 = trial.suggest_int('n_units_5', 4, 128)
    #n_units_6 = trial.suggest_int('n_units_6', 4, 128)
    #n_units_7 = trial.suggest_int('n_units_7', 4, 128)
    learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-1)
    batch_size = trial.suggest_int('batch_size', 8, 128)

    # Define the model
    inputs = Input(shape=(2,))
    x = Dense(n_units_1, activation='selu')(inputs)
    x = Dense(n_units_2, activation='selu')(x)
    x = Dense(n_units_3, activation='selu')(x)
    #x = Dense(n_units_4, activation='selu')(x)
    #x = Dense(n_units_5, activation='selu')(x)
    #x = Dense(n_units_6, activation='selu')(x)
    #x = Dense(n_units_7, activation='selu')(x)

    # Output layers for each quantile
    outputs = [Dense(1, name=f"quantile_{int(q*100)}")(x) for q in quantiles]

    # Create the model
    model = Model(inputs=inputs, outputs=outputs)

    # Compile the model with the pinball loss for each quantile
    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate),
                  loss=[pinball_loss(q) for q in quantiles])

    # Train the model
    history = model.fit(X_train, y_train, batch_size=batch_size, epochs=50, verbose=0, validation_split=0.2)

    # Evaluate the model
    val_loss = np.mean(history.history['val_loss'])
    return val_loss

# Create an Optuna study and optimize the objective function
study = optuna.create_study(direction='minimize')
study.optimize(objective, n_trials=50)

# Train the model with the best hyperparameters
best_params = study.best_params
n_units_1 = best_params['n_units_1']
n_units_2 = best_params['n_units_2']
n_units_3 = best_params['n_units_3']
#n_units_4 = best_params['n_units_4']
#n_units_5 = best_params['n_units_5']
#n_units_6 = best_params['n_units_6']
#n_units_7 = best_params['n_units_7']

learning_rate = best_params['learning_rate']
batch_size = best_params['batch_size']

inputs = Input(shape=(2,))
x = Dense(n_units_1, activation='selu')(inputs)
x = Dense(n_units_2, activation='selu')(x)
x = Dense(n_units_3, activation='selu')(x)
#x = Dense(n_units_4, activation='selu')(x)
#x = Dense(n_units_5, activation='selu')(x)
#x = Dense(n_units_6, activation='selu')(x)
#x = Dense(n_units_7, activation='selu')(x)

outputs = [Dense(1, name=f"quantile_{int(q*100)}")(x) for q in quantiles]
model = Model(inputs=inputs, outputs=outputs)
model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate),
              loss=[pinball_loss(q) for q in quantiles])

history = model.fit(X_train, y_train, batch_size=batch_size, epochs=200, verbose=1)
#+end_src

#+begin_src jupyter-python :kernel iotvar_powerprofiler
plt.figure(figsize=(12, 6))
plt.plot(history.history['loss'], label='Total Loss')
plt.plot(history.history['quantile_5_loss'], label='Quantile 5th Loss')
plt.plot(history.history['quantile_50_loss'], label='Quantile 50th Loss')
plt.plot(history.history['quantile_95_loss'], label='Quantile 95th Loss')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.title('Loss Function Evolution Over Epochs')
plt.legend()
plt.grid(True)
plt.show()
#+end_src

#+RESULTS:
[[./.ob-jupyter/7918bf83c5f763bc2ba52550381a722a65411030.png]]



#+begin_src jupyter-python :kernel iotvar_powerprofiler
predictions = model.predict(X_test)
print('Best hyperparameters: ', study.best_params)
# Inverse transform predictions to the original scale
predictions = [scaler_y.inverse_transform(pred) for pred in predictions]
y_test_inv = scaler_y.inverse_transform(y_test)

# Plotting predictions vs actual values for the test set
plt.figure(figsize=(12, 6))
plt.scatter(scaler_X.inverse_transform(X_test)[:, 0], y_test_inv, alpha=0.3, label='Actual Data')
for i, prediction in enumerate(predictions):
    plt.scatter(scaler_X.inverse_transform(X_test)[:, 0], prediction, alpha=0.3, label=f'{int(quantiles[i]*100)}th Quantile')

plt.legend()
plt.xlabel('Refresh Period')
plt.ylabel('m')
plt.title('Quantile Regression Predictions vs Actual Values')
plt.show()

plt.figure(figsize=(12, 6))
plt.scatter(scaler_X.inverse_transform(X_test)[:, 1], y_test_inv, alpha=0.3, label='Actual Data')
for i, prediction in enumerate(predictions):
    plt.scatter(scaler_X.inverse_transform(X_test)[:, 1], prediction, alpha=0.3, label=f'{int(quantiles[i]*100)}th Quantile')

plt.legend()
plt.xlabel('Number of Sensors')
plt.ylabel('m')
plt.title('Quantile Regression Predictions vs Actual Values')
plt.show()
#+end_src

#+RESULTS:
:RESULTS:
: 1/7 [===>..........................] - ETA: 0s7/7 [==============================] - 0s 2ms/step
: Best hyperparameters:  {'n_units_1': 118, 'n_units_2': 107, 'n_units_3': 17, 'learning_rate': 0.011600255687932801, 'batch_size': 8}
[[./.ob-jupyter/4f7f4abf0748e3f0c3ceddbe23962787eadb1c19.png]]
[[./.ob-jupyter/d7ae6c8942ddecdcd427ecc98e9b1881b8642156.png]]
:END:

#+begin_src jupyter-python :kernel iotvar_powerprofiler
refresh_periods = np.arange(1,21)
number_sensors = np.arange(1, 201)
grid_refresh_periods, grid_number_sensors = np.meshgrid(refresh_periods, number_sensors)
xx = np.c_[grid_refresh_periods.ravel(), grid_number_sensors.ravel()]

#print(xx)
xx = scaler_X.transform(xx)
predictions = model.predict(xx)

predictions = [scaler_y.inverse_transform(pred) for pred in predictions]
y_test_inv = scaler_y.inverse_transform(y_test)

#print(xx)

plt.figure(figsize=(10, 10))
plt.plot(scaler_X.inverse_transform(X_test)[:,0], y_test_inv,'x', label='Actual Data')
for i, prediction in enumerate(predictions):
    if(i==1):
        plt.plot(scaler_X.inverse_transform(xx)[:,0], prediction,'k.', label=f'{int(quantiles[i]*100)}th Quantile')
    else:
        plt.plot(scaler_X.inverse_transform(xx)[:,0], prediction,'r.', label=f'{int(quantiles[i]*100)}th Quantile')

plt.legend()
plt.xlabel('Refresh Period')
plt.ylabel('m')
plt.title('Quantile Regression Predictions vs Actual Values')
plt.grid()
plt.show()

plt.figure(figsize=(10, 10))
plt.plot(scaler_X.inverse_transform(X_test)[:, 1], y_test_inv,'x', label='Actual Data')
for i, prediction in enumerate(predictions):
    if(i==1):
        plt.plot(scaler_X.inverse_transform(xx)[:,1], prediction,'.', label=f'{int(quantiles[i]*100)}th Quantile')
    else:
        plt.plot(scaler_X.inverse_transform(xx)[:,1], prediction,'.', label=f'{int(quantiles[i]*100)}th Quantile')
plt.legend()
plt.xlabel('Number of Sensors')
plt.ylabel('m')
plt.title('Quantile Regression Predictions vs Actual Values')
plt.grid()
plt.show()
#+end_src

#+RESULTS:
:RESULTS:
:   1/125 [..............................] - ETA: 2s 34/125 [=======>......................] - ETA: 0s 66/125 [==============>...............] - ETA: 0s 97/125 [======================>.......] - ETA: 0s125/125 [==============================] - 0s 2ms/step
[[./.ob-jupyter/bbc70ef4162326bbf416c4d2f34866c6e235a3ea.png]]
[[./.ob-jupyter/e84ebc8e18477f59811ced8162aa0b781ea887d3.png]]
:END:
* Prediction intercept b values
** K means regressor
#+begin_src jupyter-python :kernel iotvar_powerprofiler
from sklearn.cluster import KMeans
from sklearn.neighbors import KNeighborsRegressor
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error

m_b_df_pd = m_b_df.to_pandas()

# Step 2: Clustering based on 'm' and 'b'
kmeans = KMeans(n_clusters=7, random_state=0)
m_b_df_pd['cluster'] = kmeans.fit_predict(m_b_df_pd[['m', 'b']])
# Plot the clusters
plt.figure(figsize=(10, 6))
scatter = plt.scatter(m_b_df_pd['m'], m_b_df_pd['b'], c=m_b_df_pd['cluster'], cmap='viridis', alpha=0.7)
plt.colorbar(scatter, label='Cluster Label')
plt.xlabel('Slope (m)')
plt.ylabel('Intercept (b)')
plt.title('Clusters based on Slope (m) and Intercept (b)')
plt.show()

# Step 3: kNN Regression within Clusters
predictions = pd.Series(0, index=m_b_df_pd.index)

for cluster in m_b_df_pd['cluster'].unique():
    cluster_data = m_b_df_pd[m_b_df_pd['cluster'] == cluster]
    X_cluster = cluster_data[['m', 'refresh_period']]
    y_cluster = cluster_data['b']

    # Split the data into training and testing sets
    X_train, X_test, y_train, y_test = train_test_split(X_cluster, y_cluster, test_size=0.2, random_state=42)

    # Initialize and train the kNN Regressor
    knn = KNeighborsRegressor(n_neighbors=5)  # You can tune the number of neighbors
    knn.fit(X_train, y_train)

    # Predict on the entire cluster data
    predictions[m_b_df_pd['cluster'] == cluster] = knn.predict(X_cluster)

# Step 4: Evaluate the Model
mse = mean_squared_error(m_b_df_pd['b'], predictions)
print(f'Mean Squared Error: {mse}')

# Optional: Plot the predicted vs actual values
plt.scatter(m_b_df_pd['b'], predictions, alpha=0.7)
plt.xlabel('Actual Intercept (b)')
plt.ylabel('Predicted Intercept (b)')
plt.title('kNN Regression: Actual vs Predicted Intercept (b)')
plt.show()
#+end_src

#+RESULTS:
:RESULTS:
[[./.ob-jupyter/4ef907758025fccbd0f492ca60a0a0f00ea823f4.png]]
: Mean Squared Error: 0.2083597988102613
#+attr_org: :width 736
[[./.ob-jupyter/eaa6b4b52c7c377e8ee8934d9fa20287e8774deb.png]]
:END:

#+begin_src jupyter-python :kernel iotvar_powerprofiler
from sklearn.preprocessing import StandardScaler

# Standardize the features
scaler = StandardScaler()
m_b_df_pd[['m', 'refresh_period']] = scaler.fit_transform(m_b_df_pd[['m', 'refresh_period']])

# Re-run the clustering and kNN regression with scaled data
kmeans = KMeans(n_clusters=3, random_state=42)
m_b_df_pd['cluster'] = kmeans.fit_predict(m_b_df_pd[['m', 'b']])

predictions = pd.Series(0, index=m_b_df_pd.index)

for cluster in m_b_df_pd['cluster'].unique():
    cluster_data = m_b_df_pd[m_b_df_pd['cluster'] == cluster]
    X_cluster = cluster_data[['m', 'refresh_period']]
    y_cluster = cluster_data['b']

    X_train, X_test, y_train, y_test = train_test_split(X_cluster, y_cluster, test_size=0.2, random_state=42)

    knn = KNeighborsRegressor(n_neighbors=5)
    knn.fit(X_train, y_train)

    predictions[m_b_df_pd['cluster'] == cluster] = knn.predict(X_cluster)

mse = mean_squared_error(m_b_df_pd['b'], predictions)
print(f'Mean Squared Error: {mse}')

plt.scatter(m_b_df_pd['b'], predictions, alpha=0.7)
plt.xlabel('Actual Intercept (b)')
plt.ylabel('Predicted Intercept (b)')
plt.title('kNN Regression: Actual vs Predicted Intercept (b)')
plt.show()
#+end_src

#+RESULTS:
:RESULTS:
: Mean Squared Error: 0.7967907541774008
#+attr_org: :width 736
[[./.ob-jupyter/c7f23e87c854c35ff6d76749cf60efc04fa71ab4.png]]
:END:
** Neural networks

#+begin_src jupyter-python :kernel iotvar_powerprofiler :results silent
import optuna
from optuna.integration import TFKerasPruningCallback
from sklearn.preprocessing import MinMaxScaler


df = m_b_df.to_pandas()

# Define predictors and target
X = df[['refresh_period', 'number_sensors', 'm']].values
y = df['b'].values

# Split the data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Scale the data
#scaler_X = StandardScaler()
#scaler_y = StandardScaler()

#X_train_scaled = scaler_X.fit_transform(X_train)
#X_test_scaled = scaler_X.transform(X_test)
#y_train_scaled = scaler_y.fit_transform(y_train.reshape(-1, 1)).flatten()
#y_test_scaled = scaler_y.transform(y_test.reshape(-1, 1)).flatten()
scaler_X = MinMaxScaler()
scaler_y = MinMaxScaler()

X_train_scaled = scaler_X.fit_transform(X_train)
X_test_scaled = scaler_X.transform(X_test)
y_train_scaled = scaler_y.fit_transform(y_train.reshape(-1, 1)).flatten()
y_test_scaled = scaler_y.transform(y_test.reshape(-1, 1)).flatten()


# Define the objective function for Optuna
def objective(trial):
    # Define hyperparameters to tune
    n_layers = trial.suggest_int('n_layers', 1, 10)
    units = trial.suggest_int('units', 2, 256)
    activation = trial.suggest_categorical('activation', ['relu', 'tanh', 'softplus','leaky_relu'])
    learning_rate = trial.suggest_float('learning_rate', 1e-4, 1e-2, log=True)

    # Build the model
    model = tf.keras.Sequential()
    model.add(tf.keras.layers.InputLayer(input_shape=(X_train_scaled.shape[1],)))

    for _ in range(n_layers):
        model.add(tf.keras.layers.Dense(units, activation=activation))

    model.add(tf.keras.layers.Dense(1))

    # Compile the model
    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate),
                  loss='kullback_leibler_divergence')

    # Train the model
    history = model.fit(X_train_scaled, y_train_scaled,
                        validation_split=0.2,
                        epochs=200,
                        callbacks=[TFKerasPruningCallback(trial, 'val_loss')],
                        verbose=0)

    # Evaluate the model
    loss = model.evaluate(X_test_scaled, y_test_scaled, verbose=0)
    return loss

# Create a study and optimize the objective function
study = optuna.create_study(direction='minimize')
study.optimize(objective, n_trials=50)

# Train the best model using the best parameters
best_params = study.best_trial.params
model = tf.keras.Sequential()
model.add(tf.keras.layers.InputLayer(input_shape=(X_train_scaled.shape[1],)))

for _ in range(best_params['n_layers']):
    model.add(tf.keras.layers.Dense(best_params['units'], activation=best_params['activation']))

model.add(tf.keras.layers.Dense(1))

model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=best_params['learning_rate']),
              loss='mean_squared_error')

history = model.fit(X_train_scaled, y_train_scaled, validation_split=0.2, epochs=50, verbose=1)
#+end_src

#+begin_src jupyter-python :kernel iotvar_powerprofiler :results silent
history = model.fit(X_train_scaled, y_train_scaled, validation_split=0.2, epochs=200, verbose=1)

#+end_src

#+begin_src jupyter-python :kernel iotvar_powerprofiler
print(f'Best trial: {study.best_trial.value}')
print(f'Best parameters: {study.best_trial.params}')
loss = model.evaluate(X_test, y_test, verbose=1)
print(f'Test Loss: {loss}')

plt.plot(history.history['loss'], label='Training Loss')
plt.plot(history.history['val_loss'], label='Validation Loss')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.title('Loss Function Evolution Over Epochs')
plt.legend()
plt.show()
#+end_src

#+RESULTS:
:RESULTS:
: Best trial: -0.3408735692501068
: Best parameters: {'n_layers': 8, 'units': 18, 'activation': 'tanh', 'learning_rate': 0.0004445851654997604}
: 1/8 [==>...........................] - ETA: 0s - loss: 4.30208/8 [==============================] - 0s 2ms/step - loss: 4.7759
: Test Loss: 4.77586030960083
#+attr_org: :width 774
[[./.ob-jupyter/fba50f741e10aa071448e722f724f01ff383a52a.png]]
:END:

#+begin_src jupyter-python :kernel iotvar_powerprofiler
predictions_scaled = model.predict(X_test_scaled)
predictions = scaler_y.inverse_transform(predictions_scaled).flatten()
plt.scatter(y_test, predictions, alpha=0.7)
plt.xlabel('Actual Values')
plt.ylabel('Predicted Values')
plt.title('Predicted Values vs Actual Values')
plt.plot([min(y_test), max(y_test)], [min(y_test), max(y_test)], color='red')  # Diagonal line for reference
plt.show()
#+end_src

#+RESULTS:
:RESULTS:
: 1/8 [==>...........................] - ETA: 0s8/8 [==============================] - 0s 2ms/step
#+attr_org: :width 736
[[./.ob-jupyter/4aa5994abcf3e37d35edf64c7d77aa9d893e11df.png]]
:END:

#+begin_src jupyter-python :kernel iotvar_powerprofiler
plt.scatter(X_test[:, 2], y_test, alpha=0.7, label='Actual Values')
plt.scatter(X_test[:, 2], predictions, alpha=0.7, label='Predicted Values')
plt.xlabel('m')
plt.ylabel('b')
plt.title('m vs b: Actual vs Predicted')
plt.legend()
plt.show()
#+end_src

#+RESULTS:
:RESULTS:
#+attr_org: :width 736
[[./.ob-jupyter/8ff760825c4f5c3bea194dc3aa3557c9a1a00ca8.png]]
:END:

#+begin_src jupyter-python :kernel iotvar_powerprofiler
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score
mae = mean_absolute_error(y_test, predictions)
mse = mean_squared_error(y_test, predictions)
r2 = r2_score(y_test, predictions)

print(f"Mean Absolute Error: {mae}")
print(f"Mean Squared Error: {mse}")
print(f"R-squared: {r2}")

# Scatter plot of Actual vs Predicted
comparison_df = pd.DataFrame({'Actual': y_test, 'Predicted': predictions})
plt.figure(figsize=(12, 6))
sns.scatterplot(x='Actual', y='Predicted', data=comparison_df)
plt.title('Actual vs Predicted b Values')
plt.xlabel('Actual b')
plt.ylabel('Predicted b')
plt.plot([comparison_df['Actual'].min(), comparison_df['Actual'].max()],
         [comparison_df['Actual'].min(), comparison_df['Actual'].max()],
         color='red', linestyle='--')
plt.show()

# Residual plot
residuals = y_test - predictions
plt.figure(figsize=(12, 6))
sns.histplot(residuals, kde=True)
plt.title('Residuals Distribution')
plt.xlabel('Residuals')
plt.ylabel('Frequency')
plt.show()
#+end_src

#+RESULTS:
:RESULTS:
: Mean Absolute Error: 1.5323282868923274
: Mean Squared Error: 3.994885270775361
: R-squared: 0.11134159061880244
[[./.ob-jupyter/8cfd2d4d307d449d400741c4149d9b01d877f93d.png]]
[[./.ob-jupyter/e05df0f5040d7acf684fccf2f2bbb36ef71ece67.png]]
:END:


#+begin_src jupyter-python :kernel iotvar_powerprofiler :results silent
import polars as pl
import tensorflow as tf
from sklearn.model_selection import train_test_split, KFold
from sklearn.preprocessing import StandardScaler
import optuna
from optuna.integration import TFKerasPruningCallback
import matplotlib.pyplot as plt
import numpy as np

# Assuming m_b_df is already loaded
# Convert polars DataFrame to pandas DataFrame
df = m_b_df.to_pandas()

# Define predictors and target
X = df[['refresh_period', 'number_sensors', 'm']].values
y = df['b'].values

# Scale the data
scaler_X = StandardScaler()
scaler_y = StandardScaler()

X_scaled = scaler_X.fit_transform(X)
y_scaled = scaler_y.fit_transform(y.reshape(-1, 1)).flatten()

# Define the objective function for Optuna
def objective(trial):
    # Define hyperparameters to tune
    n_layers = trial.suggest_int('n_layers', 1, 3)
    units = trial.suggest_int('units', 16, 128)
    activation = trial.suggest_categorical('activation', ['relu', 'tanh', 'sigmoid'])
    learning_rate = trial.suggest_float('learning_rate', 1e-4, 1e-2, log=True)

    # Build the model
    model = tf.keras.Sequential()
    model.add(tf.keras.layers.InputLayer(input_shape=(X_scaled.shape[1],)))

    for _ in range(n_layers):
        model.add(tf.keras.layers.Dense(units, activation=activation))

    model.add(tf.keras.layers.Dense(1))

    # Compile the model
    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate),
                  loss='mean_squared_error')

    # Cross-validation
    kf = KFold(n_splits=5)
    val_losses = []

    for train_index, val_index in kf.split(X_scaled):
        X_train_fold, X_val_fold = X_scaled[train_index], X_scaled[val_index]
        y_train_fold, y_val_fold = y_scaled[train_index], y_scaled[val_index]

        history = model.fit(X_train_fold, y_train_fold,
                            validation_data=(X_val_fold, y_val_fold),
                            epochs=50,
                            callbacks=[TFKerasPruningCallback(trial, 'val_loss')],
                            verbose=0)

        val_loss = model.evaluate(X_val_fold, y_val_fold, verbose=0)
        val_losses.append(val_loss)

    return np.mean(val_losses)

# Create a study and optimize the objective function
study = optuna.create_study(direction='minimize')
study.optimize(objective, n_trials=50)

# Print the best parameters
print(f'Best trial: {study.best_trial.value}')
print(f'Best parameters: {study.best_trial.params}')

# Train the best model using the best parameters
best_params = study.best_trial.params
model = tf.keras.Sequential()
model.add(tf.keras.layers.InputLayer(input_shape=(X_scaled.shape[1],)))

for _ in range(best_params['n_layers']):
    model.add(tf.keras.layers.Dense(best_params['units'], activation=best_params['activation']))

model.add(tf.keras.layers.Dense(1))

model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=best_params['learning_rate']),
              loss='mean_squared_error')

# Split the data again to ensure reproducibility
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
X_train_scaled = scaler_X.fit_transform(X_train)
X_test_scaled = scaler_X.transform(X_test)
y_train_scaled = scaler_y.fit_transform(y_train.reshape(-1, 1)).flatten()
y_test_scaled = scaler_y.transform(y_test.reshape(-1, 1)).flatten()

history = model.fit(X_train_scaled, y_train_scaled, validation_split=0.2, epochs=50, verbose=1)

# Evaluate the final model
loss = model.evaluate(X_test_scaled, y_test_scaled, verbose=1)
print(f'Test Loss: {loss}')

# Make predictions
predictions_scaled = model.predict(X_test_scaled)
predictions = scaler_y.inverse_transform(predictions_scaled).flatten()
print(f'Predictions: {predictions}')

#+end_src

#+begin_src jupyter-python :kernel iotvar_powerprofiler
# Plot the evolution of the loss function over the epochs
plt.figure(figsize=(14, 7))
plt.subplot(1, 2, 1)
plt.plot(history.history['loss'], label='Training Loss')
plt.plot(history.history['val_loss'], label='Validation Loss')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.title('Loss Function Evolution Over Epochs')
plt.legend()

# Plot m vs b comparing actual b values from the test set and the predictions
plt.subplot(1, 2, 2)
plt.scatter(X_test[:, 2], y_test, alpha=0.7, label='Actual Values')
plt.scatter(X_test[:, 2], predictions, alpha=0.7, label='Predicted Values')
plt.xlabel('m')
plt.ylabel('b')
plt.title('m vs b: Actual vs Predicted')
plt.legend()
plt.tight_layout()
plt.show()

#+end_src

#+RESULTS:
[[./.ob-jupyter/91f743a3507ce1e8e14d6e47ab80aba13e7ee5a6.png]]

#+begin_src jupyter-python :kernel iotvar_powerprofiler :results silent
import polars as pl
import tensorflow as tf
from sklearn.model_selection import train_test_split, KFold
from sklearn.preprocessing import StandardScaler
import optuna
from optuna.integration import TFKerasPruningCallback
import matplotlib.pyplot as plt
import numpy as np

# Assuming m_b_df is already loaded
# Convert polars DataFrame to pandas DataFrame
df = m_b_df.to_pandas()

# Define predictors and target
X = df[['refresh_period', 'number_sensors', 'm']].values
y = df['b'].values

# Scale the data
scaler_X = StandardScaler()
scaler_y = StandardScaler()

X_scaled = scaler_X.fit_transform(X)
y_scaled = scaler_y.fit_transform(y.reshape(-1, 1)).flatten()

# Define the objective function for Optuna
def objective(trial):
    # Define hyperparameters to tune
    n_layers = trial.suggest_int('n_layers', 1, 3)
    units = trial.suggest_int('units', 16, 128)
    activation = trial.suggest_categorical('activation', ['relu', 'tanh', 'sigmoid'])
    learning_rate = trial.suggest_float('learning_rate', 1e-4, 1e-2, log=True)

    # Build the model
    model = tf.keras.Sequential()
    model.add(tf.keras.layers.InputLayer(input_shape=(X_scaled.shape[1],)))

    for _ in range(n_layers):
        model.add(tf.keras.layers.Dense(units, activation=activation))

    model.add(tf.keras.layers.Dense(1))

    # Compile the model
    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate),
                  loss='mean_squared_error')

    # Cross-validation
    kf = KFold(n_splits=5)
    val_losses = []

    for train_index, val_index in kf.split(X_scaled):
        X_train_fold, X_val_fold = X_scaled[train_index], X_scaled[val_index]
        y_train_fold, y_val_fold = y_scaled[train_index], y_scaled[val_index]

        history = model.fit(X_train_fold, y_train_fold,
                            validation_data=(X_val_fold, y_val_fold),
                            epochs=50,
                            callbacks=[TFKerasPruningCallback(trial, 'val_loss')],
                            verbose=0)

        val_loss = model.evaluate(X_val_fold, y_val_fold, verbose=0)
        val_losses.append(val_loss)

    return np.mean(val_losses)

# Create a study and optimize the objective function
study = optuna.create_study(direction='minimize')
study.optimize(objective, n_trials=50)

# Print the best parameters
print(f'Best trial: {study.best_trial.value}')
print(f'Best parameters: {study.best_trial.params}')

# Train the best model using the best parameters
best_params = study.best_trial.params
model = tf.keras.Sequential()
model.add(tf.keras.layers.InputLayer(input_shape=(X_scaled.shape[1],)))

for _ in range(best_params['n_layers']):
    model.add(tf.keras.layers.Dense(best_params['units'], activation=best_params['activation']))

model.add(tf.keras.layers.Dense(1))

model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=best_params['learning_rate']),
              loss='mean_squared_error')

# Split the data again to ensure reproducibility
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
X_train_scaled = scaler_X.fit_transform(X_train)
X_test_scaled = scaler_X.transform(X_test)
y_train_scaled = scaler_y.fit_transform(y_train.reshape(-1, 1)).flatten()
y_test_scaled = scaler_y.transform(y_test.reshape(-1, 1)).flatten()

history = model.fit(X_train_scaled, y_train_scaled, validation_split=0.2, epochs=50, verbose=1)

# Evaluate the final model
loss = model.evaluate(X_test_scaled, y_test_scaled, verbose=1)
print(f'Test Loss: {loss}')

# Make predictions
predictions_scaled = model.predict(X_test_scaled)
predictions = scaler_y.inverse_transform(predictions_scaled).flatten()
print(f'Predictions: {predictions}')


#+end_src

#+begin_src jupyter-python :kernel iotvar_powerprofiler
# Plot the evolution of the loss function over the epochs
plt.figure(figsize=(14, 7))
plt.subplot(1, 2, 1)
plt.plot(history.history['loss'], label='Training Loss')
plt.plot(history.history['val_loss'], label='Validation Loss')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.title('Loss Function Evolution Over Epochs')
plt.legend()

# Plot m vs b comparing actual b values from the test set and the predictions
plt.subplot(1, 2, 2)
plt.scatter(X_test[:, 2], y_test, alpha=0.7, label='Actual Values')
plt.scatter(X_test[:, 2], predictions, alpha=0.7, label='Predicted Values')
plt.xlabel('m')
plt.ylabel('b')
plt.title('m vs b: Actual vs Predicted')
plt.legend()

plt.tight_layout()
plt.show()

#+end_src

#+RESULTS:
[[./.ob-jupyter/955ed36e787f40c4a23a68a2a8ba4d02d34a181f.png]]
** lightgbm
#+begin_src jupyter-python :kernel iotvar_powerprofiler :results silent
import lightgbm as lgb
import optuna
from sklearn.model_selection import train_test_split, cross_val_score, KFold
from sklearn.metrics import mean_squared_error
from sklearn.preprocessing import StandardScaler, PolynomialFeatures
import pandas as pd

# Convert to DataFrame for easier manipulation
df = pd.DataFrame({
    'm': m_b_df['m'],
    'refresh_period': m_b_df['refresh_period'],
    'number_sensors': m_b_df['number_sensors'],
    'b': m_b_df['b']
})

# Create interaction and polynomial features
poly = PolynomialFeatures(degree=2, include_bias=False, interaction_only=False)
X_poly = poly.fit_transform(df[['m', 'refresh_period', 'number_sensors']])

# Standardize the new feature set
scaler = StandardScaler()
X_poly_scaled = scaler.fit_transform(X_poly)

# Update X and Z
X = X_poly_scaled
Z = df['b'].values

# Split the data into training and testing sets
X_train, X_test, Z_train, Z_test = train_test_split(X, Z, test_size=0.2, random_state=42)

# Define the objective function for Optuna
def objective(trial):
    param = {
        'objective': 'regression',
        'metric': 'rmse',
        'boosting_type': 'gbdt',
        'n_estimators': trial.suggest_int('n_estimators', 50, 500),
        'max_depth': trial.suggest_int('max_depth', 3, 10),
        'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.2),
        'subsample': trial.suggest_float('subsample', 0.6, 1.0),
        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.6, 1.0),
        'reg_alpha': trial.suggest_loguniform('reg_alpha', 1e-8, 1.0),
        'reg_lambda': trial.suggest_loguniform('reg_lambda', 1e-8, 1.0),
        'min_child_weight': trial.suggest_loguniform('min_child_weight', 1e-8, 1.0)
    }

    lgb_reg = lgb.LGBMRegressor(**param)

    kf = KFold(n_splits=5, shuffle=True, random_state=42)
    cv_scores = cross_val_score(lgb_reg, X_train, Z_train, cv=kf, scoring='neg_mean_squared_error')

    return np.mean(-cv_scores)

# Run the optimization
study = optuna.create_study(direction='minimize')
study.optimize(objective, n_trials=100, timeout=600)

# Output the best parameters
print("Best parameters found: ", study.best_params)

# Train the model with the best parameters and early stopping
best_params = study.best_params
best_lgb_reg = lgb.LGBMRegressor(**best_params)

best_lgb_reg.fit(
    X_train,
    Z_train,
    eval_set=[(X_test, Z_test)]
)

# Predict on test set
Z_pred = best_lgb_reg.predict(X_test)

# Evaluate model performance
mse = mean_squared_error(Z_test, Z_pred)
print(f"Mean Squared Error: {mse}")
#+end_src

#+RESULTS:

#+begin_src jupyter-python :kernel iotvar_powerprofiler
print("Best parameters found: ", study.best_params)
#+end_src

#+RESULTS:
: Best parameters found:  {'n_estimators': 134, 'max_depth': 7, 'learning_rate': 0.011846511414706478, 'subsample': 0.7817834050543645, 'colsample_bytree': 0.6633084223010128, 'reg_alpha': 4.752278039219861e-07, 'reg_lambda': 1.0666454399378853e-05, 'min_child_weight': 0.0027023637190968027}

#+begin_src jupyter-python :kernel iotvar_powerprofiler
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score
mae = mean_absolute_error(Z_test, Z_pred)
mse = mean_squared_error(Z_test, Z_pred)
r2 = r2_score(Z_test, Z_pred)

print(f"Mean Absolute Error: {mae}")
print(f"Mean Squared Error: {mse}")
print(f"R-squared: {r2}")

comparison_df = pd.DataFrame({'Actual': Z_test, 'Predicted': Z_pred})
plt.figure(figsize=(12, 6))
sns.scatterplot(x='Actual', y='Predicted', data=comparison_df)
plt.title('Actual vs Predicted b Values')
plt.xlabel('Actual b')
plt.ylabel('Predicted b')
plt.plot([comparison_df['Actual'].min(), comparison_df['Actual'].max()],
         [comparison_df['Actual'].min(), comparison_df['Actual'].max()],
         color='red', linestyle='--')
plt.show()

residuals = Z_test - Z_pred
plt.figure(figsize=(12, 6))
sns.histplot(residuals, kde=True)
plt.title('Residuals Distribution')
plt.xlabel('Residuals')
plt.ylabel('Frequency')
plt.show()
#+end_src

#+RESULTS:
:RESULTS:
: Mean Absolute Error: 1.4545320529985621
: Mean Squared Error: 3.7802511339130156
: R-squared: 0.15908674917400123
[[./.ob-jupyter/99dc212dd46bf21f47fdd5d7a6a8384fec2a6c81.png]]
[[./.ob-jupyter/68ade6003040460ea990d8aa5c41f3fc4eeaf34d.png]]
:END:
** stacking xgboost and lightgbm

#+begin_src jupyter-python :kernel iotvar_powerprofiler :results silent
import numpy as np
import pandas as pd
import lightgbm as lgb
import xgboost as xgb
import optuna
from sklearn.linear_model import LinearRegression
from sklearn.model_selection import train_test_split, KFold
from sklearn.metrics import mean_squared_error
from sklearn.preprocessing import StandardScaler, PolynomialFeatures
from sklearn.base import clone
from sklearn.ensemble import StackingRegressor

# Convert to DataFrame for easier manipulation
df = pd.DataFrame({
    'm': m_b_df['m'],
    'refresh_period': m_b_df['refresh_period'],
    'number_sensors': m_b_df['number_sensors'],
    'b': m_b_df['b']
})

# Create interaction and polynomial features
poly = PolynomialFeatures(degree=2, include_bias=False, interaction_only=False)
X_poly = poly.fit_transform(df[['m', 'refresh_period', 'number_sensors']])

# Standardize the new feature set
scaler = StandardScaler()
X_poly_scaled = scaler.fit_transform(X_poly)

# Update X and Z
X = X_poly_scaled
Z = df['b'].values

# Split the data into training and testing sets
X_train, X_test, Z_train, Z_test = train_test_split(X, Z, test_size=0.2, random_state=42)

# Define the objective function for Optuna for LightGBM
def objective_lgb(trial):
    param = {
        'objective': 'regression',
        'metric': 'rmse',
        'boosting_type': 'gbdt',
        'n_estimators': trial.suggest_int('n_estimators', 50, 500),
        'max_depth': trial.suggest_int('max_depth', 3, 10),
        'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.2),
        'subsample': trial.suggest_float('subsample', 0.6, 1.0),
        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.6, 1.0),
        'reg_alpha': trial.suggest_loguniform('reg_alpha', 1e-8, 1.0),
        'reg_lambda': trial.suggest_loguniform('reg_lambda', 1e-8, 1.0),
        'min_child_weight': trial.suggest_loguniform('min_child_weight', 1e-8, 1.0)
    }

    lgb_reg = lgb.LGBMRegressor(**param)

    kf = KFold(n_splits=5, shuffle=True, random_state=42)
    cv_scores = cross_val_score(lgb_reg, X_train, Z_train, cv=kf, scoring='neg_mean_squared_error')

    return np.mean(-cv_scores)

# Run the optimization for LightGBM
study_lgb = optuna.create_study(direction='minimize')
study_lgb.optimize(objective_lgb, n_trials=100, timeout=600)

# Define the objective function for Optuna for XGBoost
def objective_xgb(trial):
    param = {
        'objective': 'reg:squarederror',
        'n_estimators': trial.suggest_int('n_estimators', 50, 500),
        'max_depth': trial.suggest_int('max_depth', 3, 10),
        'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.2),
        'subsample': trial.suggest_float('subsample', 0.6, 1.0),
        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.6, 1.0),
        'alpha': trial.suggest_loguniform('alpha', 1e-8, 1.0),
        'lambda': trial.suggest_loguniform('lambda', 1e-8, 1.0),
        'gamma': trial.suggest_loguniform('gamma', 1e-8, 1.0)
    }

    xgb_reg = xgb.XGBRegressor(**param)

    kf = KFold(n_splits=5, shuffle=True, random_state=42)
    cv_scores = cross_val_score(xgb_reg, X_train, Z_train, cv=kf, scoring='neg_mean_squared_error')

    return np.mean(-cv_scores)

# Run the optimization for XGBoost
study_xgb = optuna.create_study(direction='minimize')
study_xgb.optimize(objective_xgb, n_trials=100, timeout=600)

# Get the best parameters for both models
best_params_lgb = study_lgb.best_params
best_params_xgb = study_xgb.best_params

# Create the base models with the best parameters
lgb_reg = lgb.LGBMRegressor(**best_params_lgb)
xgb_reg = xgb.XGBRegressor(**best_params_xgb)

# Create the stacking ensemble
stacking_regressor = StackingRegressor(
    estimators=[
        ('lgb', lgb_reg),
        ('xgb', xgb_reg)
    ],
    final_estimator=LinearRegression()
)

# Train the stacking ensemble
stacking_regressor.fit(X_train, Z_train)

# Predict on test set
Z_pred = stacking_regressor.predict(X_test)

# Evaluate model performance
mse = mean_squared_error(Z_test, Z_pred)
print(f"Mean Squared Error: {mse}")

#+end_src

#+begin_src jupyter-python :kernel iotvar_powerprofiler :results silent
import numpy as np
import pandas as pd
from sklearn.preprocessing import StandardScaler, PolynomialFeatures
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error
import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Dropout
from tensorflow.keras.callbacks import EarlyStopping

# Convert to DataFrame for easier manipulation
df = pd.DataFrame({
    'm': m_b_df['m'],
    'refresh_period': m_b_df['refresh_period'],
    'number_sensors': m_b_df['number_sensors'],
    'b': m_b_df['b']
})

# Create interaction and polynomial features
poly = PolynomialFeatures(degree=2, include_bias=False, interaction_only=False)
X_poly = poly.fit_transform(df[['m', 'refresh_period', 'number_sensors']])

# Standardize the new feature set
scaler = StandardScaler()
X_poly_scaled = scaler.fit_transform(X_poly)

# Update X and Z
X = X_poly_scaled
Z = df['b'].values

# Split the data into training and testing sets
X_train, X_test, Z_train, Z_test = train_test_split(X, Z, test_size=0.2, random_state=42)

# Define the neural network model
def create_model():
    model = Sequential()
    model.add(Dense(128, input_dim=X_train.shape[1], activation='relu'))
    model.add(Dropout(0.2))
    model.add(Dense(64, activation='relu'))
    model.add(Dropout(0.2))
    model.add(Dense(32, activation='relu'))
    model.add(Dropout(0.2))
    model.add(Dense(1, activation='linear'))

    model.compile(optimizer='adam', loss='mse', metrics=['mse'])
    return model

# Create the model
model = create_model()

# Define early stopping
early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)

# Train the model
history = model.fit(X_train, Z_train, epochs=100, batch_size=32, validation_split=0.2, callbacks=[early_stopping], verbose=1)

# Predict on test set
Z_pred = model.predict(X_test).flatten()

# Evaluate model performance
#+end_src

#+begin_src jupyter-python :kernel iotvar_powerprofiler
mse = mean_squared_error(Z_test, Z_pred)
print(f"Mean Squared Error: {mse}")
#+end_src

#+RESULTS:
: Mean Squared Error: 3.7001290913961835

#+begin_src jupyter-python :kernel iotvar_powerprofiler :results silent
import numpy as np
import pandas as pd
from sklearn.preprocessing import StandardScaler, PolynomialFeatures
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error
import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Dropout
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau
import optuna

# Convert to DataFrame for easier manipulation
df = pd.DataFrame({
    'm': m_b_df['m'],
    'refresh_period': m_b_df['refresh_period'],
    'number_sensors': m_b_df['number_sensors'],
    'b': m_b_df['b']
})

# Create interaction and polynomial features
poly = PolynomialFeatures(degree=2, include_bias=False, interaction_only=False)
X_poly = poly.fit_transform(df[['m', 'refresh_period', 'number_sensors']])

# Standardize the new feature set
scaler = StandardScaler()
X_poly_scaled = scaler.fit_transform(X_poly)

# Update X and Z
X = X_poly_scaled
Z = df['b'].values

# Split the data into training and testing sets
X_train, X_test, Z_train, Z_test = train_test_split(X, Z, test_size=0.2, random_state=42)

# Define the objective function for Optuna
def objective(trial):
    model = Sequential()

    # Define the hyperparameters to tune
    n_layers = trial.suggest_int('n_layers', 1, 5)
    for i in range(n_layers):
        num_units = trial.suggest_int(f'n_units_l{i}', 32, 256)
        model.add(Dense(num_units, activation='relu'))
        dropout_rate = trial.suggest_float(f'dropout_l{i}', 0.2, 0.5)
        model.add(Dropout(dropout_rate))

    model.add(Dense(1, activation='linear'))

    # Learning rate
    learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-2)
    optimizer = Adam(learning_rate=learning_rate)

    model.compile(optimizer=optimizer, loss='mse', metrics=['mse'])

    # Early stopping and learning rate reduction
    early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)
    reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=5, min_lr=1e-6)

    history = model.fit(X_train, Z_train, epochs=100, batch_size=32, validation_split=0.2,
                        callbacks=[early_stopping, reduce_lr], verbose=0)

    # Predict on test set
    Z_pred = model.predict(X_test).flatten()

    # Evaluate model performance
    mse = mean_squared_error(Z_test, Z_pred)

    return mse

# Run the optimization
study = optuna.create_study(direction='minimize')
study.optimize(objective, n_trials=50, timeout=3600)

# Output the best parameters
best_params = study.best_params
print("Best parameters found: ", best_params)

# Train the final model with the best parameters
final_model = Sequential()
n_layers = best_params['n_layers']
for i in range(n_layers):
    num_units = best_params[f'n_units_l{i}']
    final_model.add(Dense(num_units, activation='relu'))
    dropout_rate = best_params[f'dropout_l{i}']
    final_model.add(Dropout(dropout_rate))

final_model.add(Dense(1, activation='linear'))

# Learning rate
learning_rate = best_params['learning_rate']
optimizer = Adam(learning_rate=learning_rate)

final_model.compile(optimizer=optimizer, loss='mse', metrics=['mse'])

# Early stopping and learning rate reduction
early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)
reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=5, min_lr=1e-6)

final_model.fit(X_train, Z_train, epochs=100, batch_size=32, validation_split=0.2,
                callbacks=[early_stopping, reduce_lr], verbose=1)

# Predict on test set
Z_pred = final_model.predict(X_test).flatten()

# Evaluate model performance
#+end_src

#+begin_src jupyter-python :kernel iotvar_powerprofiler
mse = mean_squared_error(Z_test, Z_pred)
print(f"Mean Squared Error: {mse}")

#+end_src

#+RESULTS:
: Mean Squared Error: 3.733835246749555
